---
title: chatmodels
sidebar_position: 1
---

<!-- Code generated by gomarkdoc. DO NOT EDIT -->


# chatmodels

```go
import "github.com/lookatitude/beluga-ai/pkg/chatmodels"
```

Package chatmodels provides chat-based language model implementations following the Beluga AI Framework design patterns.

This package implements chat models that can handle conversation-like interactions with various providers. It follows SOLID principles with dependency inversion, interface segregation, and composition over inheritance.

Key Features:

- Multiple provider support (OpenAI, Anthropic, local models)
- Streaming and non-streaming message generation
- Comprehensive error handling with custom error types
- Observability with OpenTelemetry tracing and metrics
- Configurable generation with retry logic and timeouts
- Health checking and model information

Basic Usage:

```
// Create a chat model
config := chatmodels.DefaultConfig()
config.DefaultProvider = "openai"
model, err := chatmodels.NewChatModel("gpt-4", config)

// Generate messages
:= []schema.Message{
	{Role: "user", Content: "Hello, how are you?"},
}
response, err := model.GenerateMessages(ctx, messages)
```

Advanced Usage:

```
// Create with custom configuration
model, err := chatmodels.NewChatModel("gpt-4", config,
	chatmodels.WithTemperature(0.8),
	chatmodels.WithMaxTokens(2000),
	chatmodels.WithFunctionCalling(true),
)

// Use streaming
stream, err := model.StreamMessages(ctx, messages)
for msg := range stream {
	fmt.Println("Received:", msg.Content)
}
```

Package chatmodels provides advanced test utilities and comprehensive mocks for testing chat model implementations. This file contains utilities designed to support both unit tests and integration tests.

Test Coverage Exclusions:

The following code paths are intentionally excluded from 100% coverage requirements:

1. Panic Recovery Paths:

- Panic handlers in concurrent test runners (ConcurrentTestRunner)
- These paths are difficult to test without causing actual panics in test code

2. Context Cancellation Edge Cases:

- Some context cancellation paths in streaming operations are difficult to reliably test
- Race conditions between context cancellation and channel operations in StreamMessages

3. Error Paths Requiring System Conditions:

- Network errors that require actual network failures (provider implementations)
- File system errors that require specific OS conditions
- Memory exhaustion scenarios

4. Provider-Specific Untestable Paths:

- Provider implementations in pkg/chatmodels/providers/* require external service failures
- These are tested through integration tests rather than unit tests
- Provider registry initialization code (init() functions)

5. Test Utility Functions:

- Helper functions in test\_utils.go that are used by tests but not directly tested
- These are validated through their usage in actual test cases

6. Initialization Code:

- Package init() functions and global variable initialization
- Registry registration code that executes automatically

7. OTEL Context Logging:

- logWithOTELContext function has paths that require valid OTEL context
- Some edge cases in trace/span ID extraction are difficult to test in isolation

All exclusions are documented here to maintain transparency about coverage goals. The target is 100% coverage of testable code paths, excluding the above categories.

## Index

- [Constants](<#constants>)
- [Variables](<#variables>)
- [`func AssertChatModelHealth(t *testing.T, health map[string]any, expectedStatus string)`](<#AssertChatModelHealth>)
- [`func AssertChatResponse(t *testing.T, response schema.Message, expectedMinLength int)`](<#AssertChatResponse>)
- [`func AssertConversationFlow(t *testing.T, history []schema.Message, expectedMinLength int)`](<#AssertConversationFlow>)
- [`func AssertErrorType(t *testing.T, err error, expectedCode string)`](<#AssertErrorType>)
- [`func AssertStreamingResponse(t *testing.T, chunks []llmsiface.AIMessageChunk, expectedMinChunks int)`](<#AssertStreamingResponse>)
- [`func CreateTestMessages(conversationLength int) []schema.Message`](<#CreateTestMessages>)
- [`func GenerateMessages(ctx context.Context, model iface.ChatModel, messages []schema.Message, opts ...iface.Option) ([]schema.Message, error)`](<#GenerateMessages>)
- [`func GetModelInfo(model iface.ChatModel) iface.ModelInfo`](<#GetModelInfo>)
- [`func GetRegistry() registryiface.Registry`](<#GetRegistry>)
- [`func GetSupportedModels(provider string) []string`](<#GetSupportedModels>)
- [`func GetSupportedProviders() []string`](<#GetSupportedProviders>)
- [`func HealthCheck(model iface.ChatModel) map[string]any`](<#HealthCheck>)
- [`func InitMetrics(meter metric.Meter, tracer trace.Tracer)`](<#InitMetrics>)
- [`func IsAuthenticationError(err error) bool`](<#IsAuthenticationError>)
- [`func IsGenerationError(err error) bool`](<#IsGenerationError>)
- [`func IsProviderError(err error) bool`](<#IsProviderError>)
- [`func IsQuotaError(err error) bool`](<#IsQuotaError>)
- [`func IsRetryable(err error) bool`](<#IsRetryable>)
- [`func IsStreamingError(err error) bool`](<#IsStreamingError>)
- [`func IsValidationError(err error) bool`](<#IsValidationError>)
- [`func NewChatModel(model string, config *Config, opts ...iface.Option) (iface.ChatModel, error)`](<#NewChatModel>)
- [`func NewMockChatModel(model string, opts ...iface.Option) (iface.ChatModel, error)`](<#NewMockChatModel>)
- [`func NewOpenAIChatModel(model, apiKey string, opts ...iface.Option) (iface.ChatModel, error)`](<#NewOpenAIChatModel>)
- [`func RunLoadTest(t *testing.T, chatModel *AdvancedMockChatModel, numOperations, concurrency int)`](<#RunLoadTest>)
- [`func StreamMessages(ctx context.Context, model iface.ChatModel, messages []schema.Message, opts ...iface.Option) (<-chan schema.Message, error)`](<#StreamMessages>)
- [`func ValidateConfig(config *Config) error`](<#ValidateConfig>)
- [`func WithFunctionCalling(enabled bool) iface.Option`](<#WithFunctionCalling>)
- [`func WithMaxRetries(retries int) iface.Option`](<#WithMaxRetries>)
- [`func WithMaxTokens(maxTokens int) iface.Option`](<#WithMaxTokens>)
- [`func WithMetrics(enabled bool) iface.Option`](<#WithMetrics>)
- [`func WithStopSequences(sequences []string) iface.Option`](<#WithStopSequences>)
- [`func WithSystemPrompt(prompt string) iface.Option`](<#WithSystemPrompt>)
- [`func WithTemperature(temp float32) iface.Option`](<#WithTemperature>)
- [`func WithTimeout(timeout time.Duration) iface.Option`](<#WithTimeout>)
- [`func WithTopP(topP float32) iface.Option`](<#WithTopP>)
- [`func WithTracing(enabled bool) iface.Option`](<#WithTracing>)
- [type AdvancedMockChatModel](<#AdvancedMockChatModel>)
  - [`func NewAdvancedMockChatModel(modelName, providerName string, options ...MockChatModelOption) *AdvancedMockChatModel`](<#NewAdvancedMockChatModel>)
  - [`func (m *AdvancedMockChatModel) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error)`](<#AdvancedMockChatModel.Batch>)
  - [`func (m *AdvancedMockChatModel) BindTools(toolsToBind []tools.Tool) llmsiface.ChatModel`](<#AdvancedMockChatModel.BindTools>)
  - [`func (m *AdvancedMockChatModel) CheckHealth() map[string]any`](<#AdvancedMockChatModel.CheckHealth>)
  - [`func (m *AdvancedMockChatModel) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error)`](<#AdvancedMockChatModel.Generate>)
  - [`func (m *AdvancedMockChatModel) GenerateMessages(ctx context.Context, messages []schema.Message, options ...core.Option) ([]schema.Message, error)`](<#AdvancedMockChatModel.GenerateMessages>)
  - [`func (m *AdvancedMockChatModel) GetCallCount() int`](<#AdvancedMockChatModel.GetCallCount>)
  - [`func (m *AdvancedMockChatModel) GetConversationHistory() []schema.Message`](<#AdvancedMockChatModel.GetConversationHistory>)
  - [`func (m *AdvancedMockChatModel) GetModelInfo() iface.ModelInfo`](<#AdvancedMockChatModel.GetModelInfo>)
  - [`func (m *AdvancedMockChatModel) GetModelName() string`](<#AdvancedMockChatModel.GetModelName>)
  - [`func (m *AdvancedMockChatModel) GetProviderName() string`](<#AdvancedMockChatModel.GetProviderName>)
  - [`func (m *AdvancedMockChatModel) Invoke(ctx context.Context, input any, options ...core.Option) (any, error)`](<#AdvancedMockChatModel.Invoke>)
  - [`func (m *AdvancedMockChatModel) ResetConversation()`](<#AdvancedMockChatModel.ResetConversation>)
  - [`func (m *AdvancedMockChatModel) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error)`](<#AdvancedMockChatModel.Stream>)
  - [`func (m *AdvancedMockChatModel) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan llmsiface.AIMessageChunk, error)`](<#AdvancedMockChatModel.StreamChat>)
  - [`func (m *AdvancedMockChatModel) StreamMessages(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan schema.Message, error)`](<#AdvancedMockChatModel.StreamMessages>)
- [type AdvancedMockcomponent](<#AdvancedMockcomponent>)
  - [`func NewAdvancedMockcomponent() *AdvancedMockcomponent`](<#NewAdvancedMockcomponent>)
- [type BenchmarkHelper](<#BenchmarkHelper>)
  - [`func NewBenchmarkHelper(chatModel llmsiface.ChatModel, conversationCount int) *BenchmarkHelper`](<#NewBenchmarkHelper>)
  - [`func (b *BenchmarkHelper) BenchmarkGeneration(iterations int) (time.Duration, error)`](<#BenchmarkHelper.BenchmarkGeneration>)
  - [`func (b *BenchmarkHelper) BenchmarkStreaming(iterations int) (time.Duration, error)`](<#BenchmarkHelper.BenchmarkStreaming>)
- [type ChatModelError](<#ChatModelError>)
  - [`func NewChatModelError(op, model, provider, code string, err error) *ChatModelError`](<#NewChatModelError>)
  - [`func (e *ChatModelError) Error() string`](<#ChatModelError.Error>)
  - [`func (e *ChatModelError) Unwrap() error`](<#ChatModelError.Unwrap>)
  - [`func (e *ChatModelError) WithField(key string, value any) *ChatModelError`](<#ChatModelError.WithField>)
- [type ChatModelScenarioRunner](<#ChatModelScenarioRunner>)
  - [`func NewChatModelScenarioRunner(chatModel llmsiface.ChatModel) *ChatModelScenarioRunner`](<#NewChatModelScenarioRunner>)
  - [`func (r *ChatModelScenarioRunner) RunConversationScenario(ctx context.Context, turns int) error`](<#ChatModelScenarioRunner.RunConversationScenario>)
  - [`func (r *ChatModelScenarioRunner) RunStreamingScenario(ctx context.Context, queries []string) error`](<#ChatModelScenarioRunner.RunStreamingScenario>)
- [type ConcurrentTestRunner](<#ConcurrentTestRunner>)
  - [`func NewConcurrentTestRunner(numGoroutines int, duration time.Duration, testFunc func() error) *ConcurrentTestRunner`](<#NewConcurrentTestRunner>)
  - [`func (r *ConcurrentTestRunner) Run() error`](<#ConcurrentTestRunner.Run>)
- [type Config](<#Config>)
  - [`func CreateTestChatModelConfig() Config`](<#CreateTestChatModelConfig>)
  - [`func DefaultConfig() *Config`](<#DefaultConfig>)
  - [`func NewDefaultConfig() *Config`](<#NewDefaultConfig>)
  - [`func (c *Config) GetDefaultProvider() string`](<#Config.GetDefaultProvider>)
  - [`func (c *Config) GetProviderConfig(provider string) (*ProviderConfig, error)`](<#Config.GetProviderConfig>)
  - [`func (c *Config) Validate() error`](<#Config.Validate>)
- [type ConfigProvider](<#ConfigProvider>)
- [type GenerationError](<#GenerationError>)
  - [`func NewGenerationError(model string, messages int, err error) *GenerationError`](<#NewGenerationError>)
  - [`func (e *GenerationError) Error() string`](<#GenerationError.Error>)
  - [`func (e *GenerationError) Unwrap() error`](<#GenerationError.Unwrap>)
  - [`func (e *GenerationError) WithSuggestion(suggestion string) *GenerationError`](<#GenerationError.WithSuggestion>)
  - [`func (e *GenerationError) WithTokenCount(tokens int) *GenerationError`](<#GenerationError.WithTokenCount>)
- [type IntegrationTestHelper](<#IntegrationTestHelper>)
  - [`func NewIntegrationTestHelper() *IntegrationTestHelper`](<#NewIntegrationTestHelper>)
  - [`func (h *IntegrationTestHelper) AddChatModel(name string, chatModel *AdvancedMockChatModel)`](<#IntegrationTestHelper.AddChatModel>)
  - [`func (h *IntegrationTestHelper) GetChatModel(name string) *AdvancedMockChatModel`](<#IntegrationTestHelper.GetChatModel>)
  - [`func (h *IntegrationTestHelper) Reset()`](<#IntegrationTestHelper.Reset>)
- [type Metrics](<#Metrics>)
  - [`func DefaultMetrics() *Metrics`](<#DefaultMetrics>)
  - [`func GetMetrics() *Metrics`](<#GetMetrics>)
  - [`func NewMetrics(meter metric.Meter, tracer trace.Tracer) (*Metrics, error)`](<#NewMetrics>)
  - [`func NoOpMetrics() *Metrics`](<#NoOpMetrics>)
  - [`func (m *Metrics) RecordMessageGeneration(model, provider string, duration time.Duration, success bool, tokenCount int)`](<#Metrics.RecordMessageGeneration>)
  - [`func (m *Metrics) RecordMessageGenerationError(model, provider, errorType string)`](<#Metrics.RecordMessageGenerationError>)
  - [`func (m *Metrics) RecordModelError(model, provider, errorType string)`](<#Metrics.RecordModelError>)
  - [`func (m *Metrics) RecordModelRequest(model, provider string, duration time.Duration, success bool)`](<#Metrics.RecordModelRequest>)
  - [`func (m *Metrics) RecordProviderError(provider, errorType string)`](<#Metrics.RecordProviderError>)
  - [`func (m *Metrics) RecordProviderRequest(provider string, duration time.Duration, success bool)`](<#Metrics.RecordProviderRequest>)
  - [`func (m *Metrics) RecordStreamingError(model, provider, errorType string)`](<#Metrics.RecordStreamingError>)
  - [`func (m *Metrics) RecordStreamingSession(model, provider string, duration time.Duration, success bool, messageCount int)`](<#Metrics.RecordStreamingSession>)
  - [`func (m *Metrics) RecordTokenUsage(model, provider string, tokensGenerated, tokensConsumed int)`](<#Metrics.RecordTokenUsage>)
  - [`func (m *Metrics) StartGenerationSpan(ctx context.Context, model, provider, operation string) (context.Context, trace.Span)`](<#Metrics.StartGenerationSpan>)
  - [`func (m *Metrics) StartProviderSpan(ctx context.Context, provider, operation string) (context.Context, trace.Span)`](<#Metrics.StartProviderSpan>)
  - [`func (m *Metrics) StartStreamingSpan(ctx context.Context, model, provider string) (context.Context, trace.Span)`](<#Metrics.StartStreamingSpan>)
- [type MockChatModelOption](<#MockChatModelOption>)
  - [`func WithConversationHistory(messages []schema.Message) MockChatModelOption`](<#WithConversationHistory>)
  - [`func WithMockAuthenticationError() MockChatModelOption`](<#WithMockAuthenticationError>)
  - [`func WithMockError(shouldError bool, err error) MockChatModelOption`](<#WithMockError>)
  - [`func WithMockErrorCode(code string) MockChatModelOption`](<#WithMockErrorCode>)
  - [`func WithMockGenerationError() MockChatModelOption`](<#WithMockGenerationError>)
  - [`func WithMockInvalidInputError() MockChatModelOption`](<#WithMockInvalidInputError>)
  - [`func WithMockInvalidResponseError() MockChatModelOption`](<#WithMockInvalidResponseError>)
  - [`func WithMockMaxRetriesError() MockChatModelOption`](<#WithMockMaxRetriesError>)
  - [`func WithMockModelNotFoundError() MockChatModelOption`](<#WithMockModelNotFoundError>)
  - [`func WithMockNetworkError() MockChatModelOption`](<#WithMockNetworkError>)
  - [`func WithMockProviderNotSupportedError() MockChatModelOption`](<#WithMockProviderNotSupportedError>)
  - [`func WithMockQuotaError() MockChatModelOption`](<#WithMockQuotaError>)
  - [`func WithMockRateLimitError() MockChatModelOption`](<#WithMockRateLimitError>)
  - [`func WithMockResourceExhaustedError() MockChatModelOption`](<#WithMockResourceExhaustedError>)
  - [`func WithMockResponses(responses []schema.Message) MockChatModelOption`](<#WithMockResponses>)
  - [`func WithMockStreamingError() MockChatModelOption`](<#WithMockStreamingError>)
  - [`func WithMockTimeoutError() MockChatModelOption`](<#WithMockTimeoutError>)
  - [`func WithStreamingDelay(delay time.Duration) MockChatModelOption`](<#WithStreamingDelay>)
  - [`func WithToolsSupport(supported bool) MockChatModelOption`](<#WithToolsSupport>)
- [type ProviderConfig](<#ProviderConfig>)
- [type ProviderError](<#ProviderError>)
  - [`func NewProviderError(provider, operation string, err error) *ProviderError`](<#NewProviderError>)
  - [`func (e *ProviderError) Error() string`](<#ProviderError.Error>)
  - [`func (e *ProviderError) Unwrap() error`](<#ProviderError.Unwrap>)
- [type RateLimitConfig](<#RateLimitConfig>)
- [type StreamingError](<#StreamingError>)
  - [`func NewStreamingError(model string, err error) *StreamingError`](<#NewStreamingError>)
  - [`func (e *StreamingError) Error() string`](<#StreamingError.Error>)
  - [`func (e *StreamingError) Unwrap() error`](<#StreamingError.Unwrap>)
  - [`func (e *StreamingError) WithDuration(duration string) *StreamingError`](<#StreamingError.WithDuration>)
- [type ValidationError](<#ValidationError>)
  - [`func NewValidationError(field, message string) *ValidationError`](<#NewValidationError>)
  - [`func (e *ValidationError) Error() string`](<#ValidationError.Error>)

## Constants

<a name="ErrCodeConfigInvalid"></a>Error codes for different types of chat model errors.

```go
const (
    ErrCodeConfigInvalid        = "config_invalid"
    ErrCodeInitialization       = "initialization_failed"
    ErrCodeGeneration           = "generation_failed"
    ErrCodeStreaming            = "streaming_failed"
    ErrCodeRateLimit            = "rate_limit"
    ErrCodeInvalidInput         = "invalid_input"
    ErrCodeNetworkError         = "network_error"
    ErrCodeTimeout              = "timeout"
    ErrCodeMaxRetries           = "max_retries_exceeded"
    ErrCodeInvalidResponse      = "invalid_response"
    ErrCodeModelNotFound        = "model_not_found"
    ErrCodeProviderNotSupported = "provider_not_supported"
    ErrCodeAuthentication       = "authentication_failed"
    ErrCodeQuotaExceeded        = "quota_exceeded"
    ErrCodeResourceExhausted    = "resource_exhausted"
)
```

## Variables

<a name="ErrChatModelNotFound"></a>Common error variables for frequently used errors.

```go
var (
    ErrChatModelNotFound    = errors.New("chat model not found")
    ErrInvalidConfig        = errors.New("invalid configuration")
    ErrProviderNotAvailable = errors.New("provider not available")
    ErrModelNotSupported    = errors.New("model not supported")
    ErrMaxRetriesExceeded   = errors.New("maximum retries exceeded")
    ErrContextCancelled     = errors.New("context canceled")
    ErrTimeout              = errors.New("operation timed out")
    ErrRateLimitExceeded    = errors.New("rate limit exceeded")
    ErrQuotaExceeded        = errors.New("quota exceeded")
    ErrResourceExhausted    = errors.New("resource exhausted")
    ErrAuthenticationFailed = errors.New("authentication failed")
    ErrNetworkError         = errors.New("network error")
)
```

<a name="AssertChatModelHealth"></a>
## func [AssertChatModelHealth](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L547>)

```go
func AssertChatModelHealth(t *testing.T, health map[string]any, expectedStatus string)
```

AssertChatModelHealth validates chat model health check results.

<a name="AssertChatResponse"></a>
## func [AssertChatResponse](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L507>)

```go
func AssertChatResponse(t *testing.T, response schema.Message, expectedMinLength int)
```

AssertChatResponse validates chat model response.

<a name="AssertConversationFlow"></a>
## func [AssertConversationFlow](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L531>)

```go
func AssertConversationFlow(t *testing.T, history []schema.Message, expectedMinLength int)
```

AssertConversationFlow validates conversation flow.

<a name="AssertErrorType"></a>
## func [AssertErrorType](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L557>)

```go
func AssertErrorType(t *testing.T, err error, expectedCode string)
```

AssertErrorType validates error types and codes.

<a name="AssertStreamingResponse"></a>
## func [AssertStreamingResponse](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L515>)

```go
func AssertStreamingResponse(t *testing.T, chunks []llmsiface.AIMessageChunk, expectedMinChunks int)
```

AssertStreamingResponse validates streaming response.

<a name="CreateTestMessages"></a>
## func [CreateTestMessages](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L471>)

```go
func CreateTestMessages(conversationLength int) []schema.Message
```

CreateTestMessages creates a set of test messages for chat model testing.

<a name="GenerateMessages"></a>
## func [GenerateMessages](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L332>)

```go
func GenerateMessages(ctx context.Context, model iface.ChatModel, messages []schema.Message, opts ...iface.Option) ([]schema.Message, error)
```

GenerateMessages is a convenience function for generating messages with a chat model. This wraps the model's GenerateMessages method for easier usage.

Parameters:

- ctx: Context for cancellation and timeout control
- model: Chat model instance
- messages: Input messages
- opts: Optional generation options

Returns:

- Generated response messages
- Error if generation fails

Example:

```
messages := []schema.Message{
	schema.NewHumanMessage("Hello!"),
}
response, err := chatmodels.GenerateMessages(ctx, model, messages)
```

<a name="GetModelInfo"></a>
## func [GetModelInfo](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L309>)

```go
func GetModelInfo(model iface.ChatModel) iface.ModelInfo
```

GetModelInfo retrieves model information from a chat model.

Parameters:

- model: Chat model instance

Returns:

- Model information struct

Example:

```
info := chatmodels.GetModelInfo(model)
fmt.Printf("Model: %s, Provider: %s\n", info.Name, info.Provider)
```

<a name="GetRegistry"></a>
## func [GetRegistry](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/registry.go#L18>)

```go
func GetRegistry() registryiface.Registry
```

GetRegistry returns the global registry instance. This is a convenience function that delegates to the registry package. This follows the standard pattern used across all Beluga AI packages.

Example:

```
registry := chatmodels.GetRegistry()
if registry.IsRegistered("openai") {
    model, err := registry.CreateProvider("gpt-4", config, options)
}
```

<a name="GetSupportedModels"></a>
## func [GetSupportedModels](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L267>)

```go
func GetSupportedModels(provider string) []string
```

GetSupportedModels returns a list of supported models for a given provider.

Parameters:

- provider: Provider name

Returns:

- Slice of supported model names

Example:

```
models := chatmodels.GetSupportedModels("openai")
fmt.Printf("OpenAI models: %v\n", models)
```

<a name="GetSupportedProviders"></a>
## func [GetSupportedProviders](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L251>)

```go
func GetSupportedProviders() []string
```

GetSupportedProviders returns a list of supported chat model providers.

Returns:

- Slice of supported provider names

Example:

```
providers := chatmodels.GetSupportedProviders()
fmt.Printf("Supported providers: %v\n", providers)
```

<a name="HealthCheck"></a>
## func [HealthCheck](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L293>)

```go
func HealthCheck(model iface.ChatModel) map[string]any
```

HealthCheck performs a health check on a chat model. This can be used for monitoring and ensuring model availability.

Parameters:

- model: Chat model to check

Returns:

- Health status information

Example:

```
status := chatmodels.HealthCheck(model)
if status["state"] == "error" {
	log.Warn("Model is in error state")
}
```

<a name="InitMetrics"></a>
## func [InitMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L425>)

```go
func InitMetrics(meter metric.Meter, tracer trace.Tracer)
```

InitMetrics initializes the global metrics instance. This follows the standard pattern used across all Beluga AI packages.

<a name="IsAuthenticationError"></a>
## func [IsAuthenticationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L274>)

```go
func IsAuthenticationError(err error) bool
```

IsAuthenticationError checks if an error is an authentication error.

<a name="IsGenerationError"></a>
## func [IsGenerationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L262>)

```go
func IsGenerationError(err error) bool
```

IsGenerationError checks if an error is a generation error.

<a name="IsProviderError"></a>
## func [IsProviderError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L256>)

```go
func IsProviderError(err error) bool
```

IsProviderError checks if an error is a provider error.

<a name="IsQuotaError"></a>
## func [IsQuotaError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L283>)

```go
func IsQuotaError(err error) bool
```

IsQuotaError checks if an error is a quota-related error.

<a name="IsRetryable"></a>
## func [IsRetryable](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L231>)

```go
func IsRetryable(err error) bool
```

IsRetryable checks if an error is retryable.

<a name="IsStreamingError"></a>
## func [IsStreamingError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L268>)

```go
func IsStreamingError(err error) bool
```

IsStreamingError checks if an error is a streaming error.

<a name="IsValidationError"></a>
## func [IsValidationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L250>)

```go
func IsValidationError(err error) bool
```

IsValidationError checks if an error is a validation error.

<a name="NewChatModel"></a>
## func [NewChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L78>)

```go
func NewChatModel(model string, config *Config, opts ...iface.Option) (iface.ChatModel, error)
```

NewChatModel creates a new chat model instance with the specified model name and configuration. This is the main factory function for creating chat models.

Parameters:

- model: The model name/identifier (e.g., "gpt-4", "claude-3")
- config: Configuration instance (use DefaultConfig() for defaults)
- opts: Optional configuration functions

Returns:

- Chat model instance implementing the ChatModel interface
- Error if initialization fails

Example:

```
config := chatmodels.DefaultConfig()
model, err := chatmodels.NewChatModel("gpt-4", config,
	chatmodels.WithTemperature(0.7),
	chatmodels.WithMaxTokens(1000),
)
```

<a name="NewMockChatModel"></a>
## func [NewMockChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L197>)

```go
func NewMockChatModel(model string, opts ...iface.Option) (iface.ChatModel, error)
```

NewMockChatModel creates a new mock chat model for testing. This creates a chat model that returns predetermined responses.

Parameters:

- model: Model name for the mock
- opts: Optional configuration functions

Returns:

- Mock chat model instance
- Error if initialization fails

Example:

```
model, err := chatmodels.NewMockChatModel("mock-gpt-4",
	chatmodels.WithTemperature(0.5),
)
```

<a name="NewOpenAIChatModel"></a>
## func [NewOpenAIChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L167>)

```go
func NewOpenAIChatModel(model, apiKey string, opts ...iface.Option) (iface.ChatModel, error)
```

NewOpenAIChatModel creates a new OpenAI chat model instance. This is a convenience function for creating OpenAI-specific models.

Parameters:

- model: OpenAI model name (e.g., "gpt-4", "gpt-3.5-turbo")
- apiKey: OpenAI API key
- opts: Optional configuration functions

Returns:

- OpenAI chat model instance
- Error if initialization fails

Example:

```
model, err := chatmodels.NewOpenAIChatModel("gpt-4", "your-api-key",
	chatmodels.WithTemperature(0.7),
)
```

<a name="RunLoadTest"></a>
## func [RunLoadTest](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L628>)

```go
func RunLoadTest(t *testing.T, chatModel *AdvancedMockChatModel, numOperations, concurrency int)
```

RunLoadTest executes a load test scenario on chat model.

<a name="StreamMessages"></a>
## func [StreamMessages](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L384>)

```go
func StreamMessages(ctx context.Context, model iface.ChatModel, messages []schema.Message, opts ...iface.Option) (<-chan schema.Message, error)
```

StreamMessages is a convenience function for streaming messages with a chat model. This wraps the model's StreamMessages method for easier usage.

Parameters:

- ctx: Context for cancellation and timeout control
- model: Chat model instance
- messages: Input messages
- opts: Optional streaming options

Returns:

- Channel of streaming messages
- Error if streaming fails

Example:

```
stream, err := chatmodels.StreamMessages(ctx, model, messages)
if err != nil {
	log.Fatal(err)
}
for msg := range stream {
	fmt.Println("Received:", msg.GetContent())
}
```

<a name="ValidateConfig"></a>
## func [ValidateConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L238>)

```go
func ValidateConfig(config *Config) error
```

ValidateConfig validates a chat model configuration. This ensures the configuration is complete and contains valid values.

Parameters:

- config: Configuration to validate

Returns:

- Error if validation fails, nil otherwise

Example:

```
config := chatmodels.DefaultConfig()
if err := chatmodels.ValidateConfig(config); err != nil {
	log.Fatal("Invalid config:", err)
}
```

<a name="WithFunctionCalling"></a>
## func [WithFunctionCalling](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L117>)

```go
func WithFunctionCalling(enabled bool) iface.Option
```

WithFunctionCalling enables or disables function calling.

<a name="WithMaxRetries"></a>
## func [WithMaxRetries](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L137>)

```go
func WithMaxRetries(retries int) iface.Option
```

WithMaxRetries sets the maximum number of retries.

<a name="WithMaxTokens"></a>
## func [WithMaxTokens](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L77>)

```go
func WithMaxTokens(maxTokens int) iface.Option
```

WithMaxTokens sets the maximum number of tokens to generate.

<a name="WithMetrics"></a>
## func [WithMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L147>)

```go
func WithMetrics(enabled bool) iface.Option
```

WithMetrics enables or disables metrics collection.

<a name="WithStopSequences"></a>
## func [WithStopSequences](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L97>)

```go
func WithStopSequences(sequences []string) iface.Option
```

WithStopSequences sets the stop sequences for generation.

<a name="WithSystemPrompt"></a>
## func [WithSystemPrompt](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L107>)

```go
func WithSystemPrompt(prompt string) iface.Option
```

WithSystemPrompt sets the system prompt.

<a name="WithTemperature"></a>
## func [WithTemperature](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L67>)

```go
func WithTemperature(temp float32) iface.Option
```

WithTemperature sets the temperature for response generation.

<a name="WithTimeout"></a>
## func [WithTimeout](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L127>)

```go
func WithTimeout(timeout time.Duration) iface.Option
```

WithTimeout sets the timeout for operations.

<a name="WithTopP"></a>
## func [WithTopP](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L87>)

```go
func WithTopP(topP float32) iface.Option
```

WithTopP sets the nucleus sampling parameter.

<a name="WithTracing"></a>
## func [WithTracing](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L157>)

```go
func WithTracing(enabled bool) iface.Option
```

WithTracing enables or disables tracing.

<a name="AdvancedMockChatModel"></a>
## type [AdvancedMockChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L62-L78>)

AdvancedMockChatModel provides a comprehensive mock implementation for testing.

```go
type AdvancedMockChatModel struct {
    mock.Mock
    // contains filtered or unexported fields
}
```

<a name="NewAdvancedMockChatModel"></a>
### func [NewAdvancedMockChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L81>)

```go
func NewAdvancedMockChatModel(modelName, providerName string, options ...MockChatModelOption) *AdvancedMockChatModel
```

NewAdvancedMockChatModel creates a new advanced mock with configurable behavior.

<a name="AdvancedMockChatModel.Batch"></a>
### func (*AdvancedMockChatModel) [Batch](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L239>)

```go
func (m *AdvancedMockChatModel) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error)
```

<a name="AdvancedMockChatModel.BindTools"></a>
### func (*AdvancedMockChatModel) [BindTools](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L362>)

```go
func (m *AdvancedMockChatModel) BindTools(toolsToBind []tools.Tool) llmsiface.ChatModel
```

<a name="AdvancedMockChatModel.CheckHealth"></a>
### func (*AdvancedMockChatModel) [CheckHealth](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L387>)

```go
func (m *AdvancedMockChatModel) CheckHealth() map[string]any
```

<a name="AdvancedMockChatModel.Generate"></a>
### func (*AdvancedMockChatModel) [Generate](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L275>)

```go
func (m *AdvancedMockChatModel) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error)
```

Mock implementation methods for ChatModel interface.

<a name="AdvancedMockChatModel.GenerateMessages"></a>
### func (*AdvancedMockChatModel) [GenerateMessages](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L401>)

```go
func (m *AdvancedMockChatModel) GenerateMessages(ctx context.Context, messages []schema.Message, options ...core.Option) ([]schema.Message, error)
```

GenerateMessages implements iface.ChatModel interface.

<a name="AdvancedMockChatModel.GetCallCount"></a>
### func (*AdvancedMockChatModel) [GetCallCount](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L447>)

```go
func (m *AdvancedMockChatModel) GetCallCount() int
```

Additional helper methods for testing.

<a name="AdvancedMockChatModel.GetConversationHistory"></a>
### func (*AdvancedMockChatModel) [GetConversationHistory](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L453>)

```go
func (m *AdvancedMockChatModel) GetConversationHistory() []schema.Message
```

<a name="AdvancedMockChatModel.GetModelInfo"></a>
### func (*AdvancedMockChatModel) [GetModelInfo](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L436>)

```go
func (m *AdvancedMockChatModel) GetModelInfo() iface.ModelInfo
```

GetModelInfo implements iface.ChatModel interface.

<a name="AdvancedMockChatModel.GetModelName"></a>
### func (*AdvancedMockChatModel) [GetModelName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L379>)

```go
func (m *AdvancedMockChatModel) GetModelName() string
```

<a name="AdvancedMockChatModel.GetProviderName"></a>
### func (*AdvancedMockChatModel) [GetProviderName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L383>)

```go
func (m *AdvancedMockChatModel) GetProviderName() string
```

<a name="AdvancedMockChatModel.Invoke"></a>
### func (*AdvancedMockChatModel) [Invoke](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L222>)

```go
func (m *AdvancedMockChatModel) Invoke(ctx context.Context, input any, options ...core.Option) (any, error)
```

Mock implementation methods for core.Runnable interface.

<a name="AdvancedMockChatModel.ResetConversation"></a>
### func (*AdvancedMockChatModel) [ResetConversation](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L461>)

```go
func (m *AdvancedMockChatModel) ResetConversation()
```

<a name="AdvancedMockChatModel.Stream"></a>
### func (*AdvancedMockChatModel) [Stream](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L251>)

```go
func (m *AdvancedMockChatModel) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error)
```

<a name="AdvancedMockChatModel.StreamChat"></a>
### func (*AdvancedMockChatModel) [StreamChat](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L315>)

```go
func (m *AdvancedMockChatModel) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan llmsiface.AIMessageChunk, error)
```

<a name="AdvancedMockChatModel.StreamMessages"></a>
### func (*AdvancedMockChatModel) [StreamMessages](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L410>)

```go
func (m *AdvancedMockChatModel) StreamMessages(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan schema.Message, error)
```

StreamMessages implements iface.ChatModel interface.

<a name="AdvancedMockcomponent"></a>
## type [AdvancedMockcomponent](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/advanced_mock.go#L8-L10>)

AdvancedMockcomponent is a mock implementation of Interface.

```go
type AdvancedMockcomponent struct {
    mock.Mock
}
```

<a name="NewAdvancedMockcomponent"></a>
### func [NewAdvancedMockcomponent](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/advanced_mock.go#L13>)

```go
func NewAdvancedMockcomponent() *AdvancedMockcomponent
```

NewAdvancedMockcomponent creates a new AdvancedMockcomponent.

<a name="BenchmarkHelper"></a>
## type [BenchmarkHelper](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L779-L782>)

BenchmarkHelper provides benchmarking utilities for chat models.

```go
type BenchmarkHelper struct {
    // contains filtered or unexported fields
}
```

<a name="NewBenchmarkHelper"></a>
### func [NewBenchmarkHelper](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L784>)

```go
func NewBenchmarkHelper(chatModel llmsiface.ChatModel, conversationCount int) *BenchmarkHelper
```

<a name="BenchmarkHelper.BenchmarkGeneration"></a>
### func (*BenchmarkHelper) [BenchmarkGeneration](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L796>)

```go
func (b *BenchmarkHelper) BenchmarkGeneration(iterations int) (time.Duration, error)
```

<a name="BenchmarkHelper.BenchmarkStreaming"></a>
### func (*BenchmarkHelper) [BenchmarkStreaming](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L811>)

```go
func (b *BenchmarkHelper) BenchmarkStreaming(iterations int) (time.Duration, error)
```

<a name="ChatModelError"></a>
## type [ChatModelError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L11-L16>)

ChatModelError represents a custom error type for chat model operations. It includes context about the operation that failed and wraps the underlying error. This follows the standard Beluga AI error pattern with Op/Err/Code.

```go
type ChatModelError struct {
    Op     string
    Err    error
    Code   string
    Fields map[string]any
}
```

<a name="NewChatModelError"></a>
### func [NewChatModelError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L60>)

```go
func NewChatModelError(op, model, provider, code string, err error) *ChatModelError
```

NewChatModelError creates a new ChatModelError. This follows the standard Beluga AI error pattern with Op/Err/Code. Model and provider are stored in Fields for error message formatting.

<a name="ChatModelError.Error"></a>
### func (*ChatModelError) [Error](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L19>)

```go
func (e *ChatModelError) Error() string
```

Error implements the error interface.

<a name="ChatModelError.Unwrap"></a>
### func (*ChatModelError) [Unwrap](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L34>)

```go
func (e *ChatModelError) Unwrap() error
```

Unwrap returns the underlying error for error wrapping.

<a name="ChatModelError.WithField"></a>
### func (*ChatModelError) [WithField](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L77>)

```go
func (e *ChatModelError) WithField(key string, value any) *ChatModelError
```

WithField adds a context field to the error.

<a name="ChatModelScenarioRunner"></a>
## type [ChatModelScenarioRunner](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L713-L715>)

ChatModelScenarioRunner runs common chat model scenarios.

```go
type ChatModelScenarioRunner struct {
    // contains filtered or unexported fields
}
```

<a name="NewChatModelScenarioRunner"></a>
### func [NewChatModelScenarioRunner](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L717>)

```go
func NewChatModelScenarioRunner(chatModel llmsiface.ChatModel) *ChatModelScenarioRunner
```

<a name="ChatModelScenarioRunner.RunConversationScenario"></a>
### func (*ChatModelScenarioRunner) [RunConversationScenario](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L723>)

```go
func (r *ChatModelScenarioRunner) RunConversationScenario(ctx context.Context, turns int) error
```

<a name="ChatModelScenarioRunner.RunStreamingScenario"></a>
### func (*ChatModelScenarioRunner) [RunStreamingScenario](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L744>)

```go
func (r *ChatModelScenarioRunner) RunStreamingScenario(ctx context.Context, queries []string) error
```

<a name="ConcurrentTestRunner"></a>
## type [ConcurrentTestRunner](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L569-L573>)

ConcurrentTestRunner runs chat model tests concurrently for performance testing.

```go
type ConcurrentTestRunner struct {
    NumGoroutines int
    TestDuration  time.Duration
    // contains filtered or unexported fields
}
```

<a name="NewConcurrentTestRunner"></a>
### func [NewConcurrentTestRunner](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L575>)

```go
func NewConcurrentTestRunner(numGoroutines int, duration time.Duration, testFunc func() error) *ConcurrentTestRunner
```

<a name="ConcurrentTestRunner.Run"></a>
### func (*ConcurrentTestRunner) [Run](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L583>)

```go
func (r *ConcurrentTestRunner) Run() error
```

<a name="Config"></a>
## type [Config](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L17-L42>)

Config represents the configuration for the chatmodels package. It includes settings for model behavior, generation parameters, and observability.

```go
type Config struct {
    Providers               map[string]any `mapstructure:"providers" yaml:"providers"`
    DefaultSystemPrompt     string         `mapstructure:"default_system_prompt" yaml:"default_system_prompt" env:"CHATMODEL_DEFAULT_SYSTEM_PROMPT"`
    DefaultProvider         string         `mapstructure:"default_provider" yaml:"default_provider" env:"CHATMODEL_DEFAULT_PROVIDER" default:"openai"`
    TracingServiceName      string         `mapstructure:"tracing_service_name" yaml:"tracing_service_name" env:"CHATMODEL_TRACING_SERVICE_NAME" default:"beluga-chatmodels"`
    MetricsPrefix           string         `mapstructure:"metrics_prefix" yaml:"metrics_prefix" env:"CHATMODEL_METRICS_PREFIX" default:"beluga_chatmodels"`
    DefaultModel            string         `mapstructure:"default_model" yaml:"default_model" env:"CHATMODEL_DEFAULT_MODEL" default:"gpt-3.5-turbo"`
    DefaultStopSequences    []string       `mapstructure:"default_stop_sequences" yaml:"default_stop_sequences" env:"CHATMODEL_DEFAULT_STOP_SEQUENCES"`
    RetryBackoffFactor      float64        `mapstructure:"retry_backoff_factor" yaml:"retry_backoff_factor" env:"CHATMODEL_RETRY_BACKOFF_FACTOR" validate:"gt=0" default:"2.0"`
    MaxConcurrentRequests   int            `mapstructure:"max_concurrent_requests" yaml:"max_concurrent_requests" env:"CHATMODEL_MAX_CONCURRENT_REQUESTS" validate:"gt=0" default:"100"`
    DefaultMaxRetries       int            `mapstructure:"default_max_retries" yaml:"default_max_retries" env:"CHATMODEL_DEFAULT_MAX_RETRIES" validate:"gte=0" default:"3"`
    DefaultRetryDelay       time.Duration  `mapstructure:"default_retry_delay" yaml:"default_retry_delay" env:"CHATMODEL_DEFAULT_RETRY_DELAY" validate:"gt=0" default:"2s"`
    MaxRetryDelay           time.Duration  `mapstructure:"max_retry_delay" yaml:"max_retry_delay" env:"CHATMODEL_MAX_RETRY_DELAY" validate:"gt=0" default:"30s"`
    ConnectionTimeout       time.Duration  `mapstructure:"connection_timeout" yaml:"connection_timeout" env:"CHATMODEL_CONNECTION_TIMEOUT" validate:"gt=0" default:"10s"`
    RequestTimeout          time.Duration  `mapstructure:"request_timeout" yaml:"request_timeout" env:"CHATMODEL_REQUEST_TIMEOUT" validate:"gt=0" default:"2m"`
    StreamTimeout           time.Duration  `mapstructure:"stream_timeout" yaml:"stream_timeout" env:"CHATMODEL_STREAM_TIMEOUT" validate:"gt=0" default:"5m"`
    DefaultTimeout          time.Duration  `mapstructure:"default_timeout" yaml:"default_timeout" env:"CHATMODEL_DEFAULT_TIMEOUT" validate:"gt=0" default:"30s"`
    DefaultMaxTokens        int            `mapstructure:"default_max_tokens" yaml:"default_max_tokens" env:"CHATMODEL_DEFAULT_MAX_TOKENS" validate:"gt=0" default:"1000"`
    StreamBufferSize        int            `mapstructure:"stream_buffer_size" yaml:"stream_buffer_size" env:"CHATMODEL_STREAM_BUFFER_SIZE" validate:"gt=0" default:"100"`
    DefaultTopP             float32        `mapstructure:"default_top_p" yaml:"default_top_p" env:"CHATMODEL_DEFAULT_TOP_P" validate:"gte=0,lte=1" default:"1.0"`
    DefaultTemperature      float32        `mapstructure:"default_temperature" yaml:"default_temperature" env:"CHATMODEL_DEFAULT_TEMPERATURE" validate:"gte=0,lte=2" default:"0.7"`
    DefaultStreamingEnabled bool           `mapstructure:"default_streaming_enabled" yaml:"default_streaming_enabled" env:"CHATMODEL_DEFAULT_STREAMING_ENABLED" default:"false"`
    EnableTracing           bool           `mapstructure:"enable_tracing" yaml:"enable_tracing" env:"CHATMODEL_ENABLE_TRACING" default:"true"`
    DefaultFunctionCalling  bool           `mapstructure:"default_function_calling" yaml:"default_function_calling" env:"CHATMODEL_DEFAULT_FUNCTION_CALLING" default:"false"`
    EnableMetrics           bool           `mapstructure:"enable_metrics" yaml:"enable_metrics" env:"CHATMODEL_ENABLE_METRICS" default:"true"`
}
```

<a name="CreateTestChatModelConfig"></a>
### func [CreateTestChatModelConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L489>)

```go
func CreateTestChatModelConfig() Config
```

CreateTestChatModelConfig creates a test chat model configuration.

<a name="DefaultConfig"></a>
### func [DefaultConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L167>)

```go
func DefaultConfig() *Config
```

DefaultConfig returns a default configuration for the chatmodels package.

<a name="NewDefaultConfig"></a>
### func [NewDefaultConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L219>)

```go
func NewDefaultConfig() *Config
```

NewDefaultConfig creates a new configuration instance with default values. This provides sensible defaults for most use cases while allowing customization. Defaults include: temperature 0.7, max tokens 2000, timeout 30s, retries 3.

Returns:

- *Config: Configuration instance with defaults

Example:

```
config := chatmodels.NewDefaultConfig()
config.DefaultTemperature = 0.8
config.DefaultMaxTokens = 1000
model, err := chatmodels.NewChatModel("gpt-4", config)
```

Example usage can be found in examples/chatmodels/basic/main.go

<a name="Config.GetDefaultProvider"></a>
### func (*Config) [GetDefaultProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L46>)

```go
func (c *Config) GetDefaultProvider() string
```

GetDefaultProvider returns the default provider name. This method implements ConfigProvider interface to avoid import cycles.

<a name="Config.GetProviderConfig"></a>
### func (*Config) [GetProviderConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L227>)

```go
func (c *Config) GetProviderConfig(provider string) (*ProviderConfig, error)
```

GetProviderConfig returns the configuration for a specific provider.

<a name="Config.Validate"></a>
### func (*Config) [Validate](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L197>)

```go
func (c *Config) Validate() error
```

Validate validates the configuration and returns an error if invalid.

<a name="ConfigProvider"></a>
## type [ConfigProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L11-L13>)

ConfigProvider is an interface for getting the default provider name. This interface is used by the registry to avoid import cycles.

```go
type ConfigProvider interface {
    GetDefaultProvider() string
}
```

<a name="GenerationError"></a>
## type [GenerationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L131-L137>)

GenerationError represents errors that occur during message generation.

```go
type GenerationError struct {
    Err        error
    Model      string
    Suggestion string
    Messages   int
    Tokens     int
}
```

<a name="NewGenerationError"></a>
### func [NewGenerationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L158>)

```go
func NewGenerationError(model string, messages int, err error) *GenerationError
```

NewGenerationError creates a new GenerationError.

<a name="GenerationError.Error"></a>
### func (*GenerationError) [Error](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L140>)

```go
func (e *GenerationError) Error() string
```

Error implements the error interface.

<a name="GenerationError.Unwrap"></a>
### func (*GenerationError) [Unwrap](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L153>)

```go
func (e *GenerationError) Unwrap() error
```

Unwrap returns the underlying error.

<a name="GenerationError.WithSuggestion"></a>
### func (*GenerationError) [WithSuggestion](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L173>)

```go
func (e *GenerationError) WithSuggestion(suggestion string) *GenerationError
```

WithSuggestion adds a suggestion to help resolve the generation error.

<a name="GenerationError.WithTokenCount"></a>
### func (*GenerationError) [WithTokenCount](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L167>)

```go
func (e *GenerationError) WithTokenCount(tokens int) *GenerationError
```

WithTokenCount adds token count information to the error.

<a name="IntegrationTestHelper"></a>
## type [IntegrationTestHelper](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L687-L689>)

IntegrationTestHelper provides utilities for integration testing.

```go
type IntegrationTestHelper struct {
    // contains filtered or unexported fields
}
```

<a name="NewIntegrationTestHelper"></a>
### func [NewIntegrationTestHelper](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L691>)

```go
func NewIntegrationTestHelper() *IntegrationTestHelper
```

<a name="IntegrationTestHelper.AddChatModel"></a>
### func (*IntegrationTestHelper) [AddChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L697>)

```go
func (h *IntegrationTestHelper) AddChatModel(name string, chatModel *AdvancedMockChatModel)
```

<a name="IntegrationTestHelper.GetChatModel"></a>
### func (*IntegrationTestHelper) [GetChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L701>)

```go
func (h *IntegrationTestHelper) GetChatModel(name string) *AdvancedMockChatModel
```

<a name="IntegrationTestHelper.Reset"></a>
### func (*IntegrationTestHelper) [Reset](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L705>)

```go
func (h *IntegrationTestHelper) Reset()
```

<a name="Metrics"></a>
## type [Metrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L26-L54>)

Metrics holds the metrics for the chatmodels package.

```go
type Metrics struct {
    // contains filtered or unexported fields
}
```

<a name="DefaultMetrics"></a>
### func [DefaultMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L448>)

```go
func DefaultMetrics() *Metrics
```

DefaultMetrics creates a metrics instance with default meter and tracer. Deprecated: Use InitMetrics(meter) and GetMetrics() instead for consistency.

<a name="GetMetrics"></a>
### func [GetMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L442>)

```go
func GetMetrics() *Metrics
```

GetMetrics returns the global metrics instance. This follows the standard pattern used across all Beluga AI packages.

<a name="NewMetrics"></a>
### func [NewMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L57>)

```go
func NewMetrics(meter metric.Meter, tracer trace.Tracer) (*Metrics, error)
```

NewMetrics creates a new Metrics instance with OpenTelemetry metrics.

<a name="NoOpMetrics"></a>
### func [NoOpMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L461>)

```go
func NoOpMetrics() *Metrics
```

NoOpMetrics returns a metrics instance that does nothing. Useful for testing or when metrics are disabled.

<a name="Metrics.RecordMessageGeneration"></a>
### func (*Metrics) [RecordMessageGeneration](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L208>)

```go
func (m *Metrics) RecordMessageGeneration(model, provider string, duration time.Duration, success bool, tokenCount int)
```

Message generation metrics.

<a name="Metrics.RecordMessageGenerationError"></a>
### func (*Metrics) [RecordMessageGenerationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L236>)

```go
func (m *Metrics) RecordMessageGenerationError(model, provider, errorType string)
```

<a name="Metrics.RecordModelError"></a>
### func (*Metrics) [RecordModelError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L377>)

```go
func (m *Metrics) RecordModelError(model, provider, errorType string)
```

<a name="Metrics.RecordModelRequest"></a>
### func (*Metrics) [RecordModelRequest](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L354>)

```go
func (m *Metrics) RecordModelRequest(model, provider string, duration time.Duration, success bool)
```

Model metrics.

<a name="Metrics.RecordProviderError"></a>
### func (*Metrics) [RecordProviderError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L339>)

```go
func (m *Metrics) RecordProviderError(provider, errorType string)
```

<a name="Metrics.RecordProviderRequest"></a>
### func (*Metrics) [RecordProviderRequest](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L317>)

```go
func (m *Metrics) RecordProviderRequest(provider string, duration time.Duration, success bool)
```

Provider metrics.

<a name="Metrics.RecordStreamingError"></a>
### func (*Metrics) [RecordStreamingError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L280>)

```go
func (m *Metrics) RecordStreamingError(model, provider, errorType string)
```

<a name="Metrics.RecordStreamingSession"></a>
### func (*Metrics) [RecordStreamingSession](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L252>)

```go
func (m *Metrics) RecordStreamingSession(model, provider string, duration time.Duration, success bool, messageCount int)
```

Streaming metrics.

<a name="Metrics.RecordTokenUsage"></a>
### func (*Metrics) [RecordTokenUsage](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L296>)

```go
func (m *Metrics) RecordTokenUsage(model, provider string, tokensGenerated, tokensConsumed int)
```

Token metrics.

<a name="Metrics.StartGenerationSpan"></a>
### func (*Metrics) [StartGenerationSpan](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L394>)

```go
func (m *Metrics) StartGenerationSpan(ctx context.Context, model, provider, operation string) (context.Context, trace.Span)
```

Tracing helpers. Spans returned by these methods must be ended by the caller using span.End().

<a name="Metrics.StartProviderSpan"></a>
### func (*Metrics) [StartProviderSpan](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L414>)

```go
func (m *Metrics) StartProviderSpan(ctx context.Context, provider, operation string) (context.Context, trace.Span)
```

<a name="Metrics.StartStreamingSpan"></a>
### func (*Metrics) [StartStreamingSpan](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L404>)

```go
func (m *Metrics) StartStreamingSpan(ctx context.Context, model, provider string) (context.Context, trace.Span)
```

<a name="MockChatModelOption"></a>
## type [MockChatModelOption](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L108>)

MockChatModelOption defines functional options for mock configuration.

```go
type MockChatModelOption func(*AdvancedMockChatModel)
```

<a name="WithConversationHistory"></a>
### func [WithConversationHistory](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L214>)

```go
func WithConversationHistory(messages []schema.Message) MockChatModelOption
```

WithConversationHistory preloads conversation history.

<a name="WithMockAuthenticationError"></a>
### func [WithMockAuthenticationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L142>)

```go
func WithMockAuthenticationError() MockChatModelOption
```

WithMockAuthenticationError configures the mock to return an authentication error.

<a name="WithMockError"></a>
### func [WithMockError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L111>)

```go
func WithMockError(shouldError bool, err error) MockChatModelOption
```

WithMockError configures the mock to return errors.

<a name="WithMockErrorCode"></a>
### func [WithMockErrorCode](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L119>)

```go
func WithMockErrorCode(code string) MockChatModelOption
```

WithMockErrorCode configures the mock to return a specific error code.

<a name="WithMockGenerationError"></a>
### func [WithMockGenerationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L152>)

```go
func WithMockGenerationError() MockChatModelOption
```

WithMockGenerationError configures the mock to return a generation error.

<a name="WithMockInvalidInputError"></a>
### func [WithMockInvalidInputError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L162>)

```go
func WithMockInvalidInputError() MockChatModelOption
```

WithMockInvalidInputError configures the mock to return an invalid input error.

<a name="WithMockInvalidResponseError"></a>
### func [WithMockInvalidResponseError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L172>)

```go
func WithMockInvalidResponseError() MockChatModelOption
```

WithMockInvalidResponseError configures the mock to return an invalid response error.

<a name="WithMockMaxRetriesError"></a>
### func [WithMockMaxRetriesError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L167>)

```go
func WithMockMaxRetriesError() MockChatModelOption
```

WithMockMaxRetriesError configures the mock to return a max retries error.

<a name="WithMockModelNotFoundError"></a>
### func [WithMockModelNotFoundError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L177>)

```go
func WithMockModelNotFoundError() MockChatModelOption
```

WithMockModelNotFoundError configures the mock to return a model not found error.

<a name="WithMockNetworkError"></a>
### func [WithMockNetworkError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L137>)

```go
func WithMockNetworkError() MockChatModelOption
```

WithMockNetworkError configures the mock to return a network error.

<a name="WithMockProviderNotSupportedError"></a>
### func [WithMockProviderNotSupportedError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L182>)

```go
func WithMockProviderNotSupportedError() MockChatModelOption
```

WithMockProviderNotSupportedError configures the mock to return a provider not supported error.

<a name="WithMockQuotaError"></a>
### func [WithMockQuotaError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L147>)

```go
func WithMockQuotaError() MockChatModelOption
```

WithMockQuotaError configures the mock to return a quota error.

<a name="WithMockRateLimitError"></a>
### func [WithMockRateLimitError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L127>)

```go
func WithMockRateLimitError() MockChatModelOption
```

WithMockRateLimitError configures the mock to return a rate limit error.

<a name="WithMockResourceExhaustedError"></a>
### func [WithMockResourceExhaustedError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L187>)

```go
func WithMockResourceExhaustedError() MockChatModelOption
```

WithMockResourceExhaustedError configures the mock to return a resource exhausted error.

<a name="WithMockResponses"></a>
### func [WithMockResponses](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L192>)

```go
func WithMockResponses(responses []schema.Message) MockChatModelOption
```

WithMockResponses sets predefined responses for the mock.

<a name="WithMockStreamingError"></a>
### func [WithMockStreamingError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L157>)

```go
func WithMockStreamingError() MockChatModelOption
```

WithMockStreamingError configures the mock to return a streaming error.

<a name="WithMockTimeoutError"></a>
### func [WithMockTimeoutError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L132>)

```go
func WithMockTimeoutError() MockChatModelOption
```

WithMockTimeoutError configures the mock to return a timeout error.

<a name="WithStreamingDelay"></a>
### func [WithStreamingDelay](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L200>)

```go
func WithStreamingDelay(delay time.Duration) MockChatModelOption
```

WithStreamingDelay adds artificial delay to mock operations.

<a name="WithToolsSupport"></a>
### func [WithToolsSupport](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L207>)

```go
func WithToolsSupport(supported bool) MockChatModelOption
```

WithToolsSupport configures whether the mock supports tools.

<a name="ProviderConfig"></a>
## type [ProviderConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L51-L57>)

ProviderConfig represents configuration for a specific provider.

```go
type ProviderConfig struct {
    APIKey     string          `mapstructure:"api_key" yaml:"api_key" env:"CHATMODEL_PROVIDER_API_KEY"`
    BaseURL    string          `mapstructure:"base_url" yaml:"base_url" env:"CHATMODEL_PROVIDER_BASE_URL"`
    Timeout    time.Duration   `mapstructure:"timeout" yaml:"timeout" env:"CHATMODEL_PROVIDER_TIMEOUT" validate:"gt=0" default:"30s"`
    MaxRetries int             `mapstructure:"max_retries" yaml:"max_retries" env:"CHATMODEL_PROVIDER_MAX_RETRIES" validate:"gte=0" default:"3"`
    RateLimit  RateLimitConfig `mapstructure:"rate_limit" yaml:"rate_limit"`
}
```

<a name="ProviderError"></a>
## type [ProviderError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L105-L109>)

ProviderError represents errors that occur with specific providers.

```go
type ProviderError struct {
    Err       error
    Provider  string
    Operation string
}
```

<a name="NewProviderError"></a>
### func [NewProviderError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L122>)

```go
func NewProviderError(provider, operation string, err error) *ProviderError
```

NewProviderError creates a new ProviderError.

<a name="ProviderError.Error"></a>
### func (*ProviderError) [Error](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L112>)

```go
func (e *ProviderError) Error() string
```

Error implements the error interface.

<a name="ProviderError.Unwrap"></a>
### func (*ProviderError) [Unwrap](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L117>)

```go
func (e *ProviderError) Unwrap() error
```

Unwrap returns the underlying error.

<a name="RateLimitConfig"></a>
## type [RateLimitConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L60-L64>)

RateLimitConfig represents rate limiting configuration.

```go
type RateLimitConfig struct {
    RequestsPerMinute int `mapstructure:"requests_per_minute" yaml:"requests_per_minute" env:"CHATMODEL_RATE_LIMIT_REQUESTS_PER_MINUTE" validate:"gt=0" default:"60"`
    RequestsPerHour   int `mapstructure:"requests_per_hour" yaml:"requests_per_hour" env:"CHATMODEL_RATE_LIMIT_REQUESTS_PER_HOUR" validate:"gt=0" default:"1000"`
    BurstSize         int `mapstructure:"burst_size" yaml:"burst_size" env:"CHATMODEL_RATE_LIMIT_BURST_SIZE" validate:"gt=0" default:"10"`
}
```

<a name="StreamingError"></a>
## type [StreamingError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L179-L183>)

StreamingError represents errors that occur during streaming operations.

```go
type StreamingError struct {
    Err      error
    Model    string
    Duration string
}
```

<a name="NewStreamingError"></a>
### func [NewStreamingError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L201>)

```go
func NewStreamingError(model string, err error) *StreamingError
```

NewStreamingError creates a new StreamingError.

<a name="StreamingError.Error"></a>
### func (*StreamingError) [Error](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L186>)

```go
func (e *StreamingError) Error() string
```

Error implements the error interface.

<a name="StreamingError.Unwrap"></a>
### func (*StreamingError) [Unwrap](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L196>)

```go
func (e *StreamingError) Unwrap() error
```

Unwrap returns the underlying error.

<a name="StreamingError.WithDuration"></a>
### func (*StreamingError) [WithDuration](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L209>)

```go
func (e *StreamingError) WithDuration(duration string) *StreamingError
```

WithDuration adds duration information to the streaming error.

<a name="ValidationError"></a>
## type [ValidationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L86-L89>)

ValidationError represents configuration validation errors.

```go
type ValidationError struct {
    Field   string
    Message string
}
```

<a name="NewValidationError"></a>
### func [NewValidationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L97>)

```go
func NewValidationError(field, message string) *ValidationError
```

NewValidationError creates a new ValidationError.

<a name="ValidationError.Error"></a>
### func (*ValidationError) [Error](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L92>)

```go
func (e *ValidationError) Error() string
```

Error implements the error interface.

Generated by [gomarkdoc](<https://github.com/princjef/gomarkdoc>)

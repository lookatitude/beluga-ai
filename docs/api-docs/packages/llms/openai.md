---
title: openai
sidebar_position: 1
---

<!-- Code generated by gomarkdoc. DO NOT EDIT -->


# openai

```go
import "github.com/lookatitude/beluga-ai/pkg/llms/providers/openai"
```

Package openai provides an implementation of the llms.ChatModel interface using the OpenAI API (GPT models).

## Index

- [Constants](<#constants>)
- [`func NewOpenAIProviderFactory() func(*llms.Config) (iface.ChatModel, error)`](<#NewOpenAIProviderFactory>)
- [type AdvancedMockOpenAIProvider](<#AdvancedMockOpenAIProvider>)
  - [`func NewAdvancedMockOpenAIProvider(modelName string) *AdvancedMockOpenAIProvider`](<#NewAdvancedMockOpenAIProvider>)
  - [`func (m *AdvancedMockOpenAIProvider) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error)`](<#AdvancedMockOpenAIProvider.Batch>)
  - [`func (m *AdvancedMockOpenAIProvider) BindTools(toolsToBind []tools.Tool) iface.ChatModel`](<#AdvancedMockOpenAIProvider.BindTools>)
  - [`func (m *AdvancedMockOpenAIProvider) CheckHealth() map[string]any`](<#AdvancedMockOpenAIProvider.CheckHealth>)
  - [`func (m *AdvancedMockOpenAIProvider) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error)`](<#AdvancedMockOpenAIProvider.Generate>)
  - [`func (m *AdvancedMockOpenAIProvider) GetCallCount() int`](<#AdvancedMockOpenAIProvider.GetCallCount>)
  - [`func (m *AdvancedMockOpenAIProvider) GetModelName() string`](<#AdvancedMockOpenAIProvider.GetModelName>)
  - [`func (m *AdvancedMockOpenAIProvider) GetProviderName() string`](<#AdvancedMockOpenAIProvider.GetProviderName>)
  - [`func (m *AdvancedMockOpenAIProvider) Invoke(ctx context.Context, input any, options ...core.Option) (any, error)`](<#AdvancedMockOpenAIProvider.Invoke>)
  - [`func (m *AdvancedMockOpenAIProvider) Reset()`](<#AdvancedMockOpenAIProvider.Reset>)
  - [`func (m *AdvancedMockOpenAIProvider) SetDelay(delay time.Duration)`](<#AdvancedMockOpenAIProvider.SetDelay>)
  - [`func (m *AdvancedMockOpenAIProvider) SetError(shouldError bool, err error)`](<#AdvancedMockOpenAIProvider.SetError>)
  - [`func (m *AdvancedMockOpenAIProvider) SetRateLimit(enabled bool)`](<#AdvancedMockOpenAIProvider.SetRateLimit>)
  - [`func (m *AdvancedMockOpenAIProvider) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error)`](<#AdvancedMockOpenAIProvider.Stream>)
  - [`func (m *AdvancedMockOpenAIProvider) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan iface.AIMessageChunk, error)`](<#AdvancedMockOpenAIProvider.StreamChat>)
- [type OpenAIProvider](<#OpenAIProvider>)
  - [`func NewOpenAIProvider(config *llms.Config) (*OpenAIProvider, error)`](<#NewOpenAIProvider>)
  - [`func (o *OpenAIProvider) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error)`](<#OpenAIProvider.Batch>)
  - [`func (o *OpenAIProvider) BindTools(toolsToBind []tools.Tool) iface.ChatModel`](<#OpenAIProvider.BindTools>)
  - [`func (o *OpenAIProvider) CheckHealth() map[string]any`](<#OpenAIProvider.CheckHealth>)
  - [`func (o *OpenAIProvider) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error)`](<#OpenAIProvider.Generate>)
  - [`func (o *OpenAIProvider) GetModelName() string`](<#OpenAIProvider.GetModelName>)
  - [`func (o *OpenAIProvider) GetProviderName() string`](<#OpenAIProvider.GetProviderName>)
  - [`func (o *OpenAIProvider) Invoke(ctx context.Context, input any, options ...core.Option) (any, error)`](<#OpenAIProvider.Invoke>)
  - [`func (o *OpenAIProvider) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error)`](<#OpenAIProvider.Stream>)
  - [`func (o *OpenAIProvider) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan iface.AIMessageChunk, error)`](<#OpenAIProvider.StreamChat>)

## Constants

<a name="ProviderName"></a>Provider constants.

```go
const (
    ProviderName = "openai"
    DefaultModel = "gpt-3.5-turbo"

    // Error codes specific to OpenAI.
    ErrCodeInvalidAPIKey  = "openai_invalid_api_key"
    ErrCodeRateLimit      = "openai_rate_limit"
    ErrCodeModelNotFound  = "openai_model_not_found"
    ErrCodeInvalidRequest = "openai_invalid_request"
    ErrCodeQuotaExceeded  = "openai_quota_exceeded"
)
```

<a name="NewOpenAIProviderFactory"></a>
## func [NewOpenAIProviderFactory](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L627>)

```go
func NewOpenAIProviderFactory() func(*llms.Config) (iface.ChatModel, error)
```

NewOpenAIProviderFactory returns a factory function for creating OpenAI providers. This is used for registering the provider with the LLM factory pattern.

Returns:

- func(*llms.Config) (iface.ChatModel, error): Factory function that creates OpenAI providers

Example:

```
factory := llms.NewFactory()
factory.RegisterProviderFactory("openai", openai.NewOpenAIProviderFactory())
provider, err := factory.CreateProvider("openai", config)
```

Example usage can be found in examples/llm-usage/main.go

<a name="AdvancedMockOpenAIProvider"></a>
## type [AdvancedMockOpenAIProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L18-L30>)

AdvancedMockOpenAIProvider provides a comprehensive mock implementation for testing OpenAI provider.

```go
type AdvancedMockOpenAIProvider struct {
    // contains filtered or unexported fields
}
```

<a name="NewAdvancedMockOpenAIProvider"></a>
### func [NewAdvancedMockOpenAIProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L33>)

```go
func NewAdvancedMockOpenAIProvider(modelName string) *AdvancedMockOpenAIProvider
```

NewAdvancedMockOpenAIProvider creates a new advanced mock with configurable behavior.

<a name="AdvancedMockOpenAIProvider.Batch"></a>
### func (*AdvancedMockOpenAIProvider) [Batch](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L158>)

```go
func (m *AdvancedMockOpenAIProvider) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error)
```

Batch implements the Runnable interface.

<a name="AdvancedMockOpenAIProvider.BindTools"></a>
### func (*AdvancedMockOpenAIProvider) [BindTools](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L131>)

```go
func (m *AdvancedMockOpenAIProvider) BindTools(toolsToBind []tools.Tool) iface.ChatModel
```

BindTools implements the ChatModel interface.

<a name="AdvancedMockOpenAIProvider.CheckHealth"></a>
### func (*AdvancedMockOpenAIProvider) [CheckHealth](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L198>)

```go
func (m *AdvancedMockOpenAIProvider) CheckHealth() map[string]any
```

CheckHealth implements the ChatModel interface.

<a name="AdvancedMockOpenAIProvider.Generate"></a>
### func (*AdvancedMockOpenAIProvider) [Generate](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L47>)

```go
func (m *AdvancedMockOpenAIProvider) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error)
```

Generate implements the ChatModel interface.

<a name="AdvancedMockOpenAIProvider.GetCallCount"></a>
### func (*AdvancedMockOpenAIProvider) [GetCallCount](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L232>)

```go
func (m *AdvancedMockOpenAIProvider) GetCallCount() int
```

GetCallCount returns the number of times methods have been called.

<a name="AdvancedMockOpenAIProvider.GetModelName"></a>
### func (*AdvancedMockOpenAIProvider) [GetModelName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L139>)

```go
func (m *AdvancedMockOpenAIProvider) GetModelName() string
```

GetModelName implements the ChatModel interface.

<a name="AdvancedMockOpenAIProvider.GetProviderName"></a>
### func (*AdvancedMockOpenAIProvider) [GetProviderName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L144>)

```go
func (m *AdvancedMockOpenAIProvider) GetProviderName() string
```

GetProviderName implements the LLM interface.

<a name="AdvancedMockOpenAIProvider.Invoke"></a>
### func (*AdvancedMockOpenAIProvider) [Invoke](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L149>)

```go
func (m *AdvancedMockOpenAIProvider) Invoke(ctx context.Context, input any, options ...core.Option) (any, error)
```

Invoke implements the Runnable interface.

<a name="AdvancedMockOpenAIProvider.Reset"></a>
### func (*AdvancedMockOpenAIProvider) [Reset](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L239>)

```go
func (m *AdvancedMockOpenAIProvider) Reset()
```

Reset resets the mock state.

<a name="AdvancedMockOpenAIProvider.SetDelay"></a>
### func (*AdvancedMockOpenAIProvider) [SetDelay](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L218>)

```go
func (m *AdvancedMockOpenAIProvider) SetDelay(delay time.Duration)
```

SetDelay configures the mock to simulate delay.

<a name="AdvancedMockOpenAIProvider.SetError"></a>
### func (*AdvancedMockOpenAIProvider) [SetError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L210>)

```go
func (m *AdvancedMockOpenAIProvider) SetError(shouldError bool, err error)
```

SetError configures the mock to return an error.

<a name="AdvancedMockOpenAIProvider.SetRateLimit"></a>
### func (*AdvancedMockOpenAIProvider) [SetRateLimit](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L225>)

```go
func (m *AdvancedMockOpenAIProvider) SetRateLimit(enabled bool)
```

SetRateLimit configures the mock to simulate rate limiting.

<a name="AdvancedMockOpenAIProvider.Stream"></a>
### func (*AdvancedMockOpenAIProvider) [Stream](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L171>)

```go
func (m *AdvancedMockOpenAIProvider) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error)
```

Stream implements the Runnable interface.

<a name="AdvancedMockOpenAIProvider.StreamChat"></a>
### func (*AdvancedMockOpenAIProvider) [StreamChat](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/openai_mock.go#L84>)

```go
func (m *AdvancedMockOpenAIProvider) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan iface.AIMessageChunk, error)
```

StreamChat implements the ChatModel interface.

<a name="OpenAIProvider"></a>
## type [OpenAIProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L37-L45>)

OpenAIProvider implements the ChatModel interface for OpenAI GPT models.

```go
type OpenAIProvider struct {
    // contains filtered or unexported fields
}
```

<a name="NewOpenAIProvider"></a>
### func [NewOpenAIProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L70>)

```go
func NewOpenAIProvider(config *llms.Config) (*OpenAIProvider, error)
```

NewOpenAIProvider creates a new OpenAI provider instance. This provider implements the ChatModel interface for OpenAI GPT models (GPT-3.5, GPT-4, etc.).

Parameters:

- config: LLM configuration containing API key, model name, and other settings

Returns:

- *OpenAIProvider: A new OpenAI provider instance ready to use
- error: Configuration validation errors or client creation errors

Example:

```
config := &llms.Config{
    APIKey:    "your-api-key",
    ModelName: "gpt-4",
}
provider, err := openai.NewOpenAIProvider(config)
if err != nil {
    log.Fatal(err)
}
response, err := provider.Generate(ctx, messages)
```

Example usage can be found in examples/llm-usage/main.go

<a name="OpenAIProvider.Batch"></a>
### func (*OpenAIProvider) [Batch](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L198>)

```go
func (o *OpenAIProvider) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error)
```

Batch implements the Runnable interface.

<a name="OpenAIProvider.BindTools"></a>
### func (*OpenAIProvider) [BindTools](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L172>)

```go
func (o *OpenAIProvider) BindTools(toolsToBind []tools.Tool) iface.ChatModel
```

BindTools implements the ChatModel interface.

<a name="OpenAIProvider.CheckHealth"></a>
### func (*OpenAIProvider) [CheckHealth](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L603>)

```go
func (o *OpenAIProvider) CheckHealth() map[string]any
```

CheckHealth implements the HealthChecker interface.

<a name="OpenAIProvider.Generate"></a>
### func (*OpenAIProvider) [Generate](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L112>)

```go
func (o *OpenAIProvider) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error)
```

Generate implements the ChatModel interface.

<a name="OpenAIProvider.GetModelName"></a>
### func (*OpenAIProvider) [GetModelName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L180>)

```go
func (o *OpenAIProvider) GetModelName() string
```

GetModelName implements the ChatModel interface.

<a name="OpenAIProvider.GetProviderName"></a>
### func (*OpenAIProvider) [GetProviderName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L184>)

```go
func (o *OpenAIProvider) GetProviderName() string
```

<a name="OpenAIProvider.Invoke"></a>
### func (*OpenAIProvider) [Invoke](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L189>)

```go
func (o *OpenAIProvider) Invoke(ctx context.Context, input any, options ...core.Option) (any, error)
```

Invoke implements the Runnable interface.

<a name="OpenAIProvider.Stream"></a>
### func (*OpenAIProvider) [Stream](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L238>)

```go
func (o *OpenAIProvider) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error)
```

Stream implements the Runnable interface.

<a name="OpenAIProvider.StreamChat"></a>
### func (*OpenAIProvider) [StreamChat](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L154>)

```go
func (o *OpenAIProvider) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan iface.AIMessageChunk, error)
```

StreamChat implements the ChatModel interface.

Generated by [gomarkdoc](<https://github.com/princjef/gomarkdoc>)

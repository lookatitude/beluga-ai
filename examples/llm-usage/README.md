# Beluga AI LLM Package Usage Example

This example application demonstrates how to use the refactored Beluga AI LLM package following the framework's design patterns.

## Features Demonstrated

- âœ… **Factory Pattern**: Provider registration and management
- âœ… **Configuration Management**: Functional options and validation
- âœ… **Error Handling**: Custom error types and retry logic
- âœ… **Streaming Responses**: Real-time response handling
- âœ… **Batch Processing**: Concurrent request processing
- âœ… **Tool Calling**: Function calling capabilities
- âœ… **Observability**: Metrics and tracing integration
- âœ… **Utility Functions**: Helper functions for common tasks

## Running the Example

### Prerequisites

1. Go 1.24 or later
2. Access to the Beluga AI Framework

### Installation

```bash
# Navigate to the example directory
cd examples/llm-usage

# Download dependencies
go mod tidy

# Run the example
go run main.go
```

### Expected Output

```
ğŸ”„ Beluga AI LLM Package Usage Example
=====================================

ğŸ“‹ Example 1: Basic Factory Usage
Creating factory and registering mock provider...
âœ… Factory created successfully
âœ… Mock configuration created
ğŸ“Š Available provider types: [anthropic openai bedrock mock]

âš™ï¸  Example 2: Configuration Management
Demonstrating configuration patterns...
âœ… Anthropic configuration validated successfully
âœ… OpenAI configuration validated successfully
âœ… Mock configuration validated successfully
âœ… Configuration merging demonstrated

ğŸš¨ Example 3: Error Handling
Demonstrating error handling patterns...
âœ… Error configuration created
âœ… LLM Error detected: rate_limit
âœ… Is retryable: true
   rate_limit: retryable=true
   authentication_error: retryable=false
   invalid_request: retryable=true
   network_error: retryable=true
   internal_error: retryable=true

ğŸŒŠ Example 4: Streaming Responses
Demonstrating streaming responses...
ğŸ“ Created 2 messages for streaming
âœ… Streaming example prepared (would work with real providers)
ğŸ’¡ Streaming usage pattern:
   streamChan, err := provider.StreamChat(ctx, messages)
   for chunk := range streamChan {
       if chunk.Err != nil { handle error }
       fmt.Print(chunk.Content) // Print as it arrives
   }

ğŸ“¦ Example 5: Batch Processing
Demonstrating batch processing...
ğŸ“¦ Prepared 4 batch inputs
âœ… Batch processing example prepared
ğŸ’¡ Batch processing benefits:
   - Concurrent processing of multiple requests
   - Automatic error handling per request
   - Configurable concurrency limits
   - Efficient resource utilization

ğŸ› ï¸  Example 6: Tool Calling (Mock)
Demonstrating tool calling...
ğŸ› ï¸  Created 2 messages for tool calling
âœ… Tool calling example prepared
ğŸ’¡ Tool calling workflow:
   1. Create tools: calculator, webSearch, etc.
   2. Bind to provider: provider.BindTools(tools)
   3. Generate: response, err := provider.Generate(ctx, messages)
   4. Handle tool calls from response.ToolCalls
   5. Execute tools and continue conversation

ğŸ”§ Example 7: Utility Functions
Testing EnsureMessages utility...
âœ… String converted to 1 messages
âœ… Message slice handled correctly
Testing GetSystemAndHumanPrompts utility...
âœ… System prompt: You are a helpful assistant.
âœ… Human prompts: What is AI?How does it work?
Testing ValidateModelName utility...
âœ… Model gpt-4 validated for provider openai
âœ… Model claude-3-sonnet validated for provider anthropic

ğŸ“Š Example 8: Metrics and Observability
Recording sample metrics...
âœ… Recorded request metrics
âœ… Recorded token usage (100 input, 50 output)
âœ… Incremented active request counter
ğŸ“ˆ Current metrics:
   Total requests: 1
   Total errors: 0
   Total token usage: 150
   Active requests: 1
ğŸ’¡ In production, these metrics would be exported to:
   - Prometheus for monitoring
   - Jaeger/Grafana for tracing
   - ELK stack for logging

ğŸ“„ Example 9: Configuration File Pattern
Example configuration file structure (YAML):
[configuration example shown]

âœ¨ All examples completed successfully!
```

## Architecture Overview

The example demonstrates the clean architecture of the refactored LLM package:

```
examples/llm-usage/
â”œâ”€â”€ main.go           # Main application demonstrating all features
â”œâ”€â”€ go.mod            # Go module dependencies
â””â”€â”€ README.md         # This documentation
```

## Key Concepts Demonstrated

### 1. Factory Pattern
```go
factory := llms.NewFactory()
// Register providers
// Create providers using factory
```

### 2. Configuration Management
```go
config := llms.NewConfig(
    llms.WithProvider("anthropic"),
    llms.WithModelName("claude-3-sonnet"),
    llms.WithAPIKey("your-key"),
    llms.WithTemperature(0.7),
)
```

### 3. Error Handling
```go
if llms.IsLLMError(err) {
    code := llms.GetLLMErrorCode(err)
    if llms.IsRetryableError(err) {
        // Implement retry logic
    }
}
```

### 4. Streaming
```go
streamChan, err := provider.StreamChat(ctx, messages)
for chunk := range streamChan {
    fmt.Print(chunk.Content)
}
```

### 5. Tool Calling
```go
modelWithTools := provider.BindTools(tools)
response, err := modelWithTools.Generate(ctx, messages)
// Handle tool calls from response.ToolCalls
```

## Production Usage

For production deployments, you would:

1. **Set up proper configuration files** (YAML/JSON)
2. **Initialize OpenTelemetry** for observability
3. **Implement proper error handling** with retries
4. **Set up monitoring** with Prometheus/Grafana
5. **Configure logging** with structured logging
6. **Implement health checks** and graceful shutdown

## Next Steps

After running this example, you can:

1. **Explore the actual provider implementations** in `pkg/llms/providers/`
2. **Check the comprehensive documentation** in `pkg/llms/README.md`
3. **Review the test examples** in `pkg/llms/llms_test.go`
4. **Study the configuration patterns** in `pkg/llms/config.go`
5. **Examine the error handling** in `pkg/llms/errors.go`

## Contributing

This example serves as a reference implementation. To contribute:

1. Add new examples demonstrating advanced features
2. Improve error handling demonstrations
3. Add performance benchmarking examples
4. Create examples for specific provider integrations
5. Add configuration file parsing examples

## License

This example is part of the Beluga AI Framework and follows the same license terms.

---
title: chatmodels
sidebar_position: 1
---

<!-- Code generated by gomarkdoc. DO NOT EDIT -->


# chatmodels

```go
import "github.com/lookatitude/beluga-ai/pkg/chatmodels"
```

Package chatmodels provides chat\-based language model implementations following the Beluga AI Framework design patterns.

This package implements chat models that can handle conversation\-like interactions with various providers. It follows SOLID principles with dependency inversion, interface segregation, and composition over inheritance.

Key Features:

- Multiple provider support \(OpenAI, Anthropic, local models\)
- Streaming and non\-streaming message generation
- Comprehensive error handling with custom error types
- Observability with OpenTelemetry tracing and metrics
- Configurable generation with retry logic and timeouts
- Health checking and model information

Basic Usage:

```
// Create a chat model
config := chatmodels.DefaultConfig()
config.DefaultProvider = "openai"
model, err := chatmodels.NewChatModel("gpt-4", config)

// Generate messages
messages := []schema.Message{
	{Role: "user", Content: "Hello, how are you?"},
}
response, err := model.GenerateMessages(ctx, messages)
```

Advanced Usage:

```
// Create with custom configuration
model, err := chatmodels.NewChatModel("gpt-4", config,
	chatmodels.WithTemperature(0.8),
	chatmodels.WithMaxTokens(2000),
	chatmodels.WithFunctionCalling(true),
)

// Use streaming
stream, err := model.StreamMessages(ctx, messages)
for msg := range stream {
	fmt.Println("Received:", msg.Content)
}
```

Package chatmodels provides advanced test utilities and comprehensive mocks for testing chat model implementations. This file contains utilities designed to support both unit tests and integration tests.

## Index

- [Constants](<#constants>)
- [Variables](<#variables>)
- [func AssertChatModelHealth\(t \*testing.T, health map\[string\]interface\{\}, expectedStatus string\)](<#AssertChatModelHealth>)
- [func AssertChatResponse\(t \*testing.T, response schema.Message, expectedMinLength int\)](<#AssertChatResponse>)
- [func AssertConversationFlow\(t \*testing.T, history \[\]schema.Message, expectedMinLength int\)](<#AssertConversationFlow>)
- [func AssertErrorType\(t \*testing.T, err error, expectedCode string\)](<#AssertErrorType>)
- [func AssertStreamingResponse\(t \*testing.T, chunks \[\]llmsiface.AIMessageChunk, expectedMinChunks int\)](<#AssertStreamingResponse>)
- [func CreateTestMessages\(conversationLength int\) \[\]schema.Message](<#CreateTestMessages>)
- [func GenerateMessages\(ctx context.Context, model iface.ChatModel, messages \[\]schema.Message, opts ...iface.Option\) \(\[\]schema.Message, error\)](<#GenerateMessages>)
- [func GetModelInfo\(model iface.ChatModel\) iface.ModelInfo](<#GetModelInfo>)
- [func GetSupportedModels\(provider string\) \[\]string](<#GetSupportedModels>)
- [func GetSupportedProviders\(\) \[\]string](<#GetSupportedProviders>)
- [func HealthCheck\(model iface.ChatModel\) map\[string\]interface\{\}](<#HealthCheck>)
- [func IsAuthenticationError\(err error\) bool](<#IsAuthenticationError>)
- [func IsGenerationError\(err error\) bool](<#IsGenerationError>)
- [func IsProviderError\(err error\) bool](<#IsProviderError>)
- [func IsQuotaError\(err error\) bool](<#IsQuotaError>)
- [func IsRetryable\(err error\) bool](<#IsRetryable>)
- [func IsStreamingError\(err error\) bool](<#IsStreamingError>)
- [func IsValidationError\(err error\) bool](<#IsValidationError>)
- [func NewChatModel\(model string, config \*Config, opts ...iface.Option\) \(iface.ChatModel, error\)](<#NewChatModel>)
- [func NewMockChatModel\(model string, opts ...iface.Option\) \(iface.ChatModel, error\)](<#NewMockChatModel>)
- [func NewOpenAIChatModel\(model, apiKey string, opts ...iface.Option\) \(iface.ChatModel, error\)](<#NewOpenAIChatModel>)
- [func RunLoadTest\(t \*testing.T, chatModel \*AdvancedMockChatModel, numOperations int, concurrency int\)](<#RunLoadTest>)
- [func StreamMessages\(ctx context.Context, model iface.ChatModel, messages \[\]schema.Message, opts ...iface.Option\) \(\<\-chan schema.Message, error\)](<#StreamMessages>)
- [func ValidateConfig\(config \*Config\) error](<#ValidateConfig>)
- [func WithFunctionCalling\(enabled bool\) iface.Option](<#WithFunctionCalling>)
- [func WithMaxRetries\(retries int\) iface.Option](<#WithMaxRetries>)
- [func WithMaxTokens\(maxTokens int\) iface.Option](<#WithMaxTokens>)
- [func WithMetrics\(enabled bool\) iface.Option](<#WithMetrics>)
- [func WithStopSequences\(sequences \[\]string\) iface.Option](<#WithStopSequences>)
- [func WithSystemPrompt\(prompt string\) iface.Option](<#WithSystemPrompt>)
- [func WithTemperature\(temp float32\) iface.Option](<#WithTemperature>)
- [func WithTimeout\(timeout time.Duration\) iface.Option](<#WithTimeout>)
- [func WithTopP\(topP float32\) iface.Option](<#WithTopP>)
- [func WithTracing\(enabled bool\) iface.Option](<#WithTracing>)
- [type AdvancedMockChatModel](<#AdvancedMockChatModel>)
  - [func NewAdvancedMockChatModel\(modelName, providerName string, options ...MockChatModelOption\) \*AdvancedMockChatModel](<#NewAdvancedMockChatModel>)
  - [func \(m \*AdvancedMockChatModel\) Batch\(ctx context.Context, inputs \[\]any, options ...core.Option\) \(\[\]any, error\)](<#AdvancedMockChatModel.Batch>)
  - [func \(m \*AdvancedMockChatModel\) BindTools\(toolsToBind \[\]tools.Tool\) llmsiface.ChatModel](<#AdvancedMockChatModel.BindTools>)
  - [func \(m \*AdvancedMockChatModel\) CheckHealth\(\) map\[string\]interface\{\}](<#AdvancedMockChatModel.CheckHealth>)
  - [func \(m \*AdvancedMockChatModel\) Generate\(ctx context.Context, messages \[\]schema.Message, options ...core.Option\) \(schema.Message, error\)](<#AdvancedMockChatModel.Generate>)
  - [func \(m \*AdvancedMockChatModel\) GetCallCount\(\) int](<#AdvancedMockChatModel.GetCallCount>)
  - [func \(m \*AdvancedMockChatModel\) GetConversationHistory\(\) \[\]schema.Message](<#AdvancedMockChatModel.GetConversationHistory>)
  - [func \(m \*AdvancedMockChatModel\) GetModelName\(\) string](<#AdvancedMockChatModel.GetModelName>)
  - [func \(m \*AdvancedMockChatModel\) GetProviderName\(\) string](<#AdvancedMockChatModel.GetProviderName>)
  - [func \(m \*AdvancedMockChatModel\) Invoke\(ctx context.Context, input any, options ...core.Option\) \(any, error\)](<#AdvancedMockChatModel.Invoke>)
  - [func \(m \*AdvancedMockChatModel\) ResetConversation\(\)](<#AdvancedMockChatModel.ResetConversation>)
  - [func \(m \*AdvancedMockChatModel\) Stream\(ctx context.Context, input any, options ...core.Option\) \(\<\-chan any, error\)](<#AdvancedMockChatModel.Stream>)
  - [func \(m \*AdvancedMockChatModel\) StreamChat\(ctx context.Context, messages \[\]schema.Message, options ...core.Option\) \(\<\-chan llmsiface.AIMessageChunk, error\)](<#AdvancedMockChatModel.StreamChat>)
- [type BenchmarkHelper](<#BenchmarkHelper>)
  - [func NewBenchmarkHelper\(chatModel llmsiface.ChatModel, conversationCount int\) \*BenchmarkHelper](<#NewBenchmarkHelper>)
  - [func \(b \*BenchmarkHelper\) BenchmarkGeneration\(iterations int\) \(time.Duration, error\)](<#BenchmarkHelper.BenchmarkGeneration>)
  - [func \(b \*BenchmarkHelper\) BenchmarkStreaming\(iterations int\) \(time.Duration, error\)](<#BenchmarkHelper.BenchmarkStreaming>)
- [type ChatModelError](<#ChatModelError>)
  - [func NewChatModelError\(op, model, provider, code string, err error\) \*ChatModelError](<#NewChatModelError>)
  - [func \(e \*ChatModelError\) Error\(\) string](<#ChatModelError.Error>)
  - [func \(e \*ChatModelError\) Unwrap\(\) error](<#ChatModelError.Unwrap>)
  - [func \(e \*ChatModelError\) WithField\(key string, value interface\{\}\) \*ChatModelError](<#ChatModelError.WithField>)
- [type ChatModelScenarioRunner](<#ChatModelScenarioRunner>)
  - [func NewChatModelScenarioRunner\(chatModel llmsiface.ChatModel\) \*ChatModelScenarioRunner](<#NewChatModelScenarioRunner>)
  - [func \(r \*ChatModelScenarioRunner\) RunConversationScenario\(ctx context.Context, turns int\) error](<#ChatModelScenarioRunner.RunConversationScenario>)
  - [func \(r \*ChatModelScenarioRunner\) RunStreamingScenario\(ctx context.Context, queries \[\]string\) error](<#ChatModelScenarioRunner.RunStreamingScenario>)
- [type ConcurrentTestRunner](<#ConcurrentTestRunner>)
  - [func NewConcurrentTestRunner\(numGoroutines int, duration time.Duration, testFunc func\(\) error\) \*ConcurrentTestRunner](<#NewConcurrentTestRunner>)
  - [func \(r \*ConcurrentTestRunner\) Run\(\) error](<#ConcurrentTestRunner.Run>)
- [type Config](<#Config>)
  - [func CreateTestChatModelConfig\(\) Config](<#CreateTestChatModelConfig>)
  - [func DefaultConfig\(\) \*Config](<#DefaultConfig>)
  - [func NewDefaultConfig\(\) \*Config](<#NewDefaultConfig>)
  - [func \(c \*Config\) GetProviderConfig\(provider string\) \(\*ProviderConfig, error\)](<#Config.GetProviderConfig>)
  - [func \(c \*Config\) Validate\(\) error](<#Config.Validate>)
- [type GenerationError](<#GenerationError>)
  - [func NewGenerationError\(model string, messages int, err error\) \*GenerationError](<#NewGenerationError>)
  - [func \(e \*GenerationError\) Error\(\) string](<#GenerationError.Error>)
  - [func \(e \*GenerationError\) Unwrap\(\) error](<#GenerationError.Unwrap>)
  - [func \(e \*GenerationError\) WithSuggestion\(suggestion string\) \*GenerationError](<#GenerationError.WithSuggestion>)
  - [func \(e \*GenerationError\) WithTokenCount\(tokens int\) \*GenerationError](<#GenerationError.WithTokenCount>)
- [type IntegrationTestHelper](<#IntegrationTestHelper>)
  - [func NewIntegrationTestHelper\(\) \*IntegrationTestHelper](<#NewIntegrationTestHelper>)
  - [func \(h \*IntegrationTestHelper\) AddChatModel\(name string, chatModel \*AdvancedMockChatModel\)](<#IntegrationTestHelper.AddChatModel>)
  - [func \(h \*IntegrationTestHelper\) GetChatModel\(name string\) \*AdvancedMockChatModel](<#IntegrationTestHelper.GetChatModel>)
  - [func \(h \*IntegrationTestHelper\) Reset\(\)](<#IntegrationTestHelper.Reset>)
- [type Metrics](<#Metrics>)
  - [func DefaultMetrics\(\) \*Metrics](<#DefaultMetrics>)
  - [func NewMetrics\(meter metric.Meter, tracer trace.Tracer\) \(\*Metrics, error\)](<#NewMetrics>)
  - [func NoOpMetrics\(\) \*Metrics](<#NoOpMetrics>)
  - [func \(m \*Metrics\) RecordMessageGeneration\(model, provider string, duration time.Duration, success bool, tokenCount int\)](<#Metrics.RecordMessageGeneration>)
  - [func \(m \*Metrics\) RecordMessageGenerationError\(model, provider, errorType string\)](<#Metrics.RecordMessageGenerationError>)
  - [func \(m \*Metrics\) RecordModelError\(model, provider, errorType string\)](<#Metrics.RecordModelError>)
  - [func \(m \*Metrics\) RecordModelRequest\(model, provider string, duration time.Duration, success bool\)](<#Metrics.RecordModelRequest>)
  - [func \(m \*Metrics\) RecordProviderError\(provider, errorType string\)](<#Metrics.RecordProviderError>)
  - [func \(m \*Metrics\) RecordProviderRequest\(provider string, duration time.Duration, success bool\)](<#Metrics.RecordProviderRequest>)
  - [func \(m \*Metrics\) RecordStreamingError\(model, provider, errorType string\)](<#Metrics.RecordStreamingError>)
  - [func \(m \*Metrics\) RecordStreamingSession\(model, provider string, duration time.Duration, success bool, messageCount int\)](<#Metrics.RecordStreamingSession>)
  - [func \(m \*Metrics\) RecordTokenUsage\(model, provider string, tokensGenerated, tokensConsumed int\)](<#Metrics.RecordTokenUsage>)
  - [func \(m \*Metrics\) StartGenerationSpan\(ctx context.Context, model, provider, operation string\) \(context.Context, trace.Span\)](<#Metrics.StartGenerationSpan>)
  - [func \(m \*Metrics\) StartProviderSpan\(ctx context.Context, provider, operation string\) \(context.Context, trace.Span\)](<#Metrics.StartProviderSpan>)
  - [func \(m \*Metrics\) StartStreamingSpan\(ctx context.Context, model, provider string\) \(context.Context, trace.Span\)](<#Metrics.StartStreamingSpan>)
- [type MockChatModelOption](<#MockChatModelOption>)
  - [func WithConversationHistory\(messages \[\]schema.Message\) MockChatModelOption](<#WithConversationHistory>)
  - [func WithMockError\(shouldError bool, err error\) MockChatModelOption](<#WithMockError>)
  - [func WithMockResponses\(responses \[\]schema.Message\) MockChatModelOption](<#WithMockResponses>)
  - [func WithStreamingDelay\(delay time.Duration\) MockChatModelOption](<#WithStreamingDelay>)
  - [func WithToolsSupport\(supported bool\) MockChatModelOption](<#WithToolsSupport>)
- [type ProviderConfig](<#ProviderConfig>)
- [type ProviderError](<#ProviderError>)
  - [func NewProviderError\(provider, operation string, err error\) \*ProviderError](<#NewProviderError>)
  - [func \(e \*ProviderError\) Error\(\) string](<#ProviderError.Error>)
  - [func \(e \*ProviderError\) Unwrap\(\) error](<#ProviderError.Unwrap>)
- [type RateLimitConfig](<#RateLimitConfig>)
- [type StreamingError](<#StreamingError>)
  - [func NewStreamingError\(model string, err error\) \*StreamingError](<#NewStreamingError>)
  - [func \(e \*StreamingError\) Error\(\) string](<#StreamingError.Error>)
  - [func \(e \*StreamingError\) Unwrap\(\) error](<#StreamingError.Unwrap>)
  - [func \(e \*StreamingError\) WithDuration\(duration string\) \*StreamingError](<#StreamingError.WithDuration>)
- [type ValidationError](<#ValidationError>)
  - [func NewValidationError\(field, message string\) \*ValidationError](<#NewValidationError>)
  - [func \(e \*ValidationError\) Error\(\) string](<#ValidationError.Error>)

## Constants

<a name="ErrCodeConfigInvalid"></a>Error codes for different types of chat model errors.

```go
const (
    ErrCodeConfigInvalid        = "config_invalid"
    ErrCodeInitialization       = "initialization_failed"
    ErrCodeGeneration           = "generation_failed"
    ErrCodeStreaming            = "streaming_failed"
    ErrCodeRateLimit            = "rate_limit"
    ErrCodeInvalidInput         = "invalid_input"
    ErrCodeNetworkError         = "network_error"
    ErrCodeTimeout              = "timeout"
    ErrCodeMaxRetries           = "max_retries_exceeded"
    ErrCodeInvalidResponse      = "invalid_response"
    ErrCodeModelNotFound        = "model_not_found"
    ErrCodeProviderNotSupported = "provider_not_supported"
    ErrCodeAuthentication       = "authentication_failed"
    ErrCodeQuotaExceeded        = "quota_exceeded"
    ErrCodeResourceExhausted    = "resource_exhausted"
)
```

## Variables

<a name="ErrChatModelNotFound"></a>Common error variables for frequently used errors.

```go
var (
    ErrChatModelNotFound    = errors.New("chat model not found")
    ErrInvalidConfig        = errors.New("invalid configuration")
    ErrProviderNotAvailable = errors.New("provider not available")
    ErrModelNotSupported    = errors.New("model not supported")
    ErrMaxRetriesExceeded   = errors.New("maximum retries exceeded")
    ErrContextCancelled     = errors.New("context cancelled")
    ErrTimeout              = errors.New("operation timed out")
    ErrRateLimitExceeded    = errors.New("rate limit exceeded")
    ErrQuotaExceeded        = errors.New("quota exceeded")
    ErrResourceExhausted    = errors.New("resource exhausted")
    ErrAuthenticationFailed = errors.New("authentication failed")
    ErrNetworkError         = errors.New("network error")
)
```

<a name="AssertChatModelHealth"></a>
## func [AssertChatModelHealth](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L391>)

```go
func AssertChatModelHealth(t *testing.T, health map[string]interface{}, expectedStatus string)
```

AssertChatModelHealth validates chat model health check results

<a name="AssertChatResponse"></a>
## func [AssertChatResponse](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L355>)

```go
func AssertChatResponse(t *testing.T, response schema.Message, expectedMinLength int)
```

AssertChatResponse validates chat model response

<a name="AssertConversationFlow"></a>
## func [AssertConversationFlow](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L376>)

```go
func AssertConversationFlow(t *testing.T, history []schema.Message, expectedMinLength int)
```

AssertConversationFlow validates conversation flow

<a name="AssertErrorType"></a>
## func [AssertErrorType](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L400>)

```go
func AssertErrorType(t *testing.T, err error, expectedCode string)
```

AssertErrorType validates error types and codes

<a name="AssertStreamingResponse"></a>
## func [AssertStreamingResponse](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L363>)

```go
func AssertStreamingResponse(t *testing.T, chunks []llmsiface.AIMessageChunk, expectedMinChunks int)
```

AssertStreamingResponse validates streaming response

<a name="CreateTestMessages"></a>
## func [CreateTestMessages](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L319>)

```go
func CreateTestMessages(conversationLength int) []schema.Message
```

CreateTestMessages creates a set of test messages for chat model testing

<a name="GenerateMessages"></a>
## func [GenerateMessages](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L324>)

```go
func GenerateMessages(ctx context.Context, model iface.ChatModel, messages []schema.Message, opts ...iface.Option) ([]schema.Message, error)
```

GenerateMessages is a convenience function for generating messages with a chat model. This wraps the model's GenerateMessages method for easier usage.

Parameters:

- ctx: Context for cancellation and timeout control
- model: Chat model instance
- messages: Input messages
- opts: Optional generation options

Returns:

- Generated response messages
- Error if generation fails

Example:

```
messages := []schema.Message{
	schema.NewHumanMessage("Hello!"),
}
response, err := chatmodels.GenerateMessages(ctx, model, messages)
```

<a name="GetModelInfo"></a>
## func [GetModelInfo](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L301>)

```go
func GetModelInfo(model iface.ChatModel) iface.ModelInfo
```

GetModelInfo retrieves model information from a chat model.

Parameters:

- model: Chat model instance

Returns:

- Model information struct

Example:

```
info := chatmodels.GetModelInfo(model)
fmt.Printf("Model: %s, Provider: %s\n", info.Name, info.Provider)
```

<a name="GetSupportedModels"></a>
## func [GetSupportedModels](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L259>)

```go
func GetSupportedModels(provider string) []string
```

GetSupportedModels returns a list of supported models for a given provider.

Parameters:

- provider: Provider name

Returns:

- Slice of supported model names

Example:

```
models := chatmodels.GetSupportedModels("openai")
fmt.Printf("OpenAI models: %v\n", models)
```

<a name="GetSupportedProviders"></a>
## func [GetSupportedProviders](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L243>)

```go
func GetSupportedProviders() []string
```

GetSupportedProviders returns a list of supported chat model providers.

Returns:

- Slice of supported provider names

Example:

```
providers := chatmodels.GetSupportedProviders()
fmt.Printf("Supported providers: %v\n", providers)
```

<a name="HealthCheck"></a>
## func [HealthCheck](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L285>)

```go
func HealthCheck(model iface.ChatModel) map[string]interface{}
```

HealthCheck performs a health check on a chat model. This can be used for monitoring and ensuring model availability.

Parameters:

- model: Chat model to check

Returns:

- Health status information

Example:

```
status := chatmodels.HealthCheck(model)
if status["state"] == "error" {
	log.Warn("Model is in error state")
}
```

<a name="IsAuthenticationError"></a>
## func [IsAuthenticationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L264>)

```go
func IsAuthenticationError(err error) bool
```

IsAuthenticationError checks if an error is an authentication error.

<a name="IsGenerationError"></a>
## func [IsGenerationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L252>)

```go
func IsGenerationError(err error) bool
```

IsGenerationError checks if an error is a generation error.

<a name="IsProviderError"></a>
## func [IsProviderError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L246>)

```go
func IsProviderError(err error) bool
```

IsProviderError checks if an error is a provider error.

<a name="IsQuotaError"></a>
## func [IsQuotaError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L273>)

```go
func IsQuotaError(err error) bool
```

IsQuotaError checks if an error is a quota\-related error.

<a name="IsRetryable"></a>
## func [IsRetryable](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L221>)

```go
func IsRetryable(err error) bool
```

IsRetryable checks if an error is retryable.

<a name="IsStreamingError"></a>
## func [IsStreamingError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L258>)

```go
func IsStreamingError(err error) bool
```

IsStreamingError checks if an error is a streaming error.

<a name="IsValidationError"></a>
## func [IsValidationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L240>)

```go
func IsValidationError(err error) bool
```

IsValidationError checks if an error is a validation error.

<a name="NewChatModel"></a>
## func [NewChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L74>)

```go
func NewChatModel(model string, config *Config, opts ...iface.Option) (iface.ChatModel, error)
```

NewChatModel creates a new chat model instance with the specified model name and configuration. This is the main factory function for creating chat models.

Parameters:

- model: The model name/identifier \(e.g., "gpt\-4", "claude\-3"\)
- config: Configuration instance \(use DefaultConfig\(\) for defaults\)
- opts: Optional configuration functions

Returns:

- Chat model instance implementing the ChatModel interface
- Error if initialization fails

Example:

```
config := chatmodels.DefaultConfig()
model, err := chatmodels.NewChatModel("gpt-4", config,
	chatmodels.WithTemperature(0.7),
	chatmodels.WithMaxTokens(1000),
)
```

<a name="NewMockChatModel"></a>
## func [NewMockChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L193>)

```go
func NewMockChatModel(model string, opts ...iface.Option) (iface.ChatModel, error)
```

NewMockChatModel creates a new mock chat model for testing. This creates a chat model that returns predetermined responses.

Parameters:

- model: Model name for the mock
- opts: Optional configuration functions

Returns:

- Mock chat model instance
- Error if initialization fails

Example:

```
model, err := chatmodels.NewMockChatModel("mock-gpt-4",
	chatmodels.WithTemperature(0.5),
)
```

<a name="NewOpenAIChatModel"></a>
## func [NewOpenAIChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L163>)

```go
func NewOpenAIChatModel(model, apiKey string, opts ...iface.Option) (iface.ChatModel, error)
```

NewOpenAIChatModel creates a new OpenAI chat model instance. This is a convenience function for creating OpenAI\-specific models.

Parameters:

- model: OpenAI model name \(e.g., "gpt\-4", "gpt\-3.5\-turbo"\)
- apiKey: OpenAI API key
- opts: Optional configuration functions

Returns:

- OpenAI chat model instance
- Error if initialization fails

Example:

```
model, err := chatmodels.NewOpenAIChatModel("gpt-4", "your-api-key",
	chatmodels.WithTemperature(0.7),
)
```

<a name="RunLoadTest"></a>
## func [RunLoadTest](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L470>)

```go
func RunLoadTest(t *testing.T, chatModel *AdvancedMockChatModel, numOperations int, concurrency int)
```

RunLoadTest executes a load test scenario on chat model

<a name="StreamMessages"></a>
## func [StreamMessages](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L355>)

```go
func StreamMessages(ctx context.Context, model iface.ChatModel, messages []schema.Message, opts ...iface.Option) (<-chan schema.Message, error)
```

StreamMessages is a convenience function for streaming messages with a chat model. This wraps the model's StreamMessages method for easier usage.

Parameters:

- ctx: Context for cancellation and timeout control
- model: Chat model instance
- messages: Input messages
- opts: Optional streaming options

Returns:

- Channel of streaming messages
- Error if streaming fails

Example:

```
stream, err := chatmodels.StreamMessages(ctx, model, messages)
if err != nil {
	log.Fatal(err)
}
for msg := range stream {
	fmt.Println("Received:", msg.GetContent())
}
```

<a name="ValidateConfig"></a>
## func [ValidateConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L230>)

```go
func ValidateConfig(config *Config) error
```

ValidateConfig validates a chat model configuration. This ensures the configuration is complete and contains valid values.

Parameters:

- config: Configuration to validate

Returns:

- Error if validation fails, nil otherwise

Example:

```
config := chatmodels.DefaultConfig()
if err := chatmodels.ValidateConfig(config); err != nil {
	log.Fatal("Invalid config:", err)
}
```

<a name="WithFunctionCalling"></a>
## func [WithFunctionCalling](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L118>)

```go
func WithFunctionCalling(enabled bool) iface.Option
```

WithFunctionCalling enables or disables function calling.

<a name="WithMaxRetries"></a>
## func [WithMaxRetries](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L138>)

```go
func WithMaxRetries(retries int) iface.Option
```

WithMaxRetries sets the maximum number of retries.

<a name="WithMaxTokens"></a>
## func [WithMaxTokens](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L78>)

```go
func WithMaxTokens(maxTokens int) iface.Option
```

WithMaxTokens sets the maximum number of tokens to generate.

<a name="WithMetrics"></a>
## func [WithMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L148>)

```go
func WithMetrics(enabled bool) iface.Option
```

WithMetrics enables or disables metrics collection.

<a name="WithStopSequences"></a>
## func [WithStopSequences](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L98>)

```go
func WithStopSequences(sequences []string) iface.Option
```

WithStopSequences sets the stop sequences for generation.

<a name="WithSystemPrompt"></a>
## func [WithSystemPrompt](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L108>)

```go
func WithSystemPrompt(prompt string) iface.Option
```

WithSystemPrompt sets the system prompt.

<a name="WithTemperature"></a>
## func [WithTemperature](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L68>)

```go
func WithTemperature(temp float32) iface.Option
```

WithTemperature sets the temperature for response generation.

<a name="WithTimeout"></a>
## func [WithTimeout](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L128>)

```go
func WithTimeout(timeout time.Duration) iface.Option
```

WithTimeout sets the timeout for operations.

<a name="WithTopP"></a>
## func [WithTopP](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L88>)

```go
func WithTopP(topP float32) iface.Option
```

WithTopP sets the nucleus sampling parameter.

<a name="WithTracing"></a>
## func [WithTracing](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L158>)

```go
func WithTracing(enabled bool) iface.Option
```

WithTracing enables or disables tracing.

<a name="AdvancedMockChatModel"></a>
## type [AdvancedMockChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L21-L45>)

AdvancedMockChatModel provides a comprehensive mock implementation for testing

```go
type AdvancedMockChatModel struct {
    mock.Mock
    // contains filtered or unexported fields
}
```

<a name="NewAdvancedMockChatModel"></a>
### func [NewAdvancedMockChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L48>)

```go
func NewAdvancedMockChatModel(modelName, providerName string, options ...MockChatModelOption) *AdvancedMockChatModel
```

NewAdvancedMockChatModel creates a new advanced mock with configurable behavior

<a name="AdvancedMockChatModel.Batch"></a>
### func \(\*AdvancedMockChatModel\) [Batch](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L133>)

```go
func (m *AdvancedMockChatModel) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error)
```

<a name="AdvancedMockChatModel.BindTools"></a>
### func \(\*AdvancedMockChatModel\) [BindTools](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L256>)

```go
func (m *AdvancedMockChatModel) BindTools(toolsToBind []tools.Tool) llmsiface.ChatModel
```

<a name="AdvancedMockChatModel.CheckHealth"></a>
### func \(\*AdvancedMockChatModel\) [CheckHealth](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L281>)

```go
func (m *AdvancedMockChatModel) CheckHealth() map[string]interface{}
```

<a name="AdvancedMockChatModel.Generate"></a>
### func \(\*AdvancedMockChatModel\) [Generate](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L169>)

```go
func (m *AdvancedMockChatModel) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error)
```

Mock implementation methods for ChatModel interface

<a name="AdvancedMockChatModel.GetCallCount"></a>
### func \(\*AdvancedMockChatModel\) [GetCallCount](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L295>)

```go
func (m *AdvancedMockChatModel) GetCallCount() int
```

Additional helper methods for testing

<a name="AdvancedMockChatModel.GetConversationHistory"></a>
### func \(\*AdvancedMockChatModel\) [GetConversationHistory](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L301>)

```go
func (m *AdvancedMockChatModel) GetConversationHistory() []schema.Message
```

<a name="AdvancedMockChatModel.GetModelName"></a>
### func \(\*AdvancedMockChatModel\) [GetModelName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L273>)

```go
func (m *AdvancedMockChatModel) GetModelName() string
```

<a name="AdvancedMockChatModel.GetProviderName"></a>
### func \(\*AdvancedMockChatModel\) [GetProviderName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L277>)

```go
func (m *AdvancedMockChatModel) GetProviderName() string
```

<a name="AdvancedMockChatModel.Invoke"></a>
### func \(\*AdvancedMockChatModel\) [Invoke](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L116>)

```go
func (m *AdvancedMockChatModel) Invoke(ctx context.Context, input any, options ...core.Option) (any, error)
```

Mock implementation methods for core.Runnable interface

<a name="AdvancedMockChatModel.ResetConversation"></a>
### func \(\*AdvancedMockChatModel\) [ResetConversation](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L309>)

```go
func (m *AdvancedMockChatModel) ResetConversation()
```

<a name="AdvancedMockChatModel.Stream"></a>
### func \(\*AdvancedMockChatModel\) [Stream](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L145>)

```go
func (m *AdvancedMockChatModel) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error)
```

<a name="AdvancedMockChatModel.StreamChat"></a>
### func \(\*AdvancedMockChatModel\) [StreamChat](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L209>)

```go
func (m *AdvancedMockChatModel) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan llmsiface.AIMessageChunk, error)
```

<a name="BenchmarkHelper"></a>
## type [BenchmarkHelper](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L618-L621>)

BenchmarkHelper provides benchmarking utilities for chat models

```go
type BenchmarkHelper struct {
    // contains filtered or unexported fields
}
```

<a name="NewBenchmarkHelper"></a>
### func [NewBenchmarkHelper](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L623>)

```go
func NewBenchmarkHelper(chatModel llmsiface.ChatModel, conversationCount int) *BenchmarkHelper
```

<a name="BenchmarkHelper.BenchmarkGeneration"></a>
### func \(\*BenchmarkHelper\) [BenchmarkGeneration](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L635>)

```go
func (b *BenchmarkHelper) BenchmarkGeneration(iterations int) (time.Duration, error)
```

<a name="BenchmarkHelper.BenchmarkStreaming"></a>
### func \(\*BenchmarkHelper\) [BenchmarkStreaming](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L650>)

```go
func (b *BenchmarkHelper) BenchmarkStreaming(iterations int) (time.Duration, error)
```

<a name="ChatModelError"></a>
## type [ChatModelError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L10-L17>)

ChatModelError represents a custom error type for chat model operations. It includes context about the operation that failed and wraps the underlying error.

```go
type ChatModelError struct {
    Op       string                 // Operation that failed
    Model    string                 // Model name or ID
    Provider string                 // Provider name
    Code     string                 // Error code for programmatic handling
    Err      error                  // Underlying error
    Fields   map[string]interface{} // Additional context fields
}
```

<a name="NewChatModelError"></a>
### func [NewChatModelError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L55>)

```go
func NewChatModelError(op, model, provider, code string, err error) *ChatModelError
```

NewChatModelError creates a new ChatModelError.

<a name="ChatModelError.Error"></a>
### func \(\*ChatModelError\) [Error](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L20>)

```go
func (e *ChatModelError) Error() string
```

Error implements the error interface.

<a name="ChatModelError.Unwrap"></a>
### func \(\*ChatModelError\) [Unwrap](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L31>)

```go
func (e *ChatModelError) Unwrap() error
```

Unwrap returns the underlying error for error wrapping.

<a name="ChatModelError.WithField"></a>
### func \(\*ChatModelError\) [WithField](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L67>)

```go
func (e *ChatModelError) WithField(key string, value interface{}) *ChatModelError
```

WithField adds a context field to the error.

<a name="ChatModelScenarioRunner"></a>
## type [ChatModelScenarioRunner](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L554-L556>)

ChatModelScenarioRunner runs common chat model scenarios

```go
type ChatModelScenarioRunner struct {
    // contains filtered or unexported fields
}
```

<a name="NewChatModelScenarioRunner"></a>
### func [NewChatModelScenarioRunner](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L558>)

```go
func NewChatModelScenarioRunner(chatModel llmsiface.ChatModel) *ChatModelScenarioRunner
```

<a name="ChatModelScenarioRunner.RunConversationScenario"></a>
### func \(\*ChatModelScenarioRunner\) [RunConversationScenario](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L564>)

```go
func (r *ChatModelScenarioRunner) RunConversationScenario(ctx context.Context, turns int) error
```

<a name="ChatModelScenarioRunner.RunStreamingScenario"></a>
### func \(\*ChatModelScenarioRunner\) [RunStreamingScenario](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L585>)

```go
func (r *ChatModelScenarioRunner) RunStreamingScenario(ctx context.Context, queries []string) error
```

<a name="ConcurrentTestRunner"></a>
## type [ConcurrentTestRunner](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L411-L415>)

ConcurrentTestRunner runs chat model tests concurrently for performance testing

```go
type ConcurrentTestRunner struct {
    NumGoroutines int
    TestDuration  time.Duration
    // contains filtered or unexported fields
}
```

<a name="NewConcurrentTestRunner"></a>
### func [NewConcurrentTestRunner](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L417>)

```go
func NewConcurrentTestRunner(numGoroutines int, duration time.Duration, testFunc func() error) *ConcurrentTestRunner
```

<a name="ConcurrentTestRunner.Run"></a>
### func \(\*ConcurrentTestRunner\) [Run](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L425>)

```go
func (r *ConcurrentTestRunner) Run() error
```

<a name="Config"></a>
## type [Config](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L11-L49>)

Config represents the configuration for the chatmodels package. It includes settings for model behavior, generation parameters, and observability.

```go
type Config struct {
    // Model configuration
    DefaultModel       string        `mapstructure:"default_model" yaml:"default_model" env:"CHATMODEL_DEFAULT_MODEL" default:"gpt-3.5-turbo"`
    DefaultProvider    string        `mapstructure:"default_provider" yaml:"default_provider" env:"CHATMODEL_DEFAULT_PROVIDER" default:"openai"`
    DefaultTemperature float32       `mapstructure:"default_temperature" yaml:"default_temperature" env:"CHATMODEL_DEFAULT_TEMPERATURE" validate:"gte=0,lte=2" default:"0.7"`
    DefaultMaxTokens   int           `mapstructure:"default_max_tokens" yaml:"default_max_tokens" env:"CHATMODEL_DEFAULT_MAX_TOKENS" validate:"gt=0" default:"1000"`
    DefaultTimeout     time.Duration `mapstructure:"default_timeout" yaml:"default_timeout" env:"CHATMODEL_DEFAULT_TIMEOUT" validate:"gt=0" default:"30s"`

    // Generation parameters
    DefaultTopP            float32  `mapstructure:"default_top_p" yaml:"default_top_p" env:"CHATMODEL_DEFAULT_TOP_P" validate:"gte=0,lte=1" default:"1.0"`
    DefaultStopSequences   []string `mapstructure:"default_stop_sequences" yaml:"default_stop_sequences" env:"CHATMODEL_DEFAULT_STOP_SEQUENCES"`
    DefaultSystemPrompt    string   `mapstructure:"default_system_prompt" yaml:"default_system_prompt" env:"CHATMODEL_DEFAULT_SYSTEM_PROMPT"`
    DefaultFunctionCalling bool     `mapstructure:"default_function_calling" yaml:"default_function_calling" env:"CHATMODEL_DEFAULT_FUNCTION_CALLING" default:"false"`

    // Retry and error handling
    DefaultMaxRetries  int           `mapstructure:"default_max_retries" yaml:"default_max_retries" env:"CHATMODEL_DEFAULT_MAX_RETRIES" validate:"gte=0" default:"3"`
    DefaultRetryDelay  time.Duration `mapstructure:"default_retry_delay" yaml:"default_retry_delay" env:"CHATMODEL_DEFAULT_RETRY_DELAY" validate:"gt=0" default:"2s"`
    MaxRetryDelay      time.Duration `mapstructure:"max_retry_delay" yaml:"max_retry_delay" env:"CHATMODEL_MAX_RETRY_DELAY" validate:"gt=0" default:"30s"`
    RetryBackoffFactor float64       `mapstructure:"retry_backoff_factor" yaml:"retry_backoff_factor" env:"CHATMODEL_RETRY_BACKOFF_FACTOR" validate:"gt=0" default:"2.0"`

    // Observability settings
    EnableMetrics      bool   `mapstructure:"enable_metrics" yaml:"enable_metrics" env:"CHATMODEL_ENABLE_METRICS" default:"true"`
    EnableTracing      bool   `mapstructure:"enable_tracing" yaml:"enable_tracing" env:"CHATMODEL_ENABLE_TRACING" default:"true"`
    MetricsPrefix      string `mapstructure:"metrics_prefix" yaml:"metrics_prefix" env:"CHATMODEL_METRICS_PREFIX" default:"beluga_chatmodels"`
    TracingServiceName string `mapstructure:"tracing_service_name" yaml:"tracing_service_name" env:"CHATMODEL_TRACING_SERVICE_NAME" default:"beluga-chatmodels"`

    // Streaming configuration
    DefaultStreamingEnabled bool          `mapstructure:"default_streaming_enabled" yaml:"default_streaming_enabled" env:"CHATMODEL_DEFAULT_STREAMING_ENABLED" default:"false"`
    StreamBufferSize        int           `mapstructure:"stream_buffer_size" yaml:"stream_buffer_size" env:"CHATMODEL_STREAM_BUFFER_SIZE" validate:"gt=0" default:"100"`
    StreamTimeout           time.Duration `mapstructure:"stream_timeout" yaml:"stream_timeout" env:"CHATMODEL_STREAM_TIMEOUT" validate:"gt=0" default:"5m"`

    // Resource limits
    MaxConcurrentRequests int           `mapstructure:"max_concurrent_requests" yaml:"max_concurrent_requests" env:"CHATMODEL_MAX_CONCURRENT_REQUESTS" validate:"gt=0" default:"100"`
    RequestTimeout        time.Duration `mapstructure:"request_timeout" yaml:"request_timeout" env:"CHATMODEL_REQUEST_TIMEOUT" validate:"gt=0" default:"2m"`
    ConnectionTimeout     time.Duration `mapstructure:"connection_timeout" yaml:"connection_timeout" env:"CHATMODEL_CONNECTION_TIMEOUT" validate:"gt=0" default:"10s"`

    // Provider-specific configurations
    Providers map[string]interface{} `mapstructure:"providers" yaml:"providers"`
}
```

<a name="CreateTestChatModelConfig"></a>
### func [CreateTestChatModelConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L337>)

```go
func CreateTestChatModelConfig() Config
```

CreateTestChatModelConfig creates a test chat model configuration

<a name="DefaultConfig"></a>
### func [DefaultConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L168>)

```go
func DefaultConfig() *Config
```

DefaultConfig returns a default configuration for the chatmodels package.

<a name="NewDefaultConfig"></a>
### func [NewDefaultConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L211>)

```go
func NewDefaultConfig() *Config
```

NewDefaultConfig creates a new configuration instance with default values. This provides sensible defaults for most use cases while allowing customization.

Returns:

- Configuration instance with defaults

Example:

```
config := chatmodels.NewDefaultConfig()
config.DefaultTemperature = 0.8
model, err := chatmodels.NewChatModel("gpt-4", config)
```

<a name="Config.GetProviderConfig"></a>
### func \(\*Config\) [GetProviderConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L228>)

```go
func (c *Config) GetProviderConfig(provider string) (*ProviderConfig, error)
```

GetProviderConfig returns the configuration for a specific provider.

<a name="Config.Validate"></a>
### func \(\*Config\) [Validate](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L198>)

```go
func (c *Config) Validate() error
```

Validate validates the configuration and returns an error if invalid.

<a name="GenerationError"></a>
## type [GenerationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L121-L127>)

GenerationError represents errors that occur during message generation.

```go
type GenerationError struct {
    Model      string
    Messages   int // Number of input messages
    Tokens     int // Approximate token count
    Err        error
    Suggestion string // Suggestion for fixing the error
}
```

<a name="NewGenerationError"></a>
### func [NewGenerationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L148>)

```go
func NewGenerationError(model string, messages int, err error) *GenerationError
```

NewGenerationError creates a new GenerationError.

<a name="GenerationError.Error"></a>
### func \(\*GenerationError\) [Error](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L130>)

```go
func (e *GenerationError) Error() string
```

Error implements the error interface.

<a name="GenerationError.Unwrap"></a>
### func \(\*GenerationError\) [Unwrap](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L143>)

```go
func (e *GenerationError) Unwrap() error
```

Unwrap returns the underlying error.

<a name="GenerationError.WithSuggestion"></a>
### func \(\*GenerationError\) [WithSuggestion](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L163>)

```go
func (e *GenerationError) WithSuggestion(suggestion string) *GenerationError
```

WithSuggestion adds a suggestion to help resolve the generation error.

<a name="GenerationError.WithTokenCount"></a>
### func \(\*GenerationError\) [WithTokenCount](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L157>)

```go
func (e *GenerationError) WithTokenCount(tokens int) *GenerationError
```

WithTokenCount adds token count information to the error.

<a name="IntegrationTestHelper"></a>
## type [IntegrationTestHelper](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L528-L530>)

IntegrationTestHelper provides utilities for integration testing

```go
type IntegrationTestHelper struct {
    // contains filtered or unexported fields
}
```

<a name="NewIntegrationTestHelper"></a>
### func [NewIntegrationTestHelper](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L532>)

```go
func NewIntegrationTestHelper() *IntegrationTestHelper
```

<a name="IntegrationTestHelper.AddChatModel"></a>
### func \(\*IntegrationTestHelper\) [AddChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L538>)

```go
func (h *IntegrationTestHelper) AddChatModel(name string, chatModel *AdvancedMockChatModel)
```

<a name="IntegrationTestHelper.GetChatModel"></a>
### func \(\*IntegrationTestHelper\) [GetChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L542>)

```go
func (h *IntegrationTestHelper) GetChatModel(name string) *AdvancedMockChatModel
```

<a name="IntegrationTestHelper.Reset"></a>
### func \(\*IntegrationTestHelper\) [Reset](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L546>)

```go
func (h *IntegrationTestHelper) Reset()
```

<a name="Metrics"></a>
## type [Metrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L17-L45>)

Metrics holds the metrics for the chatmodels package.

```go
type Metrics struct {
    // contains filtered or unexported fields
}
```

<a name="DefaultMetrics"></a>
### func [DefaultMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L411>)

```go
func DefaultMetrics() *Metrics
```

DefaultMetrics creates a metrics instance with default meter and tracer.

<a name="NewMetrics"></a>
### func [NewMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L48>)

```go
func NewMetrics(meter metric.Meter, tracer trace.Tracer) (*Metrics, error)
```

NewMetrics creates a new Metrics instance with OpenTelemetry metrics.

<a name="NoOpMetrics"></a>
### func [NoOpMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L424>)

```go
func NoOpMetrics() *Metrics
```

NoOpMetrics returns a metrics instance that does nothing. Useful for testing or when metrics are disabled.

<a name="Metrics.RecordMessageGeneration"></a>
### func \(\*Metrics\) [RecordMessageGeneration](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L199>)

```go
func (m *Metrics) RecordMessageGeneration(model, provider string, duration time.Duration, success bool, tokenCount int)
```

Message generation metrics

<a name="Metrics.RecordMessageGenerationError"></a>
### func \(\*Metrics\) [RecordMessageGenerationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L227>)

```go
func (m *Metrics) RecordMessageGenerationError(model, provider, errorType string)
```

<a name="Metrics.RecordModelError"></a>
### func \(\*Metrics\) [RecordModelError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L368>)

```go
func (m *Metrics) RecordModelError(model, provider, errorType string)
```

<a name="Metrics.RecordModelRequest"></a>
### func \(\*Metrics\) [RecordModelRequest](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L345>)

```go
func (m *Metrics) RecordModelRequest(model, provider string, duration time.Duration, success bool)
```

Model metrics

<a name="Metrics.RecordProviderError"></a>
### func \(\*Metrics\) [RecordProviderError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L330>)

```go
func (m *Metrics) RecordProviderError(provider, errorType string)
```

<a name="Metrics.RecordProviderRequest"></a>
### func \(\*Metrics\) [RecordProviderRequest](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L308>)

```go
func (m *Metrics) RecordProviderRequest(provider string, duration time.Duration, success bool)
```

Provider metrics

<a name="Metrics.RecordStreamingError"></a>
### func \(\*Metrics\) [RecordStreamingError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L271>)

```go
func (m *Metrics) RecordStreamingError(model, provider, errorType string)
```

<a name="Metrics.RecordStreamingSession"></a>
### func \(\*Metrics\) [RecordStreamingSession](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L243>)

```go
func (m *Metrics) RecordStreamingSession(model, provider string, duration time.Duration, success bool, messageCount int)
```

Streaming metrics

<a name="Metrics.RecordTokenUsage"></a>
### func \(\*Metrics\) [RecordTokenUsage](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L287>)

```go
func (m *Metrics) RecordTokenUsage(model, provider string, tokensGenerated, tokensConsumed int)
```

Token metrics

<a name="Metrics.StartGenerationSpan"></a>
### func \(\*Metrics\) [StartGenerationSpan](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L384>)

```go
func (m *Metrics) StartGenerationSpan(ctx context.Context, model, provider, operation string) (context.Context, trace.Span)
```

Tracing helpers

<a name="Metrics.StartProviderSpan"></a>
### func \(\*Metrics\) [StartProviderSpan](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L402>)

```go
func (m *Metrics) StartProviderSpan(ctx context.Context, provider, operation string) (context.Context, trace.Span)
```

<a name="Metrics.StartStreamingSpan"></a>
### func \(\*Metrics\) [StartStreamingSpan](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L393>)

```go
func (m *Metrics) StartStreamingSpan(ctx context.Context, model, provider string) (context.Context, trace.Span)
```

<a name="MockChatModelOption"></a>
## type [MockChatModelOption](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L75>)

MockChatModelOption defines functional options for mock configuration

```go
type MockChatModelOption func(*AdvancedMockChatModel)
```

<a name="WithConversationHistory"></a>
### func [WithConversationHistory](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L108>)

```go
func WithConversationHistory(messages []schema.Message) MockChatModelOption
```

WithConversationHistory preloads conversation history

<a name="WithMockError"></a>
### func [WithMockError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L78>)

```go
func WithMockError(shouldError bool, err error) MockChatModelOption
```

WithMockError configures the mock to return errors

<a name="WithMockResponses"></a>
### func [WithMockResponses](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L86>)

```go
func WithMockResponses(responses []schema.Message) MockChatModelOption
```

WithMockResponses sets predefined responses for the mock

<a name="WithStreamingDelay"></a>
### func [WithStreamingDelay](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L94>)

```go
func WithStreamingDelay(delay time.Duration) MockChatModelOption
```

WithStreamingDelay adds artificial delay to mock operations

<a name="WithToolsSupport"></a>
### func [WithToolsSupport](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L101>)

```go
func WithToolsSupport(supported bool) MockChatModelOption
```

WithToolsSupport configures whether the mock supports tools

<a name="ProviderConfig"></a>
## type [ProviderConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L52-L58>)

ProviderConfig represents configuration for a specific provider.

```go
type ProviderConfig struct {
    APIKey     string          `mapstructure:"api_key" yaml:"api_key" env:"CHATMODEL_PROVIDER_API_KEY"`
    BaseURL    string          `mapstructure:"base_url" yaml:"base_url" env:"CHATMODEL_PROVIDER_BASE_URL"`
    Timeout    time.Duration   `mapstructure:"timeout" yaml:"timeout" env:"CHATMODEL_PROVIDER_TIMEOUT" validate:"gt=0" default:"30s"`
    MaxRetries int             `mapstructure:"max_retries" yaml:"max_retries" env:"CHATMODEL_PROVIDER_MAX_RETRIES" validate:"gte=0" default:"3"`
    RateLimit  RateLimitConfig `mapstructure:"rate_limit" yaml:"rate_limit"`
}
```

<a name="ProviderError"></a>
## type [ProviderError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L95-L99>)

ProviderError represents errors that occur with specific providers.

```go
type ProviderError struct {
    Provider  string
    Operation string
    Err       error
}
```

<a name="NewProviderError"></a>
### func [NewProviderError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L112>)

```go
func NewProviderError(provider, operation string, err error) *ProviderError
```

NewProviderError creates a new ProviderError.

<a name="ProviderError.Error"></a>
### func \(\*ProviderError\) [Error](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L102>)

```go
func (e *ProviderError) Error() string
```

Error implements the error interface.

<a name="ProviderError.Unwrap"></a>
### func \(\*ProviderError\) [Unwrap](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L107>)

```go
func (e *ProviderError) Unwrap() error
```

Unwrap returns the underlying error.

<a name="RateLimitConfig"></a>
## type [RateLimitConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L61-L65>)

RateLimitConfig represents rate limiting configuration.

```go
type RateLimitConfig struct {
    RequestsPerMinute int `mapstructure:"requests_per_minute" yaml:"requests_per_minute" env:"CHATMODEL_RATE_LIMIT_REQUESTS_PER_MINUTE" validate:"gt=0" default:"60"`
    RequestsPerHour   int `mapstructure:"requests_per_hour" yaml:"requests_per_hour" env:"CHATMODEL_RATE_LIMIT_REQUESTS_PER_HOUR" validate:"gt=0" default:"1000"`
    BurstSize         int `mapstructure:"burst_size" yaml:"burst_size" env:"CHATMODEL_RATE_LIMIT_BURST_SIZE" validate:"gt=0" default:"10"`
}
```

<a name="StreamingError"></a>
## type [StreamingError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L169-L173>)

StreamingError represents errors that occur during streaming operations.

```go
type StreamingError struct {
    Model    string
    Duration string // How long the stream was active
    Err      error
}
```

<a name="NewStreamingError"></a>
### func [NewStreamingError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L191>)

```go
func NewStreamingError(model string, err error) *StreamingError
```

NewStreamingError creates a new StreamingError.

<a name="StreamingError.Error"></a>
### func \(\*StreamingError\) [Error](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L176>)

```go
func (e *StreamingError) Error() string
```

Error implements the error interface.

<a name="StreamingError.Unwrap"></a>
### func \(\*StreamingError\) [Unwrap](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L186>)

```go
func (e *StreamingError) Unwrap() error
```

Unwrap returns the underlying error.

<a name="StreamingError.WithDuration"></a>
### func \(\*StreamingError\) [WithDuration](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L199>)

```go
func (e *StreamingError) WithDuration(duration string) *StreamingError
```

WithDuration adds duration information to the streaming error.

<a name="ValidationError"></a>
## type [ValidationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L76-L79>)

ValidationError represents configuration validation errors.

```go
type ValidationError struct {
    Field   string
    Message string
}
```

<a name="NewValidationError"></a>
### func [NewValidationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L87>)

```go
func NewValidationError(field, message string) *ValidationError
```

NewValidationError creates a new ValidationError.

<a name="ValidationError.Error"></a>
### func \(\*ValidationError\) [Error](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L82>)

```go
func (e *ValidationError) Error() string
```

Error implements the error interface.

Generated by [gomarkdoc](<https://github.com/princjef/gomarkdoc>)

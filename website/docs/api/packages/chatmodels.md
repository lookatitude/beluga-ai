---
title: chatmodels
sidebar_position: 1
---

<!-- Code generated by gomarkdoc. DO NOT EDIT -->


# chatmodels

```go
import "github.com/lookatitude/beluga-ai/pkg/chatmodels"
```

Package chatmodels provides chat\-based language model implementations following the Beluga AI Framework design patterns.

This package implements chat models that can handle conversation\-like interactions with various providers. It follows SOLID principles with dependency inversion, interface segregation, and composition over inheritance.

Key Features:

- Multiple provider support \(OpenAI, Anthropic, local models\)
- Streaming and non\-streaming message generation
- Comprehensive error handling with custom error types
- Observability with OpenTelemetry tracing and metrics
- Configurable generation with retry logic and timeouts
- Health checking and model information

Basic Usage:

```
// Create a chat model
config := chatmodels.DefaultConfig()
config.DefaultProvider = "openai"
model, err := chatmodels.NewChatModel("gpt-4", config)

// Generate messages
:= []schema.Message{
	{Role: "user", Content: "Hello, how are you?"},
}
response, err := model.GenerateMessages(ctx, messages)
```

Advanced Usage:

```
// Create with custom configuration
model, err := chatmodels.NewChatModel("gpt-4", config,
	chatmodels.WithTemperature(0.8),
	chatmodels.WithMaxTokens(2000),
	chatmodels.WithFunctionCalling(true),
)

// Use streaming
stream, err := model.StreamMessages(ctx, messages)
for msg := range stream {
	fmt.Println("Received:", msg.Content)
}
```

Package chatmodels provides advanced test utilities and comprehensive mocks for testing chat model implementations. This file contains utilities designed to support both unit tests and integration tests.

## Index

- [Constants](#constants>)
- [Variables](#variables>)
- [func AssertChatModelHealth\(t \*testing.T, health map\[string\]any, expectedStatus string\)](#AssertChatModelHealth>)
- [func AssertChatResponse\(t \*testing.T, response schema.Message, expectedMinLength int\)](#AssertChatResponse>)
- [func AssertConversationFlow\(t \*testing.T, history \[\]schema.Message, expectedMinLength int\)](#AssertConversationFlow>)
- [func AssertErrorType\(t \*testing.T, err error, expectedCode string\)](#AssertErrorType>)
- [func AssertStreamingResponse\(t \*testing.T, chunks \[\]llmsiface.AIMessageChunk, expectedMinChunks int\)](#AssertStreamingResponse>)
- [func CreateTestMessages\(conversationLength int\) \[\]schema.Message](#CreateTestMessages>)
- [func GenerateMessages\(ctx context.Context, model iface.ChatModel, messages \[\]schema.Message, opts ...iface.Option\) \(\[\]schema.Message, error\)](#GenerateMessages>)
- [func GetModelInfo\(model iface.ChatModel\) iface.ModelInfo](#GetModelInfo>)
- [func GetSupportedModels\(provider string\) \[\]string](#GetSupportedModels>)
- [func GetSupportedProviders\(\) \[\]string](#GetSupportedProviders>)
- [func HealthCheck\(model iface.ChatModel\) map\[string\]any](#HealthCheck>)
- [func IsAuthenticationError\(err error\) bool](#IsAuthenticationError>)
- [func IsGenerationError\(err error\) bool](#IsGenerationError>)
- [func IsProviderError\(err error\) bool](#IsProviderError>)
- [func IsQuotaError\(err error\) bool](#IsQuotaError>)
- [func IsRetryable\(err error\) bool](#IsRetryable>)
- [func IsStreamingError\(err error\) bool](#IsStreamingError>)
- [func IsValidationError\(err error\) bool](#IsValidationError>)
- [func NewChatModel\(model string, config \*Config, opts ...iface.Option\) \(iface.ChatModel, error\)](#NewChatModel>)
- [func NewMockChatModel\(model string, opts ...iface.Option\) \(iface.ChatModel, error\)](#NewMockChatModel>)
- [func NewOpenAIChatModel\(model, apiKey string, opts ...iface.Option\) \(iface.ChatModel, error\)](#NewOpenAIChatModel>)
- [func RunLoadTest\(t \*testing.T, chatModel \*AdvancedMockChatModel, numOperations, concurrency int\)](#RunLoadTest>)
- [func StreamMessages\(ctx context.Context, model iface.ChatModel, messages \[\]schema.Message, opts ...iface.Option\) \(\<\-chan schema.Message, error\)](#StreamMessages>)
- [func ValidateConfig\(config \*Config\) error](#ValidateConfig>)
- [func WithFunctionCalling\(enabled bool\) iface.Option](#WithFunctionCalling>)
- [func WithMaxRetries\(retries int\) iface.Option](#WithMaxRetries>)
- [func WithMaxTokens\(maxTokens int\) iface.Option](#WithMaxTokens>)
- [func WithMetrics\(enabled bool\) iface.Option](#WithMetrics>)
- [func WithStopSequences\(sequences \[\]string\) iface.Option](#WithStopSequences>)
- [func WithSystemPrompt\(prompt string\) iface.Option](#WithSystemPrompt>)
- [func WithTemperature\(temp float32\) iface.Option](#WithTemperature>)
- [func WithTimeout\(timeout time.Duration\) iface.Option](#WithTimeout>)
- [func WithTopP\(topP float32\) iface.Option](#WithTopP>)
- [func WithTracing\(enabled bool\) iface.Option](#WithTracing>)
- [type AdvancedMockChatModel](#AdvancedMockChatModel>)
  - [func NewAdvancedMockChatModel\(modelName, providerName string, options ...MockChatModelOption\) \*AdvancedMockChatModel](#NewAdvancedMockChatModel>)
  - [func \(m \*AdvancedMockChatModel\) Batch\(ctx context.Context, inputs \[\]any, options ...core.Option\) \(\[\]any, error\)](#AdvancedMockChatModel.Batch>)
  - [func \(m \*AdvancedMockChatModel\) BindTools\(toolsToBind \[\]tools.Tool\) llmsiface.ChatModel](#AdvancedMockChatModel.BindTools>)
  - [func \(m \*AdvancedMockChatModel\) CheckHealth\(\) map\[string\]any](#AdvancedMockChatModel.CheckHealth>)
  - [func \(m \*AdvancedMockChatModel\) Generate\(ctx context.Context, messages \[\]schema.Message, options ...core.Option\) \(schema.Message, error\)](#AdvancedMockChatModel.Generate>)
  - [func \(m \*AdvancedMockChatModel\) GetCallCount\(\) int](#AdvancedMockChatModel.GetCallCount>)
  - [func \(m \*AdvancedMockChatModel\) GetConversationHistory\(\) \[\]schema.Message](#AdvancedMockChatModel.GetConversationHistory>)
  - [func \(m \*AdvancedMockChatModel\) GetModelName\(\) string](#AdvancedMockChatModel.GetModelName>)
  - [func \(m \*AdvancedMockChatModel\) GetProviderName\(\) string](#AdvancedMockChatModel.GetProviderName>)
  - [func \(m \*AdvancedMockChatModel\) Invoke\(ctx context.Context, input any, options ...core.Option\) \(any, error\)](#AdvancedMockChatModel.Invoke>)
  - [func \(m \*AdvancedMockChatModel\) ResetConversation\(\)](#AdvancedMockChatModel.ResetConversation>)
  - [func \(m \*AdvancedMockChatModel\) Stream\(ctx context.Context, input any, options ...core.Option\) \(\<\-chan any, error\)](#AdvancedMockChatModel.Stream>)
  - [func \(m \*AdvancedMockChatModel\) StreamChat\(ctx context.Context, messages \[\]schema.Message, options ...core.Option\) \(\<\-chan llmsiface.AIMessageChunk, error\)](#AdvancedMockChatModel.StreamChat>)
- [type AdvancedMockcomponent](#AdvancedMockcomponent>)
  - [func NewAdvancedMockcomponent\(\) \*AdvancedMockcomponent](#NewAdvancedMockcomponent>)
- [type BenchmarkHelper](#BenchmarkHelper>)
  - [func NewBenchmarkHelper\(chatModel llmsiface.ChatModel, conversationCount int\) \*BenchmarkHelper](#NewBenchmarkHelper>)
  - [func \(b \*BenchmarkHelper\) BenchmarkGeneration\(iterations int\) \(time.Duration, error\)](#BenchmarkHelper.BenchmarkGeneration>)
  - [func \(b \*BenchmarkHelper\) BenchmarkStreaming\(iterations int\) \(time.Duration, error\)](#BenchmarkHelper.BenchmarkStreaming>)
- [type ChatModelError](#ChatModelError>)
  - [func NewChatModelError\(op, model, provider, code string, err error\) \*ChatModelError](#NewChatModelError>)
  - [func \(e \*ChatModelError\) Error\(\) string](#ChatModelError.Error>)
  - [func \(e \*ChatModelError\) Unwrap\(\) error](#ChatModelError.Unwrap>)
  - [func \(e \*ChatModelError\) WithField\(key string, value any\) \*ChatModelError](#ChatModelError.WithField>)
- [type ChatModelScenarioRunner](#ChatModelScenarioRunner>)
  - [func NewChatModelScenarioRunner\(chatModel llmsiface.ChatModel\) \*ChatModelScenarioRunner](#NewChatModelScenarioRunner>)
  - [func \(r \*ChatModelScenarioRunner\) RunConversationScenario\(ctx context.Context, turns int\) error](#ChatModelScenarioRunner.RunConversationScenario>)
  - [func \(r \*ChatModelScenarioRunner\) RunStreamingScenario\(ctx context.Context, queries \[\]string\) error](#ChatModelScenarioRunner.RunStreamingScenario>)
- [type ConcurrentTestRunner](#ConcurrentTestRunner>)
  - [func NewConcurrentTestRunner\(numGoroutines int, duration time.Duration, testFunc func\(\) error\) \*ConcurrentTestRunner](#NewConcurrentTestRunner>)
  - [func \(r \*ConcurrentTestRunner\) Run\(\) error](#ConcurrentTestRunner.Run>)
- [type Config](#Config>)
  - [func CreateTestChatModelConfig\(\) Config](#CreateTestChatModelConfig>)
  - [func DefaultConfig\(\) \*Config](#DefaultConfig>)
  - [func NewDefaultConfig\(\) \*Config](#NewDefaultConfig>)
  - [func \(c \*Config\) GetProviderConfig\(provider string\) \(\*ProviderConfig, error\)](#Config.GetProviderConfig>)
  - [func \(c \*Config\) Validate\(\) error](#Config.Validate>)
- [type GenerationError](#GenerationError>)
  - [func NewGenerationError\(model string, messages int, err error\) \*GenerationError](#NewGenerationError>)
  - [func \(e \*GenerationError\) Error\(\) string](#GenerationError.Error>)
  - [func \(e \*GenerationError\) Unwrap\(\) error](#GenerationError.Unwrap>)
  - [func \(e \*GenerationError\) WithSuggestion\(suggestion string\) \*GenerationError](#GenerationError.WithSuggestion>)
  - [func \(e \*GenerationError\) WithTokenCount\(tokens int\) \*GenerationError](#GenerationError.WithTokenCount>)
- [type IntegrationTestHelper](#IntegrationTestHelper>)
  - [func NewIntegrationTestHelper\(\) \*IntegrationTestHelper](#NewIntegrationTestHelper>)
  - [func \(h \*IntegrationTestHelper\) AddChatModel\(name string, chatModel \*AdvancedMockChatModel\)](#IntegrationTestHelper.AddChatModel>)
  - [func \(h \*IntegrationTestHelper\) GetChatModel\(name string\) \*AdvancedMockChatModel](#IntegrationTestHelper.GetChatModel>)
  - [func \(h \*IntegrationTestHelper\) Reset\(\)](#IntegrationTestHelper.Reset>)
- [type Metrics](#Metrics>)
  - [func DefaultMetrics\(\) \*Metrics](#DefaultMetrics>)
  - [func NewMetrics\(meter metric.Meter, tracer trace.Tracer\) \(\*Metrics, error\)](#NewMetrics>)
  - [func NoOpMetrics\(\) \*Metrics](#NoOpMetrics>)
  - [func \(m \*Metrics\) RecordMessageGeneration\(model, provider string, duration time.Duration, success bool, tokenCount int\)](#Metrics.RecordMessageGeneration>)
  - [func \(m \*Metrics\) RecordMessageGenerationError\(model, provider, errorType string\)](#Metrics.RecordMessageGenerationError>)
  - [func \(m \*Metrics\) RecordModelError\(model, provider, errorType string\)](#Metrics.RecordModelError>)
  - [func \(m \*Metrics\) RecordModelRequest\(model, provider string, duration time.Duration, success bool\)](#Metrics.RecordModelRequest>)
  - [func \(m \*Metrics\) RecordProviderError\(provider, errorType string\)](#Metrics.RecordProviderError>)
  - [func \(m \*Metrics\) RecordProviderRequest\(provider string, duration time.Duration, success bool\)](#Metrics.RecordProviderRequest>)
  - [func \(m \*Metrics\) RecordStreamingError\(model, provider, errorType string\)](#Metrics.RecordStreamingError>)
  - [func \(m \*Metrics\) RecordStreamingSession\(model, provider string, duration time.Duration, success bool, messageCount int\)](#Metrics.RecordStreamingSession>)
  - [func \(m \*Metrics\) RecordTokenUsage\(model, provider string, tokensGenerated, tokensConsumed int\)](#Metrics.RecordTokenUsage>)
  - [func \(m \*Metrics\) StartGenerationSpan\(ctx context.Context, model, provider, operation string\) \(context.Context, trace.Span\)](#Metrics.StartGenerationSpan>)
  - [func \(m \*Metrics\) StartProviderSpan\(ctx context.Context, provider, operation string\) \(context.Context, trace.Span\)](#Metrics.StartProviderSpan>)
  - [func \(m \*Metrics\) StartStreamingSpan\(ctx context.Context, model, provider string\) \(context.Context, trace.Span\)](#Metrics.StartStreamingSpan>)
- [type MockChatModelOption](#MockChatModelOption>)
  - [func WithConversationHistory\(messages \[\]schema.Message\) MockChatModelOption](#WithConversationHistory>)
  - [func WithMockError\(shouldError bool, err error\) MockChatModelOption](#WithMockError>)
  - [func WithMockResponses\(responses \[\]schema.Message\) MockChatModelOption](#WithMockResponses>)
  - [func WithStreamingDelay\(delay time.Duration\) MockChatModelOption](#WithStreamingDelay>)
  - [func WithToolsSupport\(supported bool\) MockChatModelOption](#WithToolsSupport>)
- [type ProviderConfig](#ProviderConfig>)
- [type ProviderError](#ProviderError>)
  - [func NewProviderError\(provider, operation string, err error\) \*ProviderError](#NewProviderError>)
  - [func \(e \*ProviderError\) Error\(\) string](#ProviderError.Error>)
  - [func \(e \*ProviderError\) Unwrap\(\) error](#ProviderError.Unwrap>)
- [type RateLimitConfig](#RateLimitConfig>)
- [type StreamingError](#StreamingError>)
  - [func NewStreamingError\(model string, err error\) \*StreamingError](#NewStreamingError>)
  - [func \(e \*StreamingError\) Error\(\) string](#StreamingError.Error>)
  - [func \(e \*StreamingError\) Unwrap\(\) error](#StreamingError.Unwrap>)
  - [func \(e \*StreamingError\) WithDuration\(duration string\) \*StreamingError](#StreamingError.WithDuration>)
- [type ValidationError](#ValidationError>)
  - [func NewValidationError\(field, message string\) \*ValidationError](#NewValidationError>)
  - [func \(e \*ValidationError\) Error\(\) string](#ValidationError.Error>)

## Constants

Error codes for different types of chat model errors.

```go
const (
    ErrCodeConfigInvalid        = "config_invalid"
    ErrCodeInitialization       = "initialization_failed"
    ErrCodeGeneration           = "generation_failed"
    ErrCodeStreaming            = "streaming_failed"
    ErrCodeRateLimit            = "rate_limit"
    ErrCodeInvalidInput         = "invalid_input"
    ErrCodeNetworkError         = "network_error"
    ErrCodeTimeout              = "timeout"
    ErrCodeMaxRetries           = "max_retries_exceeded"
    ErrCodeInvalidResponse      = "invalid_response"
    ErrCodeModelNotFound        = "model_not_found"
    ErrCodeProviderNotSupported = "provider_not_supported"
    ErrCodeAuthentication       = "authentication_failed"
    ErrCodeQuotaExceeded        = "quota_exceeded"
    ErrCodeResourceExhausted    = "resource_exhausted"
)
```

## Variables

Common error variables for frequently used errors.

```go
var (
    ErrChatModelNotFound    = errors.New("chat model not found")
    ErrInvalidConfig        = errors.New("invalid configuration")
    ErrProviderNotAvailable = errors.New("provider not available")
    ErrModelNotSupported    = errors.New("model not supported")
    ErrMaxRetriesExceeded   = errors.New("maximum retries exceeded")
    ErrContextCancelled     = errors.New("context canceled")
    ErrTimeout              = errors.New("operation timed out")
    ErrRateLimitExceeded    = errors.New("rate limit exceeded")
    ErrQuotaExceeded        = errors.New("quota exceeded")
    ErrResourceExhausted    = errors.New("resource exhausted")
    ErrAuthenticationFailed = errors.New("authentication failed")
    ErrNetworkError         = errors.New("network error")
)
```


## func [AssertChatModelHealth](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L389)

```go
func AssertChatModelHealth(t *testing.T, health map[string]any, expectedStatus string)
```

AssertChatModelHealth validates chat model health check results.


## func [AssertChatResponse](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L349)

```go
func AssertChatResponse(t *testing.T, response schema.Message, expectedMinLength int)
```

AssertChatResponse validates chat model response.


## func [AssertConversationFlow](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L373)

```go
func AssertConversationFlow(t *testing.T, history []schema.Message, expectedMinLength int)
```

AssertConversationFlow validates conversation flow.


## func [AssertErrorType](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L399)

```go
func AssertErrorType(t *testing.T, err error, expectedCode string)
```

AssertErrorType validates error types and codes.


## func [AssertStreamingResponse](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L357)

```go
func AssertStreamingResponse(t *testing.T, chunks []llmsiface.AIMessageChunk, expectedMinChunks int)
```

AssertStreamingResponse validates streaming response.


## func [CreateTestMessages](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L313)

```go
func CreateTestMessages(conversationLength int) []schema.Message
```

CreateTestMessages creates a set of test messages for chat model testing.


## func [GenerateMessages](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L324)

```go
func GenerateMessages(ctx context.Context, model iface.ChatModel, messages []schema.Message, opts ...iface.Option) ([]schema.Message, error)
```

GenerateMessages is a convenience function for generating messages with a chat model. This wraps the model's GenerateMessages method for easier usage.

Parameters:

- ctx: Context for cancellation and timeout control
- model: Chat model instance
- messages: Input messages
- opts: Optional generation options

Returns:

- Generated response messages
- Error if generation fails

Example:

```
messages := []schema.Message{
	schema.NewHumanMessage("Hello!"),
}
response, err := chatmodels.GenerateMessages(ctx, model, messages)
```


## func [GetModelInfo](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L301)

```go
func GetModelInfo(model iface.ChatModel) iface.ModelInfo
```

GetModelInfo retrieves model information from a chat model.

Parameters:

- model: Chat model instance

Returns:

- Model information struct

Example:

go
```go
info := chatmodels.GetModelInfo(model)
fmt.Printf("Model: %s, Provider: %s\n", info.Name, info.Provider)
```


## func [GetSupportedModels](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L259)

```go
func GetSupportedModels(provider string) []string
```

GetSupportedModels returns a list of supported models for a given provider.

Parameters:

- provider: Provider name

Returns:

- Slice of supported model names

Example:

go
```go
models := chatmodels.GetSupportedModels("openai")
fmt.Printf("OpenAI models: %v\n", models)
```


## func [GetSupportedProviders](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L243)

```go
func GetSupportedProviders() []string
```

GetSupportedProviders returns a list of supported chat model providers.

Returns:

- Slice of supported provider names

Example:

go
```go
providers := chatmodels.GetSupportedProviders()
fmt.Printf("Supported providers: %v\n", providers)
```


## func [HealthCheck](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L285)

```go
func HealthCheck(model iface.ChatModel) map[string]any
```

HealthCheck performs a health check on a chat model. This can be used for monitoring and ensuring model availability.

Parameters:

- model: Chat model to check

Returns:

- Health status information

Example:

go
```go
status := chatmodels.HealthCheck(model)
if status["state"] == "error" {
	log.Warn("Model is in error state")
}
```


## func [IsAuthenticationError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L264)

```go
func IsAuthenticationError(err error) bool
```

IsAuthenticationError checks if an error is an authentication error.


## func [IsGenerationError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L252)

```go
func IsGenerationError(err error) bool
```

IsGenerationError checks if an error is a generation error.


## func [IsProviderError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L246)

```go
func IsProviderError(err error) bool
```

IsProviderError checks if an error is a provider error.


## func [IsQuotaError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L273)

```go
func IsQuotaError(err error) bool
```

IsQuotaError checks if an error is a quota\-related error.


## func [IsRetryable](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L221)

```go
func IsRetryable(err error) bool
```

IsRetryable checks if an error is retryable.


## func [IsStreamingError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L258)

```go
func IsStreamingError(err error) bool
```

IsStreamingError checks if an error is a streaming error.


## func [IsValidationError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L240)

```go
func IsValidationError(err error) bool
```

IsValidationError checks if an error is a validation error.


## func [NewChatModel](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L74)

```go
func NewChatModel(model string, config *Config, opts ...iface.Option) (iface.ChatModel, error)
```

NewChatModel creates a new chat model instance with the specified model name and configuration. This is the main factory function for creating chat models.

Parameters:

- model: The model name/identifier \(e.g., "gpt\-4", "claude\-3"\)
- config: Configuration instance \(use DefaultConfig\(\) for defaults\)
- opts: Optional configuration functions

Returns:

- Chat model instance implementing the ChatModel interface
- Error if initialization fails

Example:

```
config := chatmodels.DefaultConfig()
model, err := chatmodels.NewChatModel("gpt-4", config,

	chatmodels.WithTemperature(0.7),
	chatmodels.WithMaxTokens(1000),
)
```


## func [NewMockChatModel](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L193)

```go
func NewMockChatModel(model string, opts ...iface.Option) (iface.ChatModel, error)
```

NewMockChatModel creates a new mock chat model for testing. This creates a chat model that returns predetermined responses.

Parameters:

- model: Model name for the mock
- opts: Optional configuration functions

Returns:

- Mock chat model instance
- Error if initialization fails

Example:

```
model, err := chatmodels.NewMockChatModel("mock-gpt-4",

	chatmodels.WithTemperature(0.5),
)
```


## func [NewOpenAIChatModel](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L163)

```go
func NewOpenAIChatModel(model, apiKey string, opts ...iface.Option) (iface.ChatModel, error)
```

NewOpenAIChatModel creates a new OpenAI chat model instance. This is a convenience function for creating OpenAI\-specific models.

Parameters:

- model: OpenAI model name \(e.g., "gpt\-4", "gpt\-3.5\-turbo"\)
- apiKey: OpenAI API key
- opts: Optional configuration functions

Returns:

- OpenAI chat model instance
- Error if initialization fails

Example:

```
model, err := chatmodels.NewOpenAIChatModel("gpt-4", "your-api-key",

	chatmodels.WithTemperature(0.7),
)
```


## func [RunLoadTest](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L470)

```go
func RunLoadTest(t *testing.T, chatModel *AdvancedMockChatModel, numOperations, concurrency int)
```

RunLoadTest executes a load test scenario on chat model.


## func [StreamMessages](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L355)

```go
func StreamMessages(ctx context.Context, model iface.ChatModel, messages []schema.Message, opts ...iface.Option) (<-chan schema.Message, error)
```

StreamMessages is a convenience function for streaming messages with a chat model. This wraps the model's StreamMessages method for easier usage.

Parameters:

- ctx: Context for cancellation and timeout control
- model: Chat model instance
- messages: Input messages
- opts: Optional streaming options

Returns:

- Channel of streaming messages
- Error if streaming fails

Example:

```
stream, err := chatmodels.StreamMessages(ctx, model, messages)
if err != nil {
	log.Fatal(err)
}
for msg := range stream {
	fmt.Println("Received:", msg.GetContent())
}
```


## func [ValidateConfig](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L230)

```go
func ValidateConfig(config *Config) error
```

ValidateConfig validates a chat model configuration. This ensures the configuration is complete and contains valid values.

Parameters:

- config: Configuration to validate

Returns:

- Error if validation fails, nil otherwise

Example:

go
```go
config := chatmodels.DefaultConfig()
if err := chatmodels.ValidateConfig(config); err != nil {
	log.Fatal("Invalid config:", err)
}
```


## func [WithFunctionCalling](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L105)

```go
func WithFunctionCalling(enabled bool) iface.Option
```

WithFunctionCalling enables or disables function calling.


## func [WithMaxRetries](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L125)

```go
func WithMaxRetries(retries int) iface.Option
```

WithMaxRetries sets the maximum number of retries.


## func [WithMaxTokens](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L65)

```go
func WithMaxTokens(maxTokens int) iface.Option
```

WithMaxTokens sets the maximum number of tokens to generate.


## func [WithMetrics](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L135)

```go
func WithMetrics(enabled bool) iface.Option
```

WithMetrics enables or disables metrics collection.


## func [WithStopSequences](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L85)

```go
func WithStopSequences(sequences []string) iface.Option
```

WithStopSequences sets the stop sequences for generation.


## func [WithSystemPrompt](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L95)

```go
func WithSystemPrompt(prompt string) iface.Option
```

WithSystemPrompt sets the system prompt.


## func [WithTemperature](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L55)

```go
func WithTemperature(temp float32) iface.Option
```

WithTemperature sets the temperature for response generation.


## func [WithTimeout](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L115)

```go
func WithTimeout(timeout time.Duration) iface.Option
```

WithTimeout sets the timeout for operations.


## func [WithTopP](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L75)

```go
func WithTopP(topP float32) iface.Option
```

WithTopP sets the nucleus sampling parameter.


## func [WithTracing](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L145)

```go
func WithTracing(enabled bool) iface.Option
```

WithTracing enables or disables tracing.


## type [AdvancedMockChatModel](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L23-L39)

AdvancedMockChatModel provides a comprehensive mock implementation for testing.

```go
type AdvancedMockChatModel struct {
    mock.Mock
    // contains filtered or unexported fields
}
```


### func [NewAdvancedMockChatModel](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L42)

```go
func NewAdvancedMockChatModel(modelName, providerName string, options ...MockChatModelOption) *AdvancedMockChatModel
```

NewAdvancedMockChatModel creates a new advanced mock with configurable behavior.


### func \(\*AdvancedMockChatModel\) [Batch](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L127)

```go
func (m *AdvancedMockChatModel) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error)
```


### func \(\*AdvancedMockChatModel\) [BindTools](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L250)

```go
func (m *AdvancedMockChatModel) BindTools(toolsToBind []tools.Tool) llmsiface.ChatModel
```


### func \(\*AdvancedMockChatModel\) [CheckHealth](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L275)

```go
func (m *AdvancedMockChatModel) CheckHealth() map[string]any
```


### func \(\*AdvancedMockChatModel\) [Generate](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L163)

```go
func (m *AdvancedMockChatModel) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error)
```

Mock implementation methods for ChatModel interface.


### func \(\*AdvancedMockChatModel\) [GetCallCount](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L289)

```go
func (m *AdvancedMockChatModel) GetCallCount() int
```

Additional helper methods for testing.


### func \(\*AdvancedMockChatModel\) [GetConversationHistory](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L295)

```go
func (m *AdvancedMockChatModel) GetConversationHistory() []schema.Message
```


### func \(\*AdvancedMockChatModel\) [GetModelName](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L267)

```go
func (m *AdvancedMockChatModel) GetModelName() string
```


### func \(\*AdvancedMockChatModel\) [GetProviderName](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L271)

```go
func (m *AdvancedMockChatModel) GetProviderName() string
```


### func \(\*AdvancedMockChatModel\) [Invoke](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L110)

```go
func (m *AdvancedMockChatModel) Invoke(ctx context.Context, input any, options ...core.Option) (any, error)
```

Mock implementation methods for core.Runnable interface.


### func \(\*AdvancedMockChatModel\) [ResetConversation](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L303)

```go
func (m *AdvancedMockChatModel) ResetConversation()
```


### func \(\*AdvancedMockChatModel\) [Stream](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L139)

```go
func (m *AdvancedMockChatModel) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error)
```


### func \(\*AdvancedMockChatModel\) [StreamChat](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L203)

```go
func (m *AdvancedMockChatModel) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan llmsiface.AIMessageChunk, error)
```


## type [AdvancedMockcomponent](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/advanced_mock.go#L8-L10)

AdvancedMockcomponent is a mock implementation of Interface.

```go
type AdvancedMockcomponent struct {
    mock.Mock
}
```


### func [NewAdvancedMockcomponent](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/advanced_mock.go#L13)

```go
func NewAdvancedMockcomponent() *AdvancedMockcomponent
```

NewAdvancedMockcomponent creates a new AdvancedMockcomponent.


## type [BenchmarkHelper](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L621-L624)

BenchmarkHelper provides benchmarking utilities for chat models.

```go
type BenchmarkHelper struct {
    // contains filtered or unexported fields
}
```


### func [NewBenchmarkHelper](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L626)

```go
func NewBenchmarkHelper(chatModel llmsiface.ChatModel, conversationCount int) *BenchmarkHelper
```


### func \(\*BenchmarkHelper\) [BenchmarkGeneration](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L638)

```go
func (b *BenchmarkHelper) BenchmarkGeneration(iterations int) (time.Duration, error)
```


### func \(\*BenchmarkHelper\) [BenchmarkStreaming](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L653)

```go
func (b *BenchmarkHelper) BenchmarkStreaming(iterations int) (time.Duration, error)
```


## type [ChatModelError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L10-L17)

ChatModelError represents a custom error type for chat model operations. It includes context about the operation that failed and wraps the underlying error.

```go
type ChatModelError struct {
    Err      error
    Fields   map[string]any
    Op       string
    Model    string
    Provider string
    Code     string
}
```


### func [NewChatModelError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L55)

```go
func NewChatModelError(op, model, provider, code string, err error) *ChatModelError
```

NewChatModelError creates a new ChatModelError.


### func \(\*ChatModelError\) [Error](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L20)

```go
func (e *ChatModelError) Error() string
```

Error implements the error interface.


### func \(\*ChatModelError\) [Unwrap](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L31)

```go
func (e *ChatModelError) Unwrap() error
```

Unwrap returns the underlying error for error wrapping.


### func \(\*ChatModelError\) [WithField](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L67)

```go
func (e *ChatModelError) WithField(key string, value any) *ChatModelError
```

WithField adds a context field to the error.


## type [ChatModelScenarioRunner](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L555-L557)

ChatModelScenarioRunner runs common chat model scenarios.

```go
type ChatModelScenarioRunner struct {
    // contains filtered or unexported fields
}
```


### func [NewChatModelScenarioRunner](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L559)

```go
func NewChatModelScenarioRunner(chatModel llmsiface.ChatModel) *ChatModelScenarioRunner
```


### func \(\*ChatModelScenarioRunner\) [RunConversationScenario](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L565)

```go
func (r *ChatModelScenarioRunner) RunConversationScenario(ctx context.Context, turns int) error
```


### func \(\*ChatModelScenarioRunner\) [RunStreamingScenario](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L586)

```go
func (r *ChatModelScenarioRunner) RunStreamingScenario(ctx context.Context, queries []string) error
```


## type [ConcurrentTestRunner](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L411-L415)

ConcurrentTestRunner runs chat model tests concurrently for performance testing.

```go
type ConcurrentTestRunner struct {
    NumGoroutines int
    TestDuration  time.Duration
    // contains filtered or unexported fields
}
```


### func [NewConcurrentTestRunner](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L417)

```go
func NewConcurrentTestRunner(numGoroutines int, duration time.Duration, testFunc func() error) *ConcurrentTestRunner
```


### func \(\*ConcurrentTestRunner\) [Run](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L425)

```go
func (r *ConcurrentTestRunner) Run() error
```


## type [Config](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L11-L36)

Config represents the configuration for the chatmodels package. It includes settings for model behavior, generation parameters, and observability.

```go
type Config struct {
    Providers               map[string]any `mapstructure:"providers" yaml:"providers"`
    DefaultSystemPrompt     string         `mapstructure:"default_system_prompt" yaml:"default_system_prompt" env:"CHATMODEL_DEFAULT_SYSTEM_PROMPT"`
    DefaultProvider         string         `mapstructure:"default_provider" yaml:"default_provider" env:"CHATMODEL_DEFAULT_PROVIDER" default:"openai"`
    TracingServiceName      string         `mapstructure:"tracing_service_name" yaml:"tracing_service_name" env:"CHATMODEL_TRACING_SERVICE_NAME" default:"beluga-chatmodels"`
    MetricsPrefix           string         `mapstructure:"metrics_prefix" yaml:"metrics_prefix" env:"CHATMODEL_METRICS_PREFIX" default:"beluga_chatmodels"`
    DefaultModel            string         `mapstructure:"default_model" yaml:"default_model" env:"CHATMODEL_DEFAULT_MODEL" default:"gpt-3.5-turbo"`
    DefaultStopSequences    []string       `mapstructure:"default_stop_sequences" yaml:"default_stop_sequences" env:"CHATMODEL_DEFAULT_STOP_SEQUENCES"`
    RetryBackoffFactor      float64        `mapstructure:"retry_backoff_factor" yaml:"retry_backoff_factor" env:"CHATMODEL_RETRY_BACKOFF_FACTOR" validate:"gt=0" default:"2.0"`
    MaxConcurrentRequests   int            `mapstructure:"max_concurrent_requests" yaml:"max_concurrent_requests" env:"CHATMODEL_MAX_CONCURRENT_REQUESTS" validate:"gt=0" default:"100"`
    DefaultMaxRetries       int            `mapstructure:"default_max_retries" yaml:"default_max_retries" env:"CHATMODEL_DEFAULT_MAX_RETRIES" validate:"gte=0" default:"3"`
    DefaultRetryDelay       time.Duration  `mapstructure:"default_retry_delay" yaml:"default_retry_delay" env:"CHATMODEL_DEFAULT_RETRY_DELAY" validate:"gt=0" default:"2s"`
    MaxRetryDelay           time.Duration  `mapstructure:"max_retry_delay" yaml:"max_retry_delay" env:"CHATMODEL_MAX_RETRY_DELAY" validate:"gt=0" default:"30s"`
    ConnectionTimeout       time.Duration  `mapstructure:"connection_timeout" yaml:"connection_timeout" env:"CHATMODEL_CONNECTION_TIMEOUT" validate:"gt=0" default:"10s"`
    RequestTimeout          time.Duration  `mapstructure:"request_timeout" yaml:"request_timeout" env:"CHATMODEL_REQUEST_TIMEOUT" validate:"gt=0" default:"2m"`
    StreamTimeout           time.Duration  `mapstructure:"stream_timeout" yaml:"stream_timeout" env:"CHATMODEL_STREAM_TIMEOUT" validate:"gt=0" default:"5m"`
    DefaultTimeout          time.Duration  `mapstructure:"default_timeout" yaml:"default_timeout" env:"CHATMODEL_DEFAULT_TIMEOUT" validate:"gt=0" default:"30s"`
    DefaultMaxTokens        int            `mapstructure:"default_max_tokens" yaml:"default_max_tokens" env:"CHATMODEL_DEFAULT_MAX_TOKENS" validate:"gt=0" default:"1000"`
    StreamBufferSize        int            `mapstructure:"stream_buffer_size" yaml:"stream_buffer_size" env:"CHATMODEL_STREAM_BUFFER_SIZE" validate:"gt=0" default:"100"`
    DefaultTopP             float32        `mapstructure:"default_top_p" yaml:"default_top_p" env:"CHATMODEL_DEFAULT_TOP_P" validate:"gte=0,lte=1" default:"1.0"`
    DefaultTemperature      float32        `mapstructure:"default_temperature" yaml:"default_temperature" env:"CHATMODEL_DEFAULT_TEMPERATURE" validate:"gte=0,lte=2" default:"0.7"`
    DefaultStreamingEnabled bool           `mapstructure:"default_streaming_enabled" yaml:"default_streaming_enabled" env:"CHATMODEL_DEFAULT_STREAMING_ENABLED" default:"false"`
    EnableTracing           bool           `mapstructure:"enable_tracing" yaml:"enable_tracing" env:"CHATMODEL_ENABLE_TRACING" default:"true"`
    DefaultFunctionCalling  bool           `mapstructure:"default_function_calling" yaml:"default_function_calling" env:"CHATMODEL_DEFAULT_FUNCTION_CALLING" default:"false"`
    EnableMetrics           bool           `mapstructure:"enable_metrics" yaml:"enable_metrics" env:"CHATMODEL_ENABLE_METRICS" default:"true"`
}
```


### func [CreateTestChatModelConfig](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L331)

```go
func CreateTestChatModelConfig() Config
```

CreateTestChatModelConfig creates a test chat model configuration.


### func [DefaultConfig](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L155)

```go
func DefaultConfig() *Config
```

DefaultConfig returns a default configuration for the chatmodels package.


### func [NewDefaultConfig](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/chatmodels.go#L211)

```go
func NewDefaultConfig() *Config
```

NewDefaultConfig creates a new configuration instance with default values. This provides sensible defaults for most use cases while allowing customization.

Returns:

- Configuration instance with defaults

Example:

```
config := chatmodels.NewDefaultConfig()
config.DefaultTemperature = 0.8
model, err := chatmodels.NewChatModel("gpt-4", config)
```


### func \(\*Config\) [GetProviderConfig](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L215)

```go
func (c *Config) GetProviderConfig(provider string) (*ProviderConfig, error)
```

GetProviderConfig returns the configuration for a specific provider.


### func \(\*Config\) [Validate](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L185)

```go
func (c *Config) Validate() error
```

Validate validates the configuration and returns an error if invalid.


## type [GenerationError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L121-L127)

GenerationError represents errors that occur during message generation.

```go
type GenerationError struct {
    Err        error
    Model      string
    Suggestion string
    Messages   int
    Tokens     int
}
```


### func [NewGenerationError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L148)

```go
func NewGenerationError(model string, messages int, err error) *GenerationError
```

NewGenerationError creates a new GenerationError.


### func \(\*GenerationError\) [Error](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L130)

```go
func (e *GenerationError) Error() string
```

Error implements the error interface.


### func \(\*GenerationError\) [Unwrap](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L143)

```go
func (e *GenerationError) Unwrap() error
```

Unwrap returns the underlying error.


### func \(\*GenerationError\) [WithSuggestion](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L163)

```go
func (e *GenerationError) WithSuggestion(suggestion string) *GenerationError
```

WithSuggestion adds a suggestion to help resolve the generation error.


### func \(\*GenerationError\) [WithTokenCount](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L157)

```go
func (e *GenerationError) WithTokenCount(tokens int) *GenerationError
```

WithTokenCount adds token count information to the error.


## type [IntegrationTestHelper](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L529-L531)

IntegrationTestHelper provides utilities for integration testing.

```go
type IntegrationTestHelper struct {
    // contains filtered or unexported fields
}
```


### func [NewIntegrationTestHelper](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L533)

```go
func NewIntegrationTestHelper() *IntegrationTestHelper
```


### func \(\*IntegrationTestHelper\) [AddChatModel](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L539)

```go
func (h *IntegrationTestHelper) AddChatModel(name string, chatModel *AdvancedMockChatModel)
```


### func \(\*IntegrationTestHelper\) [GetChatModel](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L543)

```go
func (h *IntegrationTestHelper) GetChatModel(name string) *AdvancedMockChatModel
```


### func \(\*IntegrationTestHelper\) [Reset](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L547)

```go
func (h *IntegrationTestHelper) Reset()
```


## type [Metrics](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L19-L47)

Metrics holds the metrics for the chatmodels package.

```go
type Metrics struct {
    // contains filtered or unexported fields
}
```


### func [DefaultMetrics](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L421)

```go
func DefaultMetrics() *Metrics
```

DefaultMetrics creates a metrics instance with default meter and tracer.


### func [NewMetrics](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L50)

```go
func NewMetrics(meter metric.Meter, tracer trace.Tracer) (*Metrics, error)
```

NewMetrics creates a new Metrics instance with OpenTelemetry metrics.


### func [NoOpMetrics](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L434)

```go
func NoOpMetrics() *Metrics
```

NoOpMetrics returns a metrics instance that does nothing. Useful for testing or when metrics are disabled.


### func \(\*Metrics\) [RecordMessageGeneration](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L201)

```go
func (m *Metrics) RecordMessageGeneration(model, provider string, duration time.Duration, success bool, tokenCount int)
```

Message generation metrics.


### func \(\*Metrics\) [RecordMessageGenerationError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L229)

```go
func (m *Metrics) RecordMessageGenerationError(model, provider, errorType string)
```


### func \(\*Metrics\) [RecordModelError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L370)

```go
func (m *Metrics) RecordModelError(model, provider, errorType string)
```


### func \(\*Metrics\) [RecordModelRequest](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L347)

```go
func (m *Metrics) RecordModelRequest(model, provider string, duration time.Duration, success bool)
```

Model metrics.


### func \(\*Metrics\) [RecordProviderError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L332)

```go
func (m *Metrics) RecordProviderError(provider, errorType string)
```


### func \(\*Metrics\) [RecordProviderRequest](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L310)

```go
func (m *Metrics) RecordProviderRequest(provider string, duration time.Duration, success bool)
```

Provider metrics.


### func \(\*Metrics\) [RecordStreamingError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L273)

```go
func (m *Metrics) RecordStreamingError(model, provider, errorType string)
```


### func \(\*Metrics\) [RecordStreamingSession](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L245)

```go
func (m *Metrics) RecordStreamingSession(model, provider string, duration time.Duration, success bool, messageCount int)
```

Streaming metrics.


### func \(\*Metrics\) [RecordTokenUsage](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L289)

```go
func (m *Metrics) RecordTokenUsage(model, provider string, tokensGenerated, tokensConsumed int)
```

Token metrics.


### func \(\*Metrics\) [StartGenerationSpan](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L389)

```go
func (m *Metrics) StartGenerationSpan(ctx context.Context, model, provider, operation string) (context.Context, trace.Span)
```

Tracing helpers. Spans returned by these methods must be ended by the caller using span.End\(\).


### func \(\*Metrics\) [StartProviderSpan](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L411)

```go
func (m *Metrics) StartProviderSpan(ctx context.Context, provider, operation string) (context.Context, trace.Span)
```


### func \(\*Metrics\) [StartStreamingSpan](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/metrics.go#L400)

```go
func (m *Metrics) StartStreamingSpan(ctx context.Context, model, provider string) (context.Context, trace.Span)
```


## type [MockChatModelOption](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L69)

MockChatModelOption defines functional options for mock configuration.

```go
type MockChatModelOption func(*AdvancedMockChatModel)
```


### func [WithConversationHistory](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L102)

```go
func WithConversationHistory(messages []schema.Message) MockChatModelOption
```

WithConversationHistory preloads conversation history.


### func [WithMockError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L72)

```go
func WithMockError(shouldError bool, err error) MockChatModelOption
```

WithMockError configures the mock to return errors.


### func [WithMockResponses](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L80)

```go
func WithMockResponses(responses []schema.Message) MockChatModelOption
```

WithMockResponses sets predefined responses for the mock.


### func [WithStreamingDelay](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L88)

```go
func WithStreamingDelay(delay time.Duration) MockChatModelOption
```

WithStreamingDelay adds artificial delay to mock operations.


### func [WithToolsSupport](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/test_utils.go#L95)

```go
func WithToolsSupport(supported bool) MockChatModelOption
```

WithToolsSupport configures whether the mock supports tools.


## type [ProviderConfig](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L39-L45)

ProviderConfig represents configuration for a specific provider.

```go
type ProviderConfig struct {
    APIKey     string          `mapstructure:"api_key" yaml:"api_key" env:"CHATMODEL_PROVIDER_API_KEY"`
    BaseURL    string          `mapstructure:"base_url" yaml:"base_url" env:"CHATMODEL_PROVIDER_BASE_URL"`
    Timeout    time.Duration   `mapstructure:"timeout" yaml:"timeout" env:"CHATMODEL_PROVIDER_TIMEOUT" validate:"gt=0" default:"30s"`
    MaxRetries int             `mapstructure:"max_retries" yaml:"max_retries" env:"CHATMODEL_PROVIDER_MAX_RETRIES" validate:"gte=0" default:"3"`
    RateLimit  RateLimitConfig `mapstructure:"rate_limit" yaml:"rate_limit"`
}
```


## type [ProviderError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L95-L99)

ProviderError represents errors that occur with specific providers.

```go
type ProviderError struct {
    Err       error
    Provider  string
    Operation string
}
```


### func [NewProviderError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L112)

```go
func NewProviderError(provider, operation string, err error) *ProviderError
```

NewProviderError creates a new ProviderError.


### func \(\*ProviderError\) [Error](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L102)

```go
func (e *ProviderError) Error() string
```

Error implements the error interface.


### func \(\*ProviderError\) [Unwrap](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L107)

```go
func (e *ProviderError) Unwrap() error
```

Unwrap returns the underlying error.


## type [RateLimitConfig](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/config.go#L48-L52)

RateLimitConfig represents rate limiting configuration.

```go
type RateLimitConfig struct {
    RequestsPerMinute int `mapstructure:"requests_per_minute" yaml:"requests_per_minute" env:"CHATMODEL_RATE_LIMIT_REQUESTS_PER_MINUTE" validate:"gt=0" default:"60"`
    RequestsPerHour   int `mapstructure:"requests_per_hour" yaml:"requests_per_hour" env:"CHATMODEL_RATE_LIMIT_REQUESTS_PER_HOUR" validate:"gt=0" default:"1000"`
    BurstSize         int `mapstructure:"burst_size" yaml:"burst_size" env:"CHATMODEL_RATE_LIMIT_BURST_SIZE" validate:"gt=0" default:"10"`
}
```


## type [StreamingError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L169-L173)

StreamingError represents errors that occur during streaming operations.

```go
type StreamingError struct {
    Err      error
    Model    string
    Duration string
}
```


### func [NewStreamingError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L191)

```go
func NewStreamingError(model string, err error) *StreamingError
```

NewStreamingError creates a new StreamingError.


### func \(\*StreamingError\) [Error](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L176)

```go
func (e *StreamingError) Error() string
```

Error implements the error interface.


### func \(\*StreamingError\) [Unwrap](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L186)

```go
func (e *StreamingError) Unwrap() error
```

Unwrap returns the underlying error.


### func \(\*StreamingError\) [WithDuration](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L199)

```go
func (e *StreamingError) WithDuration(duration string) *StreamingError
```

WithDuration adds duration information to the streaming error.


## type [ValidationError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L76-L79)

ValidationError represents configuration validation errors.

```go
type ValidationError struct {
    Field   string
    Message string
}
```


### func [NewValidationError](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L87)

```go
func NewValidationError(field, message string) *ValidationError
```

NewValidationError creates a new ValidationError.


### func \(\*ValidationError\) [Error](https://github.com/lookatitude/beluga-ai/blob/main/pkg/chatmodels/errors.go#L82)

```go
func (e *ValidationError) Error() string
```

Error implements the error interface.

Generated by [gomarkdoc](https://github.com/princjef/gomarkdoc)

---
title: llms
sidebar_position: 1
---

<!-- Code generated by gomarkdoc. DO NOT EDIT -->


# llms

```go
import "github.com/lookatitude/beluga-ai/pkg/llms"
```

Package llms provides chat model interfaces and implementations. This file contains the high\-level chat model interfaces and utilities that build on top of the core LLM functionality.

Package llms provides code generation utilities for LLM implementations. This file contains directives for automated code generation following the Beluga AI Framework patterns.

Package llms provides integration test setup utilities for testing with real LLM providers. This file contains utilities to help set up and run integration tests safely.

IMPORTANT: These tests require real API keys and will make actual API calls. They should only be run in CI/CD environments or with explicit permission.

Usage:

```
go test -tags=integration ./pkg/llms/...
```

Package llms provides interfaces and implementations for Large Language Model interactions. This package follows the Beluga AI Framework's design patterns for consistency, extensibility, configuration management, and observability.

Package llms provides advanced test utilities and comprehensive mocks for testing LLM implementations. This file contains utilities designed to support both unit tests and integration tests.

Package llms provides tracing functionality for LLM operations using OpenTelemetry

## Index

- [Constants](<#constants>)
- [func AddSpanAttributesMap\(span trace.Span, attrs map\[string\]any\)](<#AddSpanAttributesMap>)
- [func AssertErrorType\(t \*testing.T, err error, expectedCode string\)](<#AssertErrorType>)
- [func AssertHealthCheck\(t \*testing.T, health map\[string\]any\)](<#AssertHealthCheck>)
- [func AssertStreamingResponse\(t \*testing.T, chunks \<\-chan iface.AIMessageChunk\)](<#AssertStreamingResponse>)
- [func BatchGenerate\(ctx context.Context, model iface.ChatModel, prompts \[\]string, options ...core.Option\) \(\[\]string, error\)](<#BatchGenerate>)
- [func ConcurrentTestRunner\(t \*testing.T, testFunc func\(t \*testing.T\), goroutines int\)](<#ConcurrentTestRunner>)
- [func CreateTestMessages\(\) \[\]schema.Message](<#CreateTestMessages>)
- [func EnsureMessages\(input any\) \(\[\]schema.Message, error\)](<#EnsureMessages>)
- [func EnsureMessagesFromSchema\(input any\) \(\[\]schema.Message, error\)](<#EnsureMessagesFromSchema>)
- [func GenerateMetrics\(\) string](<#GenerateMetrics>)
- [func GenerateMock\(config MockProviderConfig\) string](<#GenerateMock>)
- [func GenerateProvider\(template ProviderTemplate\) string](<#GenerateProvider>)
- [func GenerateText\(ctx context.Context, model iface.ChatModel, prompt string, options ...core.Option\) \(string, error\)](<#GenerateText>)
- [func GenerateTextWithTools\(ctx context.Context, model iface.ChatModel, prompt string, tools \[\]tools.Tool, options ...core.Option\) \(string, error\)](<#GenerateTextWithTools>)
- [func GetLLMErrorCode\(err error\) string](<#GetLLMErrorCode>)
- [func GetSystemAndHumanPromptsFromSchema\(messages \[\]schema.Message\) \(string, string\)](<#GetSystemAndHumanPromptsFromSchema>)
- [func InitMetrics\(meter metric.Meter\)](<#InitMetrics>)
- [func IsLLMError\(err error\) bool](<#IsLLMError>)
- [func IsRetryableError\(err error\) bool](<#IsRetryableError>)
- [func LoggerAttrs\(provider, model, operation string\) map\[string\]any](<#LoggerAttrs>)
- [func NewAnthropicChat\(opts ...ConfigOption\) \(iface.ChatModel, error\)](<#NewAnthropicChat>)
- [func NewAnthropicLLM\(opts ...ConfigOption\) \(iface.LLM, error\)](<#NewAnthropicLLM>)
- [func NewBedrockLLM\(opts ...ConfigOption\) \(iface.LLM, error\)](<#NewBedrockLLM>)
- [func NewChatModel\(model string, config \*Config, opts ...ChatOption\) \(iface.ChatModel, error\)](<#NewChatModel>)
- [func NewMockLLM\(opts ...ConfigOption\) \(iface.LLM, error\)](<#NewMockLLM>)
- [func NewOllamaChat\(opts ...ConfigOption\) \(iface.ChatModel, error\)](<#NewOllamaChat>)
- [func NewOllamaLLM\(opts ...ConfigOption\) \(iface.LLM, error\)](<#NewOllamaLLM>)
- [func NewOpenAIChat\(opts ...ConfigOption\) \(iface.ChatModel, error\)](<#NewOpenAIChat>)
- [func NewOpenAILLM\(opts ...ConfigOption\) \(iface.LLM, error\)](<#NewOpenAILLM>)
- [func RecordSpanError\(span trace.Span, err error\)](<#RecordSpanError>)
- [func RunAllIntegrationTests\(t \*testing.T\)](<#RunAllIntegrationTests>)
- [func RunIntegrationTestSuite\(t \*testing.T, suite IntegrationTestSuite\)](<#RunIntegrationTestSuite>)
- [func RunLoadTest\(t \*testing.T, scenario LoadTestScenario\)](<#RunLoadTest>)
- [func StartSpan\(ctx context.Context, tracer trace.Tracer, operation, provider, model string\) \(context.Context, trace.Span\)](<#StartSpan>)
- [func StreamText\(ctx context.Context, model iface.ChatModel, prompt string, options ...core.Option\) \(\<\-chan iface.AIMessageChunk, error\)](<#StreamText>)
- [func TestContext\(\) \(context.Context, context.CancelFunc\)](<#TestContext>)
- [func TestProviderInterface\(t \*testing.T, provider iface.ChatModel, providerName string\)](<#TestProviderInterface>)
- [func ValidateModelName\(provider, modelName string\) error](<#ValidateModelName>)
- [func ValidateProviderConfig\(ctx context.Context, config \*Config\) error](<#ValidateProviderConfig>)
- [func WithMaxTokensLegacy\(tokens int\) core.Option](<#WithMaxTokensLegacy>)
- [func WithStopWordsLegacy\(stop \[\]string\) core.Option](<#WithStopWordsLegacy>)
- [func WithTemperatureLegacy\(temp float32\) core.Option](<#WithTemperatureLegacy>)
- [func WithToolChoiceLegacy\(choice string\) core.Option](<#WithToolChoiceLegacy>)
- [func WithToolsLegacy\(toolsToUse \[\]tools.Tool\) core.Option](<#WithToolsLegacy>)
- [func WithTopKLegacy\(topK int\) core.Option](<#WithTopKLegacy>)
- [func WithTopPLegacy\(topP float32\) core.Option](<#WithTopPLegacy>)
- [func WrapError\(op string, err error\) error](<#WrapError>)
- [type AdvancedMockChatModel](<#AdvancedMockChatModel>)
  - [func NewAdvancedMockChatModel\(modelName string, opts ...MockOption\) \*AdvancedMockChatModel](<#NewAdvancedMockChatModel>)
  - [func \(m \*AdvancedMockChatModel\) Batch\(ctx context.Context, inputs \[\]any, options ...core.Option\) \(\[\]any, error\)](<#AdvancedMockChatModel.Batch>)
  - [func \(m \*AdvancedMockChatModel\) BindTools\(toolsToBind \[\]tools.Tool\) iface.ChatModel](<#AdvancedMockChatModel.BindTools>)
  - [func \(m \*AdvancedMockChatModel\) CheckHealth\(\) map\[string\]any](<#AdvancedMockChatModel.CheckHealth>)
  - [func \(m \*AdvancedMockChatModel\) Generate\(ctx context.Context, messages \[\]schema.Message, options ...core.Option\) \(schema.Message, error\)](<#AdvancedMockChatModel.Generate>)
  - [func \(m \*AdvancedMockChatModel\) GetCallCount\(\) int](<#AdvancedMockChatModel.GetCallCount>)
  - [func \(m \*AdvancedMockChatModel\) GetModelName\(\) string](<#AdvancedMockChatModel.GetModelName>)
  - [func \(m \*AdvancedMockChatModel\) GetProviderName\(\) string](<#AdvancedMockChatModel.GetProviderName>)
  - [func \(m \*AdvancedMockChatModel\) Invoke\(ctx context.Context, input any, options ...core.Option\) \(any, error\)](<#AdvancedMockChatModel.Invoke>)
  - [func \(m \*AdvancedMockChatModel\) Reset\(\)](<#AdvancedMockChatModel.Reset>)
  - [func \(m \*AdvancedMockChatModel\) Stream\(ctx context.Context, input any, options ...core.Option\) \(\<\-chan any, error\)](<#AdvancedMockChatModel.Stream>)
  - [func \(m \*AdvancedMockChatModel\) StreamChat\(ctx context.Context, messages \[\]schema.Message, options ...core.Option\) \(\<\-chan iface.AIMessageChunk, error\)](<#AdvancedMockChatModel.StreamChat>)
- [type AdvancedMockLLM](<#AdvancedMockLLM>)
  - [func NewAdvancedMockLLM\(modelName string\) \*AdvancedMockLLM](<#NewAdvancedMockLLM>)
  - [func \(m \*AdvancedMockLLM\) GetModelName\(\) string](<#AdvancedMockLLM.GetModelName>)
  - [func \(m \*AdvancedMockLLM\) GetProviderName\(\) string](<#AdvancedMockLLM.GetProviderName>)
  - [func \(m \*AdvancedMockLLM\) Invoke\(ctx context.Context, input any, options ...core.Option\) \(any, error\)](<#AdvancedMockLLM.Invoke>)
- [type CallOptions](<#CallOptions>)
  - [func NewCallOptions\(\) \*CallOptions](<#NewCallOptions>)
  - [func \(co \*CallOptions\) ApplyCallOption\(opt core.Option\)](<#CallOptions.ApplyCallOption>)
- [type ChatModel](<#ChatModel>)
- [type ChatModelAdapter](<#ChatModelAdapter>)
  - [func NewChatModelAdapter\(llm iface.LLM, options \*ChatOptions\) \*ChatModelAdapter](<#NewChatModelAdapter>)
  - [func \(c \*ChatModelAdapter\) Batch\(ctx context.Context, inputs \[\]any, options ...core.Option\) \(\[\]any, error\)](<#ChatModelAdapter.Batch>)
  - [func \(c \*ChatModelAdapter\) CheckHealth\(\) map\[string\]any](<#ChatModelAdapter.CheckHealth>)
  - [func \(c \*ChatModelAdapter\) GenerateMessages\(ctx context.Context, messages \[\]schema.Message, options ...core.Option\) \(\[\]schema.Message, error\)](<#ChatModelAdapter.GenerateMessages>)
  - [func \(c \*ChatModelAdapter\) GetModelInfo\(\) ModelInfo](<#ChatModelAdapter.GetModelInfo>)
  - [func \(c \*ChatModelAdapter\) Invoke\(ctx context.Context, input any, options ...core.Option\) \(any, error\)](<#ChatModelAdapter.Invoke>)
  - [func \(c \*ChatModelAdapter\) Stream\(ctx context.Context, input any, options ...core.Option\) \(\<\-chan any, error\)](<#ChatModelAdapter.Stream>)
  - [func \(c \*ChatModelAdapter\) StreamMessages\(ctx context.Context, messages \[\]schema.Message, options ...core.Option\) \(\<\-chan schema.Message, error\)](<#ChatModelAdapter.StreamMessages>)
- [type ChatModelFactory](<#ChatModelFactory>)
- [type ChatOption](<#ChatOption>)
  - [func ChatOptionFunc\(f func\(config \*map\[string\]any\)\) ChatOption](<#ChatOptionFunc>)
  - [func WithChatFunctionCalling\(enabled bool\) ChatOption](<#WithChatFunctionCalling>)
  - [func WithChatMaxRetries\(maxRetries int\) ChatOption](<#WithChatMaxRetries>)
  - [func WithChatMaxTokens\(maxTokens int\) ChatOption](<#WithChatMaxTokens>)
  - [func WithChatObservability\(metrics, tracing bool\) ChatOption](<#WithChatObservability>)
  - [func WithChatStopSequences\(sequences \[\]string\) ChatOption](<#WithChatStopSequences>)
  - [func WithChatSystemPrompt\(prompt string\) ChatOption](<#WithChatSystemPrompt>)
  - [func WithChatTemperature\(temp float32\) ChatOption](<#WithChatTemperature>)
  - [func WithChatTimeout\(timeout time.Duration\) ChatOption](<#WithChatTimeout>)
  - [func WithChatTopP\(topP float32\) ChatOption](<#WithChatTopP>)
- [type ChatOptions](<#ChatOptions>)
- [type Config](<#Config>)
  - [func CreateTestConfig\(\) \*Config](<#CreateTestConfig>)
  - [func DefaultConfig\(\) \*Config](<#DefaultConfig>)
  - [func NewConfig\(opts ...ConfigOption\) \*Config](<#NewConfig>)
  - [func NewDefaultConfig\(\) \*Config](<#NewDefaultConfig>)
  - [func \(c \*Config\) MergeOptions\(opts ...ConfigOption\)](<#Config.MergeOptions>)
  - [func \(c \*Config\) Validate\(\) error](<#Config.Validate>)
- [type ConfigOption](<#ConfigOption>)
  - [func WithAPIKey\(apiKey string\) ConfigOption](<#WithAPIKey>)
  - [func WithBaseURL\(baseURL string\) ConfigOption](<#WithBaseURL>)
  - [func WithMaxConcurrentBatches\(n int\) ConfigOption](<#WithMaxConcurrentBatches>)
  - [func WithMaxTokensConfig\(maxTokens int\) ConfigOption](<#WithMaxTokensConfig>)
  - [func WithModelName\(modelName string\) ConfigOption](<#WithModelName>)
  - [func WithObservability\(tracing, metrics, logging bool\) ConfigOption](<#WithObservability>)
  - [func WithProvider\(provider string\) ConfigOption](<#WithProvider>)
  - [func WithProviderSpecific\(key string, value any\) ConfigOption](<#WithProviderSpecific>)
  - [func WithRetryConfig\(maxRetries int, delay time.Duration, backoff float64\) ConfigOption](<#WithRetryConfig>)
  - [func WithStopSequences\(sequences \[\]string\) ConfigOption](<#WithStopSequences>)
  - [func WithTemperatureConfig\(temp float32\) ConfigOption](<#WithTemperatureConfig>)
  - [func WithTimeout\(timeout time.Duration\) ConfigOption](<#WithTimeout>)
  - [func WithToolCalling\(enabled bool\) ConfigOption](<#WithToolCalling>)
  - [func WithTopKConfig\(topK int\) ConfigOption](<#WithTopKConfig>)
  - [func WithTopPConfig\(topP float32\) ConfigOption](<#WithTopPConfig>)
- [type ConfigValidationError](<#ConfigValidationError>)
  - [func \(e \*ConfigValidationError\) AddError\(field string, value any, message string\)](<#ConfigValidationError.AddError>)
  - [func \(e \*ConfigValidationError\) Error\(\) string](<#ConfigValidationError.Error>)
  - [func \(e \*ConfigValidationError\) HasErrors\(\) bool](<#ConfigValidationError.HasErrors>)
- [type Factory](<#Factory>)
  - [func InitializeDefaultFactory\(\) \*Factory](<#InitializeDefaultFactory>)
  - [func NewFactory\(\) \*Factory](<#NewFactory>)
  - [func \(f \*Factory\) CreateLLM\(providerName string, config \*Config\) \(iface.LLM, error\)](<#Factory.CreateLLM>)
  - [func \(f \*Factory\) CreateProvider\(providerName string, config \*Config\) \(iface.ChatModel, error\)](<#Factory.CreateProvider>)
  - [func \(f \*Factory\) GetLLM\(name string\) \(iface.LLM, error\)](<#Factory.GetLLM>)
  - [func \(f \*Factory\) GetProvider\(name string\) \(iface.ChatModel, error\)](<#Factory.GetProvider>)
  - [func \(f \*Factory\) ListAvailableProviders\(\) \[\]string](<#Factory.ListAvailableProviders>)
  - [func \(f \*Factory\) ListLLMs\(\) \[\]string](<#Factory.ListLLMs>)
  - [func \(f \*Factory\) ListProviders\(\) \[\]string](<#Factory.ListProviders>)
  - [func \(f \*Factory\) RegisterLLM\(name string, llm iface.LLM\)](<#Factory.RegisterLLM>)
  - [func \(f \*Factory\) RegisterLLMFactory\(name string, factory func\(\*Config\) \(iface.LLM, error\)\)](<#Factory.RegisterLLMFactory>)
  - [func \(f \*Factory\) RegisterProvider\(name string, provider iface.ChatModel\)](<#Factory.RegisterProvider>)
  - [func \(f \*Factory\) RegisterProviderFactory\(name string, factory func\(\*Config\) \(iface.ChatModel, error\)\)](<#Factory.RegisterProviderFactory>)
- [type HealthChecker](<#HealthChecker>)
- [type IntegrationTestConfig](<#IntegrationTestConfig>)
  - [func DefaultIntegrationTestConfig\(\) \*IntegrationTestConfig](<#DefaultIntegrationTestConfig>)
  - [func LoadIntegrationTestConfig\(\) \*IntegrationTestConfig](<#LoadIntegrationTestConfig>)
- [type IntegrationTestHelper](<#IntegrationTestHelper>)
  - [func NewIntegrationTestHelper\(\) \*IntegrationTestHelper](<#NewIntegrationTestHelper>)
  - [func \(h \*IntegrationTestHelper\) GetConfig\(\) \*Config](<#IntegrationTestHelper.GetConfig>)
  - [func \(h \*IntegrationTestHelper\) GetFactory\(\) \*Factory](<#IntegrationTestHelper.GetFactory>)
  - [func \(h \*IntegrationTestHelper\) GetMetrics\(\) \*MockMetricsRecorder](<#IntegrationTestHelper.GetMetrics>)
  - [func \(h \*IntegrationTestHelper\) GetTracing\(\) \*MockTracingHelper](<#IntegrationTestHelper.GetTracing>)
  - [func \(h \*IntegrationTestHelper\) RateLimit\(\)](<#IntegrationTestHelper.RateLimit>)
  - [func \(h \*IntegrationTestHelper\) SetupAnthropicProvider\(modelName string\) \(iface.ChatModel, error\)](<#IntegrationTestHelper.SetupAnthropicProvider>)
  - [func \(h \*IntegrationTestHelper\) SetupBedrockProvider\(modelName string\) \(iface.ChatModel, error\)](<#IntegrationTestHelper.SetupBedrockProvider>)
  - [func \(h \*IntegrationTestHelper\) SetupMockProvider\(providerName, modelName string, opts ...any\) iface.ChatModel](<#IntegrationTestHelper.SetupMockProvider>)
  - [func \(h \*IntegrationTestHelper\) SetupOllamaProvider\(modelName string\) \(iface.ChatModel, error\)](<#IntegrationTestHelper.SetupOllamaProvider>)
  - [func \(h \*IntegrationTestHelper\) SetupOpenAIProvider\(modelName string\) \(iface.ChatModel, error\)](<#IntegrationTestHelper.SetupOpenAIProvider>)
  - [func \(h \*IntegrationTestHelper\) SetupProvider\(providerName string, config \*Config\) \(iface.ChatModel, error\)](<#IntegrationTestHelper.SetupProvider>)
  - [func \(h \*IntegrationTestHelper\) TestCrossProviderComparison\(t \*testing.T, providers map\[string\]iface.ChatModel, testPrompt string\)](<#IntegrationTestHelper.TestCrossProviderComparison>)
  - [func \(h \*IntegrationTestHelper\) TestProviderErrorHandling\(t \*testing.T, provider iface.ChatModel, providerName string\)](<#IntegrationTestHelper.TestProviderErrorHandling>)
  - [func \(h \*IntegrationTestHelper\) TestProviderIntegration\(t \*testing.T, provider iface.ChatModel, providerName string\)](<#IntegrationTestHelper.TestProviderIntegration>)
- [type IntegrationTestSuite](<#IntegrationTestSuite>)
  - [func AnthropicIntegrationTestSuite\(\) IntegrationTestSuite](<#AnthropicIntegrationTestSuite>)
  - [func MultiProviderIntegrationTestSuite\(\) IntegrationTestSuite](<#MultiProviderIntegrationTestSuite>)
  - [func OllamaIntegrationTestSuite\(\) IntegrationTestSuite](<#OllamaIntegrationTestSuite>)
  - [func OpenAIIntegrationTestSuite\(\) IntegrationTestSuite](<#OpenAIIntegrationTestSuite>)
- [type LLMError](<#LLMError>)
  - [func GetLLMError\(err error\) \*LLMError](<#GetLLMError>)
  - [func MapHTTPError\(op string, statusCode int, err error\) \*LLMError](<#MapHTTPError>)
  - [func NewLLMError\(op, code string, err error\) \*LLMError](<#NewLLMError>)
  - [func NewLLMErrorWithDetails\(op, code, message string, err error, details map\[string\]any\) \*LLMError](<#NewLLMErrorWithDetails>)
  - [func NewLLMErrorWithMessage\(op, code, message string, err error\) \*LLMError](<#NewLLMErrorWithMessage>)
  - [func \(e \*LLMError\) Error\(\) string](<#LLMError.Error>)
  - [func \(e \*LLMError\) Unwrap\(\) error](<#LLMError.Unwrap>)
- [type LoadTestScenario](<#LoadTestScenario>)
- [type MessageGenerator](<#MessageGenerator>)
- [type Metrics](<#Metrics>)
  - [func GetMetrics\(\) \*Metrics](<#GetMetrics>)
  - [func NewMetrics\(meter metric.Meter\) \*Metrics](<#NewMetrics>)
  - [func \(m \*Metrics\) DecrementActiveRequests\(ctx context.Context, provider, model string\)](<#Metrics.DecrementActiveRequests>)
  - [func \(m \*Metrics\) DecrementActiveStreams\(ctx context.Context, provider, model string\)](<#Metrics.DecrementActiveStreams>)
  - [func \(m \*Metrics\) IncrementActiveRequests\(ctx context.Context, provider, model string\)](<#Metrics.IncrementActiveRequests>)
  - [func \(m \*Metrics\) IncrementActiveStreams\(ctx context.Context, provider, model string\)](<#Metrics.IncrementActiveStreams>)
  - [func \(m \*Metrics\) RecordBatch\(ctx context.Context, provider, model string, batchSize int, duration time.Duration\)](<#Metrics.RecordBatch>)
  - [func \(m \*Metrics\) RecordError\(ctx context.Context, provider, model, errorCode string, duration time.Duration\)](<#Metrics.RecordError>)
  - [func \(m \*Metrics\) RecordRequest\(ctx context.Context, provider, model string, duration time.Duration\)](<#Metrics.RecordRequest>)
  - [func \(m \*Metrics\) RecordStream\(ctx context.Context, provider, model string, duration time.Duration\)](<#Metrics.RecordStream>)
  - [func \(m \*Metrics\) RecordTokenUsage\(ctx context.Context, provider, model string, inputTokens, outputTokens int\)](<#Metrics.RecordTokenUsage>)
  - [func \(m \*Metrics\) RecordToolCall\(ctx context.Context, provider, model, toolName string\)](<#Metrics.RecordToolCall>)
- [type MetricsRecorder](<#MetricsRecorder>)
- [type MockMetricsRecorder](<#MockMetricsRecorder>)
  - [func NewMockMetricsRecorder\(\) \*MockMetricsRecorder](<#NewMockMetricsRecorder>)
  - [func \(m \*MockMetricsRecorder\) DecrementActiveRequests\(ctx context.Context, provider, model string\)](<#MockMetricsRecorder.DecrementActiveRequests>)
  - [func \(m \*MockMetricsRecorder\) DecrementActiveStreams\(ctx context.Context, provider, model string\)](<#MockMetricsRecorder.DecrementActiveStreams>)
  - [func \(m \*MockMetricsRecorder\) IncrementActiveRequests\(ctx context.Context, provider, model string\)](<#MockMetricsRecorder.IncrementActiveRequests>)
  - [func \(m \*MockMetricsRecorder\) IncrementActiveStreams\(ctx context.Context, provider, model string\)](<#MockMetricsRecorder.IncrementActiveStreams>)
  - [func \(m \*MockMetricsRecorder\) RecordBatch\(ctx context.Context, provider, model string, batchSize int, duration time.Duration\)](<#MockMetricsRecorder.RecordBatch>)
  - [func \(m \*MockMetricsRecorder\) RecordError\(ctx context.Context, provider, model, errorCode string, duration time.Duration\)](<#MockMetricsRecorder.RecordError>)
  - [func \(m \*MockMetricsRecorder\) RecordRequest\(ctx context.Context, provider, model string, duration time.Duration\)](<#MockMetricsRecorder.RecordRequest>)
  - [func \(m \*MockMetricsRecorder\) RecordStream\(ctx context.Context, provider, model string, duration time.Duration\)](<#MockMetricsRecorder.RecordStream>)
  - [func \(m \*MockMetricsRecorder\) RecordTokenUsage\(ctx context.Context, provider, model string, inputTokens, outputTokens int\)](<#MockMetricsRecorder.RecordTokenUsage>)
  - [func \(m \*MockMetricsRecorder\) RecordToolCall\(ctx context.Context, provider, model, toolName string\)](<#MockMetricsRecorder.RecordToolCall>)
- [type MockOption](<#MockOption>)
  - [func WithError\(err error\) MockOption](<#WithError>)
  - [func WithHealthState\(state string\) MockOption](<#WithHealthState>)
  - [func WithNetworkDelay\(enabled bool\) MockOption](<#WithNetworkDelay>)
  - [func WithProviderName\(name string\) MockOption](<#WithProviderName>)
  - [func WithResponses\(responses ...string\) MockOption](<#WithResponses>)
  - [func WithStreamingDelay\(delay time.Duration\) MockOption](<#WithStreamingDelay>)
  - [func WithToolResults\(results map\[string\]any\) MockOption](<#WithToolResults>)
- [type MockProviderConfig](<#MockProviderConfig>)
- [type MockTool](<#MockTool>)
  - [func NewMockTool\(name string\) \*MockTool](<#NewMockTool>)
  - [func \(m \*MockTool\) Batch\(ctx context.Context, inputs \[\]any\) \(\[\]any, error\)](<#MockTool.Batch>)
  - [func \(m \*MockTool\) Definition\(\) tools.ToolDefinition](<#MockTool.Definition>)
  - [func \(m \*MockTool\) Description\(\) string](<#MockTool.Description>)
  - [func \(m \*MockTool\) Execute\(ctx context.Context, input any\) \(any, error\)](<#MockTool.Execute>)
  - [func \(m \*MockTool\) Name\(\) string](<#MockTool.Name>)
  - [func \(m \*MockTool\) SetResult\(result any\)](<#MockTool.SetResult>)
  - [func \(m \*MockTool\) SetShouldError\(shouldError bool\)](<#MockTool.SetShouldError>)
- [type MockTracingHelper](<#MockTracingHelper>)
  - [func NewMockTracingHelper\(\) \*MockTracingHelper](<#NewMockTracingHelper>)
  - [func \(m \*MockTracingHelper\) AddSpanAttributes\(ctx context.Context, attrs map\[string\]any\)](<#MockTracingHelper.AddSpanAttributes>)
  - [func \(m \*MockTracingHelper\) EndSpan\(ctx context.Context\)](<#MockTracingHelper.EndSpan>)
  - [func \(m \*MockTracingHelper\) RecordError\(ctx context.Context, err error\)](<#MockTracingHelper.RecordError>)
  - [func \(m \*MockTracingHelper\) StartOperation\(ctx context.Context, operation, provider, model string\) context.Context](<#MockTracingHelper.StartOperation>)
- [type ModelInfo](<#ModelInfo>)
- [type ModelInfoProvider](<#ModelInfoProvider>)
- [type NoOpMetrics](<#NoOpMetrics>)
  - [func NewNoOpMetrics\(\) \*NoOpMetrics](<#NewNoOpMetrics>)
  - [func \(n \*NoOpMetrics\) DecrementActiveRequests\(ctx context.Context, provider, model string\)](<#NoOpMetrics.DecrementActiveRequests>)
  - [func \(n \*NoOpMetrics\) DecrementActiveStreams\(ctx context.Context, provider, model string\)](<#NoOpMetrics.DecrementActiveStreams>)
  - [func \(n \*NoOpMetrics\) IncrementActiveRequests\(ctx context.Context, provider, model string\)](<#NoOpMetrics.IncrementActiveRequests>)
  - [func \(n \*NoOpMetrics\) IncrementActiveStreams\(ctx context.Context, provider, model string\)](<#NoOpMetrics.IncrementActiveStreams>)
  - [func \(n \*NoOpMetrics\) RecordBatch\(ctx context.Context, provider, model string, batchSize int, duration time.Duration\)](<#NoOpMetrics.RecordBatch>)
  - [func \(n \*NoOpMetrics\) RecordError\(ctx context.Context, provider, model, errorCode string, duration time.Duration\)](<#NoOpMetrics.RecordError>)
  - [func \(n \*NoOpMetrics\) RecordRequest\(ctx context.Context, provider, model string, duration time.Duration\)](<#NoOpMetrics.RecordRequest>)
  - [func \(n \*NoOpMetrics\) RecordStream\(ctx context.Context, provider, model string, duration time.Duration\)](<#NoOpMetrics.RecordStream>)
  - [func \(n \*NoOpMetrics\) RecordTokenUsage\(ctx context.Context, provider, model string, inputTokens, outputTokens int\)](<#NoOpMetrics.RecordTokenUsage>)
  - [func \(n \*NoOpMetrics\) RecordToolCall\(ctx context.Context, provider, model, toolName string\)](<#NoOpMetrics.RecordToolCall>)
- [type OpenTelemetryTracer](<#OpenTelemetryTracer>)
  - [func NewOpenTelemetryTracer\(name string\) \*OpenTelemetryTracer](<#NewOpenTelemetryTracer>)
  - [func \(t \*OpenTelemetryTracer\) AddSpanAttributes\(span trace.Span, attrs map\[string\]any\)](<#OpenTelemetryTracer.AddSpanAttributes>)
  - [func \(t \*OpenTelemetryTracer\) RecordError\(span trace.Span, err error\)](<#OpenTelemetryTracer.RecordError>)
  - [func \(t \*OpenTelemetryTracer\) StartSpan\(ctx context.Context, operation, provider, model string\) \(context.Context, trace.Span\)](<#OpenTelemetryTracer.StartSpan>)
- [type ProviderConfig](<#ProviderConfig>)
- [type ProviderError](<#ProviderError>)
  - [func NewProviderError\(provider, op, code, message string, err error\) \*ProviderError](<#NewProviderError>)
  - [func \(e \*ProviderError\) Error\(\) string](<#ProviderError.Error>)
  - [func \(e \*ProviderError\) Unwrap\(\) error](<#ProviderError.Unwrap>)
- [type ProviderTemplate](<#ProviderTemplate>)
- [type StreamError](<#StreamError>)
  - [func NewStreamError\(op, code, message string, err error\) \*StreamError](<#NewStreamError>)
  - [func \(e \*StreamError\) Error\(\) string](<#StreamError.Error>)
  - [func \(e \*StreamError\) Unwrap\(\) error](<#StreamError.Unwrap>)
- [type StreamMessageHandler](<#StreamMessageHandler>)
- [type TracerProvider](<#TracerProvider>)
- [type TracingHelper](<#TracingHelper>)
  - [func NewTracingHelper\(\) \*TracingHelper](<#NewTracingHelper>)
  - [func \(th \*TracingHelper\) AddSpanAttributes\(ctx context.Context, attrs map\[string\]any\)](<#TracingHelper.AddSpanAttributes>)
  - [func \(th \*TracingHelper\) EndSpan\(ctx context.Context\)](<#TracingHelper.EndSpan>)
  - [func \(th \*TracingHelper\) RecordError\(ctx context.Context, err error\)](<#TracingHelper.RecordError>)
  - [func \(th \*TracingHelper\) StartOperation\(ctx context.Context, operation, provider, model string\) context.Context](<#TracingHelper.StartOperation>)
- [type ValidationError](<#ValidationError>)
  - [func NewValidationError\(field string, value any, message string\) \*ValidationError](<#NewValidationError>)
  - [func \(e \*ValidationError\) Error\(\) string](<#ValidationError.Error>)

## Constants

<a name="ErrCodeInvalidConfig"></a>Error codes for LLM operations.

```go
const (
    // General errors.
    ErrCodeInvalidConfig  = "invalid_config"
    ErrCodeNetworkError   = "network_error"
    ErrCodeTimeout        = "timeout"
    ErrCodeRateLimit      = "rate_limit"
    ErrCodeQuotaExceeded  = "quota_exceeded"
    ErrCodeAuthentication = "authentication_error"
    ErrCodeAuthorization  = "authorization_error"
    ErrCodeNotFound       = "not_found"
    ErrCodeInternalError  = "internal_error"
    ErrCodeInvalidInput   = "invalid_input"

    // Provider-specific errors.
    ErrCodeUnsupportedProvider = "unsupported_provider"
    ErrCodeInvalidModel        = "invalid_model"
    ErrCodeModelNotAvailable   = "model_not_available"

    // Request/Response errors.
    ErrCodeInvalidRequest    = "invalid_request"
    ErrCodeInvalidResponse   = "invalid_response"
    ErrCodeEmptyResponse     = "empty_response"
    ErrCodeMalformedResponse = "malformed_response"

    // Streaming errors.
    ErrCodeStreamError   = "stream_error"
    ErrCodeStreamTimeout = "stream_timeout"
    ErrCodeStreamClosed  = "stream_closed"

    // Tool calling errors.
    ErrCodeToolCallError      = "tool_call_error"
    ErrCodeToolNotFound       = "tool_not_found"
    ErrCodeToolExecutionError = "tool_execution_error"

    // Context errors.
    ErrCodeContextCanceled = "context_canceled"
    ErrCodeContextTimeout  = "context_timeout"
)
```

<a name="AddSpanAttributesMap"></a>
## func [AddSpanAttributesMap](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L148>)

```go
func AddSpanAttributesMap(span trace.Span, attrs map[string]any)
```

AddSpanAttributesMap adds multiple attributes to a span.

<a name="AssertErrorType"></a>
## func [AssertErrorType](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L621>)

```go
func AssertErrorType(t *testing.T, err error, expectedCode string)
```

AssertErrorType checks if an error matches expected type.

<a name="AssertHealthCheck"></a>
## func [AssertHealthCheck](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L595>)

```go
func AssertHealthCheck(t *testing.T, health map[string]any)
```

AssertHealthCheck validates health check results.

<a name="AssertStreamingResponse"></a>
## func [AssertStreamingResponse](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L605>)

```go
func AssertStreamingResponse(t *testing.T, chunks <-chan iface.AIMessageChunk)
```

AssertStreamingResponse validates streaming responses.

<a name="BatchGenerate"></a>
## func [BatchGenerate](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L279>)

```go
func BatchGenerate(ctx context.Context, model iface.ChatModel, prompts []string, options ...core.Option) ([]string, error)
```

BatchGenerate is a convenience function for batch text generation.

<a name="ConcurrentTestRunner"></a>
## func [ConcurrentTestRunner](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L636>)

```go
func ConcurrentTestRunner(t *testing.T, testFunc func(t *testing.T), goroutines int)
```

ConcurrentTestRunner runs a test function concurrently.

<a name="CreateTestMessages"></a>
## func [CreateTestMessages](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L573>)

```go
func CreateTestMessages() []schema.Message
```

CreateTestMessages creates a set of test messages.

<a name="EnsureMessages"></a>
## func [EnsureMessages](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L187>)

```go
func EnsureMessages(input any) ([]schema.Message, error)
```

EnsureMessages ensures the input is a slice of schema.Message. It attempts to convert common input types \(like a single string or Message\) into the required format.

### Example

Example demonstrating message conversion.

```go
package main

import (
	"fmt"
	"log"

	"github.com/lookatitude/beluga-ai/pkg/llms"
)

func main() {
	// Convert string to messages
	messages, err := llms.EnsureMessages("Hello, world!")
	if err != nil {
		log.Fatal(err)
	}

	if _, err := fmt.Printf("Converted %d messages\n", len(messages)); err != nil {
		log.Printf("Failed to print: %v", err)
	}
}
```

#### Output

```
Converted 1 messages
```

<a name="EnsureMessagesFromSchema"></a>
## func [EnsureMessagesFromSchema](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L204>)

```go
func EnsureMessagesFromSchema(input any) ([]schema.Message, error)
```

EnsureMessagesFromSchema ensures the input is a slice of schema.Message. It attempts to convert common input types \(like a single string or Message\) into the required format. Deprecated: Use EnsureMessages instead.

<a name="GenerateMetrics"></a>
## func [GenerateMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/generate.go#L402>)

```go
func GenerateMetrics() string
```

GenerateMetrics generates metrics collection code.

<a name="GenerateMock"></a>
## func [GenerateMock](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/generate.go#L34>)

```go
func GenerateMock(config MockProviderConfig) string
```

GenerateMock generates a mock implementation for testing.

<a name="GenerateProvider"></a>
## func [GenerateProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/generate.go#L180>)

```go
func GenerateProvider(template ProviderTemplate) string
```

GenerateProvider generates a new provider implementation template.

<a name="GenerateText"></a>
## func [GenerateText](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L236>)

```go
func GenerateText(ctx context.Context, model iface.ChatModel, prompt string, options ...core.Option) (string, error)
```

GenerateText is a convenience function for generating text with a ChatModel.

<a name="GenerateTextWithTools"></a>
## func [GenerateTextWithTools](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L251>)

```go
func GenerateTextWithTools(ctx context.Context, model iface.ChatModel, prompt string, tools []tools.Tool, options ...core.Option) (string, error)
```

GenerateTextWithTools is a convenience function for generating text with tool calling.

<a name="GetLLMErrorCode"></a>
## func [GetLLMErrorCode](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L122>)

```go
func GetLLMErrorCode(err error) string
```

GetLLMErrorCode extracts the error code from an LLMError.

<a name="GetSystemAndHumanPromptsFromSchema"></a>
## func [GetSystemAndHumanPromptsFromSchema](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L211>)

```go
func GetSystemAndHumanPromptsFromSchema(messages []schema.Message) (string, string)
```

GetSystemAndHumanPromptsFromSchema extracts the system prompt and concatenates human messages. This is a utility function that might be useful for models that don't support distinct system messages or require a single prompt string.

### Example

Example demonstrating utility functions.

```go
package main

import (
	"fmt"
	"log"

	"github.com/lookatitude/beluga-ai/pkg/llms"
	"github.com/lookatitude/beluga-ai/pkg/schema"
)

func main() {
	messages := []schema.Message{
		schema.NewSystemMessage("You are a helpful assistant."),
		schema.NewHumanMessage("What is 2 + 2?"),
		schema.NewAIMessage("4"),
		schema.NewHumanMessage("What is 3 + 3?"),
	}

	system, human := llms.GetSystemAndHumanPromptsFromSchema(messages)

	if _, err := fmt.Printf("System: %s\n", system); err != nil {
		log.Printf("Failed to print: %v", err)
	}
	if _, err := fmt.Printf("Human: %s\n", human); err != nil {
		log.Printf("Failed to print: %v", err)
	}
}
```

#### Output

```
System: You are a helpful assistant.
Human: What is 2 + 2?
What is 3 + 3?
```

<a name="InitMetrics"></a>
## func [InitMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L27>)

```go
func InitMetrics(meter metric.Meter)
```

InitMetrics initializes the global metrics instance.

<a name="IsLLMError"></a>
## func [IsLLMError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L107>)

```go
func IsLLMError(err error) bool
```

IsLLMError checks if an error is an LLMError.

<a name="IsRetryableError"></a>
## func [IsRetryableError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L131>)

```go
func IsRetryableError(err error) bool
```

IsRetryableError checks if an error is retryable.

<a name="LoggerAttrs"></a>
## func [LoggerAttrs](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L177>)

```go
func LoggerAttrs(provider, model, operation string) map[string]any
```

LoggerAttrs returns structured logging attributes for LLM operations.

<a name="NewAnthropicChat"></a>
## func [NewAnthropicChat](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L405>)

```go
func NewAnthropicChat(opts ...ConfigOption) (iface.ChatModel, error)
```

NewAnthropicChat creates a new Anthropic chat model provider with the given options. This is a convenience function that internally uses the factory pattern.

<a name="NewAnthropicLLM"></a>
## func [NewAnthropicLLM](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L464>)

```go
func NewAnthropicLLM(opts ...ConfigOption) (iface.LLM, error)
```

NewAnthropicLLM creates a new Anthropic LLM provider with the given options. This is a convenience function that internally uses the factory pattern.

<a name="NewBedrockLLM"></a>
## func [NewBedrockLLM](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L500>)

```go
func NewBedrockLLM(opts ...ConfigOption) (iface.LLM, error)
```

NewBedrockLLM creates a new Bedrock LLM provider with the given options. This is a convenience function that internally uses the factory pattern.

<a name="NewChatModel"></a>
## func [NewChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L189>)

```go
func NewChatModel(model string, config *Config, opts ...ChatOption) (iface.ChatModel, error)
```

NewChatModel creates a new chat model instance with the specified model name and configuration. This is the main factory function for creating chat models that wraps the underlying LLM providers.

Parameters:

- model: The model name/identifier \(e.g., "gpt\-4", "claude\-3"\)
- config: Configuration instance \(use DefaultConfig\(\) for defaults\)
- opts: Optional configuration functions

Returns:

- Chat model instance implementing the ChatModel interface
- Error if initialization fails

Example:

```
config := llms.DefaultConfig()
config.DefaultProvider = "openai"
model, err := llms.NewChatModel("gpt-4", config,
	llms.WithChatTemperature(0.7),
	llms.WithChatMaxTokens(1000),
)
```

<a name="NewMockLLM"></a>
## func [NewMockLLM](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L536>)

```go
func NewMockLLM(opts ...ConfigOption) (iface.LLM, error)
```

NewMockLLM creates a new Mock LLM provider with the given options. This is a convenience function that internally uses the factory pattern.

<a name="NewOllamaChat"></a>
## func [NewOllamaChat](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L445>)

```go
func NewOllamaChat(opts ...ConfigOption) (iface.ChatModel, error)
```

NewOllamaChat creates a new Ollama chat model provider with the given options. This is a convenience function that internally uses the factory pattern.

<a name="NewOllamaLLM"></a>
## func [NewOllamaLLM](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L518>)

```go
func NewOllamaLLM(opts ...ConfigOption) (iface.LLM, error)
```

NewOllamaLLM creates a new Ollama LLM provider with the given options. This is a convenience function that internally uses the factory pattern.

<a name="NewOpenAIChat"></a>
## func [NewOpenAIChat](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L426>)

```go
func NewOpenAIChat(opts ...ConfigOption) (iface.ChatModel, error)
```

NewOpenAIChat creates a new OpenAI chat model provider with the given options. This is a convenience function that internally uses the factory pattern.

<a name="NewOpenAILLM"></a>
## func [NewOpenAILLM](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L482>)

```go
func NewOpenAILLM(opts ...ConfigOption) (iface.LLM, error)
```

NewOpenAILLM creates a new OpenAI LLM provider with the given options. This is a convenience function that internally uses the factory pattern.

<a name="RecordSpanError"></a>
## func [RecordSpanError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L140>)

```go
func RecordSpanError(span trace.Span, err error)
```

RecordSpanError records an error on a span.

<a name="RunAllIntegrationTests"></a>
## func [RunAllIntegrationTests](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L599>)

```go
func RunAllIntegrationTests(t *testing.T)
```

RunAllIntegrationTests runs all available integration tests.

<a name="RunIntegrationTestSuite"></a>
## func [RunIntegrationTestSuite](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L470>)

```go
func RunIntegrationTestSuite(t *testing.T, suite IntegrationTestSuite)
```

RunIntegrationTestSuite runs a complete integration test suite.

<a name="RunLoadTest"></a>
## func [RunLoadTest](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L672>)

```go
func RunLoadTest(t *testing.T, scenario LoadTestScenario)
```

RunLoadTest executes a load test scenario.

<a name="StartSpan"></a>
## func [StartSpan](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L129>)

```go
func StartSpan(ctx context.Context, tracer trace.Tracer, operation, provider, model string) (context.Context, trace.Span)
```

StartSpan is a convenience function for starting spans. The returned span must be ended by the caller using span.End\(\).

<a name="StreamText"></a>
## func [StreamText](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L269>)

```go
func StreamText(ctx context.Context, model iface.ChatModel, prompt string, options ...core.Option) (<-chan iface.AIMessageChunk, error)
```

StreamText is a convenience function for streaming text generation.

<a name="TestContext"></a>
## func [TestContext](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L568>)

```go
func TestContext() (context.Context, context.CancelFunc)
```

TestContext creates a context with timeout suitable for testing.

<a name="TestProviderInterface"></a>
## func [TestProviderInterface](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L787>)

```go
func TestProviderInterface(t *testing.T, provider iface.ChatModel, providerName string)
```

TestProviderInterface tests that a provider implements the ChatModel interface correctly.

<a name="ValidateModelName"></a>
## func [ValidateModelName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L307>)

```go
func ValidateModelName(provider, modelName string) error
```

ValidateModelName validates that a model name is supported by a provider.

### Example

Example demonstrating model validation.

```go
package main

import (
	"fmt"
	"log"

	"github.com/lookatitude/beluga-ai/pkg/llms"
)

func main() {
	// Valid OpenAI model
	err := llms.ValidateModelName("openai", "gpt-4")
	if _, printErr := fmt.Printf("OpenAI GPT-4 valid: %t\n", err == nil); printErr != nil {
		log.Printf("Failed to print: %v", printErr)
	}

	// Invalid OpenAI model
	err = llms.ValidateModelName("openai", "invalid-model")
	if _, printErr := fmt.Printf("OpenAI invalid model: %t\n", err != nil); printErr != nil {
		log.Printf("Failed to print: %v", printErr)
	}

	// Valid Anthropic model
	err = llms.ValidateModelName("anthropic", "claude-3-sonnet")
	if _, printErr := fmt.Printf("Anthropic Claude valid: %t\n", err == nil); printErr != nil {
		log.Printf("Failed to print: %v", printErr)
	}

	// Unknown provider (should pass)
	err = llms.ValidateModelName("unknown", "some-model")
	if _, printErr := fmt.Printf("Unknown provider: %t\n", err == nil); printErr != nil {
		log.Printf("Failed to print: %v", printErr)
	}
}
```

#### Output

```
OpenAI GPT-4 valid: true
OpenAI invalid model: true
Anthropic Claude valid: true
Unknown provider: true
```

<a name="ValidateProviderConfig"></a>
## func [ValidateProviderConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L214>)

```go
func ValidateProviderConfig(ctx context.Context, config *Config) error
```

ValidateProviderConfig validates a provider configuration.

<a name="WithMaxTokensLegacy"></a>
## func [WithMaxTokensLegacy](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L369>)

```go
func WithMaxTokensLegacy(tokens int) core.Option
```

WithMaxTokensLegacy sets the maximum number of tokens to generate \(deprecated, use core.WithOption\).

<a name="WithStopWordsLegacy"></a>
## func [WithStopWordsLegacy](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L389>)

```go
func WithStopWordsLegacy(stop []string) core.Option
```

WithStopWordsLegacy sets the stop sequences for generation \(deprecated, use core.WithOption\).

<a name="WithTemperatureLegacy"></a>
## func [WithTemperatureLegacy](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L374>)

```go
func WithTemperatureLegacy(temp float32) core.Option
```

WithTemperatureLegacy sets the sampling temperature \(deprecated, use core.WithOption\).

<a name="WithToolChoiceLegacy"></a>
## func [WithToolChoiceLegacy](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L399>)

```go
func WithToolChoiceLegacy(choice string) core.Option
```

WithToolChoiceLegacy forces the model to call a specific tool \(deprecated, use core.WithOption\).

<a name="WithToolsLegacy"></a>
## func [WithToolsLegacy](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L394>)

```go
func WithToolsLegacy(toolsToUse []tools.Tool) core.Option
```

WithToolsLegacy sets the tools that the model can call \(deprecated, use core.WithOption\).

<a name="WithTopKLegacy"></a>
## func [WithTopKLegacy](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L384>)

```go
func WithTopKLegacy(topK int) core.Option
```

WithTopKLegacy sets the top\-k sampling parameter \(deprecated, use core.WithOption\).

<a name="WithTopPLegacy"></a>
## func [WithTopPLegacy](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L379>)

```go
func WithTopPLegacy(topP float32) core.Option
```

WithTopPLegacy sets the nucleus sampling probability \(deprecated, use core.WithOption\).

<a name="WrapError"></a>
## func [WrapError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L161>)

```go
func WrapError(op string, err error) error
```

WrapError wraps an error with additional context.

<a name="AdvancedMockChatModel"></a>
## type [AdvancedMockChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L23-L40>)

AdvancedMockChatModel provides a comprehensive mock implementation for testing.

```go
type AdvancedMockChatModel struct {
    mock.Mock
    // contains filtered or unexported fields
}
```

<a name="NewAdvancedMockChatModel"></a>
### func [NewAdvancedMockChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L43>)

```go
func NewAdvancedMockChatModel(modelName string, opts ...MockOption) *AdvancedMockChatModel
```

NewAdvancedMockChatModel creates a new advanced mock with configurable behavior.

<a name="AdvancedMockChatModel.Batch"></a>
### func \(\*AdvancedMockChatModel\) [Batch](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L284>)

```go
func (m *AdvancedMockChatModel) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error)
```

Batch implements the Runnable interface.

<a name="AdvancedMockChatModel.BindTools"></a>
### func \(\*AdvancedMockChatModel\) [BindTools](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L226>)

```go
func (m *AdvancedMockChatModel) BindTools(toolsToBind []tools.Tool) iface.ChatModel
```

BindTools implements the ChatModel interface.

<a name="AdvancedMockChatModel.CheckHealth"></a>
### func \(\*AdvancedMockChatModel\) [CheckHealth](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L355>)

```go
func (m *AdvancedMockChatModel) CheckHealth() map[string]any
```

CheckHealth implements the HealthChecker interface.

<a name="AdvancedMockChatModel.Generate"></a>
### func \(\*AdvancedMockChatModel\) [Generate](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L118>)

```go
func (m *AdvancedMockChatModel) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error)
```

Generate implements the ChatModel interface.

<a name="AdvancedMockChatModel.GetCallCount"></a>
### func \(\*AdvancedMockChatModel\) [GetCallCount](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L389>)

```go
func (m *AdvancedMockChatModel) GetCallCount() int
```

GetCallCount returns the number of times methods were called.

<a name="AdvancedMockChatModel.GetModelName"></a>
### func \(\*AdvancedMockChatModel\) [GetModelName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L244>)

```go
func (m *AdvancedMockChatModel) GetModelName() string
```

GetModelName implements the ChatModel interface.

<a name="AdvancedMockChatModel.GetProviderName"></a>
### func \(\*AdvancedMockChatModel\) [GetProviderName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L249>)

```go
func (m *AdvancedMockChatModel) GetProviderName() string
```

GetProviderName returns the provider name.

<a name="AdvancedMockChatModel.Invoke"></a>
### func \(\*AdvancedMockChatModel\) [Invoke](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L254>)

```go
func (m *AdvancedMockChatModel) Invoke(ctx context.Context, input any, options ...core.Option) (any, error)
```

Invoke implements the Runnable interface.

<a name="AdvancedMockChatModel.Reset"></a>
### func \(\*AdvancedMockChatModel\) [Reset](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L396>)

```go
func (m *AdvancedMockChatModel) Reset()
```

Reset resets the mock state.

<a name="AdvancedMockChatModel.Stream"></a>
### func \(\*AdvancedMockChatModel\) [Stream](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L313>)

```go
func (m *AdvancedMockChatModel) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error)
```

Stream implements the Runnable interface.

<a name="AdvancedMockChatModel.StreamChat"></a>
### func \(\*AdvancedMockChatModel\) [StreamChat](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L146>)

```go
func (m *AdvancedMockChatModel) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan iface.AIMessageChunk, error)
```

StreamChat implements the ChatModel interface with realistic streaming.

<a name="AdvancedMockLLM"></a>
## type [AdvancedMockLLM](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L407-L413>)

AdvancedMockLLM provides a mock LLM implementation.

```go
type AdvancedMockLLM struct {
    mock.Mock
    // contains filtered or unexported fields
}
```

<a name="NewAdvancedMockLLM"></a>
### func [NewAdvancedMockLLM](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L415>)

```go
func NewAdvancedMockLLM(modelName string) *AdvancedMockLLM
```

<a name="AdvancedMockLLM.GetModelName"></a>
### func \(\*AdvancedMockLLM\) [GetModelName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L437>)

```go
func (m *AdvancedMockLLM) GetModelName() string
```

<a name="AdvancedMockLLM.GetProviderName"></a>
### func \(\*AdvancedMockLLM\) [GetProviderName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L441>)

```go
func (m *AdvancedMockLLM) GetProviderName() string
```

<a name="AdvancedMockLLM.Invoke"></a>
### func \(\*AdvancedMockLLM\) [Invoke](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L422>)

```go
func (m *AdvancedMockLLM) Invoke(ctx context.Context, input any, options ...core.Option) (any, error)
```

<a name="CallOptions"></a>
## type [CallOptions](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L258-L269>)

CallOptions represents runtime call options for LLM invocations.

```go
type CallOptions struct {
    Temperature      *float32       `json:"temperature,omitempty"`
    TopP             *float32       `json:"top_p,omitempty"`
    TopK             *int           `json:"top_k,omitempty"`
    MaxTokens        *int           `json:"max_tokens,omitempty"`
    FrequencyPenalty *float32       `json:"frequency_penalty,omitempty"`
    PresencePenalty  *float32       `json:"presence_penalty,omitempty"`
    AdditionalArgs   map[string]any `json:"additional_args,omitempty"`
    ToolChoice       string         `json:"tool_choice,omitempty"`
    StopSequences    []string       `json:"stop_sequences,omitempty"`
    Tools            []any          `json:"tools,omitempty"`
}
```

<a name="NewCallOptions"></a>
### func [NewCallOptions](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L272>)

```go
func NewCallOptions() *CallOptions
```

NewCallOptions creates new call options.

<a name="CallOptions.ApplyCallOption"></a>
### func \(\*CallOptions\) [ApplyCallOption](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L279>)

```go
func (co *CallOptions) ApplyCallOption(opt core.Option)
```

ApplyCallOption applies a core.Option to CallOptions.

<a name="ChatModel"></a>
## type [ChatModel](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L49-L55>)

ChatModel defines the core interface for chat\-based language models. It combines message generation with model information and health checking capabilities. This follows the Interface Segregation Principle while providing a composite interface for the most common use cases.

```go
type ChatModel interface {
    MessageGenerator
    StreamMessageHandler
    ModelInfoProvider
    HealthChecker
    core.Runnable // Embed core Runnable for consistency with framework
}
```

### Example (Batch)

Example demonstrating batch processing.

```go
package main

import (
	"context"
	"fmt"
	"log"

	"github.com/lookatitude/beluga-ai/pkg/agents/tools"
	"github.com/lookatitude/beluga-ai/pkg/core"
	"github.com/lookatitude/beluga-ai/pkg/llms/iface"
	"github.com/lookatitude/beluga-ai/pkg/schema"
	"github.com/stretchr/testify/mock"
)

func main() {
	mockModel := &MockChatModel{modelName: "batch-example"}

	// Mock batch response
	// Note: In a real test, you'd set up mock expectations here

	// Prepare batch inputs
	inputs := []any{
		[]schema.Message{schema.NewHumanMessage("Question 1")},
		[]schema.Message{schema.NewHumanMessage("Question 2")},
		[]schema.Message{schema.NewHumanMessage("Question 3")},
	}

	// Execute batch
	results, err := mockModel.Batch(context.Background(), inputs)
	if err != nil {
		log.Fatal(err)
	}

	if _, err := fmt.Printf("Processed %d items in batch\n", len(results)); err != nil {
		log.Printf("Failed to print: %v", err)
	}
	for i, result := range results {
		if msg, ok := result.(schema.Message); ok {
			if _, err := fmt.Printf("Result %d: %s\n", i+1, msg.GetContent()); err != nil {
				log.Printf("Failed to print: %v", err)
			}
		}
	}
	// Note: In a real test, you'd assert expectations here
	// Output:
	// Processed 3 items in batch
	// Result 1: Response 1
	// Result 2: Response 2
	// Result 3: Response 3
}

type MockChatModel struct {
	mock.Mock
	modelName string
}

func (m *MockChatModel) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error) {
	return schema.NewAIMessage("Mock response"), nil
}

func (m *MockChatModel) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan iface.AIMessageChunk, error) {
	ch := make(chan iface.AIMessageChunk, 1)
	ch <- iface.AIMessageChunk{Content: "Mock stream"}
	close(ch)
	return ch, nil
}

func (m *MockChatModel) BindTools(toolsToBind []tools.Tool) iface.ChatModel {
	return m
}

func (m *MockChatModel) GetModelName() string {
	return m.modelName
}

func (m *MockChatModel) GetProviderName() string {
	return "mock"
}

func (m *MockChatModel) Invoke(ctx context.Context, input any, options ...core.Option) (any, error) {
	return "Mock invoke result", nil
}

func (m *MockChatModel) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error) {
	results := make([]any, len(inputs))
	for i := range results {
		results[i] = schema.NewAIMessage(fmt.Sprintf("Batch response %d", i+1))
	}
	return results, nil
}

func (m *MockChatModel) CheckHealth() map[string]any {
	return map[string]any{
		"state":         "healthy",
		"provider":      "mock",
		"model":         m.modelName,
		"timestamp":     int64(1234567890),
		"call_count":    0,
		"tools_count":   0,
		"should_error":  false,
		"responses_len": 1,
	}
}

func (m *MockChatModel) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error) {
	ch := make(chan any, 1)
	ch <- "Mock stream result"
	close(ch)
	return ch, nil
}
```

### Example (Bind Tools)

Example demonstrating tool binding.

```go
package main

import (
	"context"
	"fmt"
	"log"

	"github.com/lookatitude/beluga-ai/pkg/agents/tools"
	"github.com/lookatitude/beluga-ai/pkg/core"
	"github.com/lookatitude/beluga-ai/pkg/llms/iface"
	"github.com/lookatitude/beluga-ai/pkg/schema"
	"github.com/stretchr/testify/mock"
)

func main() {
	mockModel := &MockChatModel{modelName: "tool-example"}

	// Mock tools
	tools := []tools.Tool{
		&MockTool{name: "calculator", description: "Performs calculations"},
		&MockTool{name: "search", description: "Searches the web"},
	}

	// Mock binding behavior
	// Note: In a real test, you'd set up mock expectations here

	// Bind tools
	modelWithTools := mockModel.BindTools(tools)

	if _, err := fmt.Printf("Model with tools: %s\n", modelWithTools.GetModelName()); err != nil {
		log.Printf("Failed to print: %v", err)
	}
	// Note: In a real test, you'd assert expectations here
	// Output: Model with tools: tool-example
}

type MockChatModel struct {
	mock.Mock
	modelName string
}

func (m *MockChatModel) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error) {
	return schema.NewAIMessage("Mock response"), nil
}

func (m *MockChatModel) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan iface.AIMessageChunk, error) {
	ch := make(chan iface.AIMessageChunk, 1)
	ch <- iface.AIMessageChunk{Content: "Mock stream"}
	close(ch)
	return ch, nil
}

func (m *MockChatModel) BindTools(toolsToBind []tools.Tool) iface.ChatModel {
	return m
}

func (m *MockChatModel) GetModelName() string {
	return m.modelName
}

func (m *MockChatModel) GetProviderName() string {
	return "mock"
}

func (m *MockChatModel) Invoke(ctx context.Context, input any, options ...core.Option) (any, error) {
	return "Mock invoke result", nil
}

func (m *MockChatModel) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error) {
	results := make([]any, len(inputs))
	for i := range results {
		results[i] = schema.NewAIMessage(fmt.Sprintf("Batch response %d", i+1))
	}
	return results, nil
}

func (m *MockChatModel) CheckHealth() map[string]any {
	return map[string]any{
		"state":         "healthy",
		"provider":      "mock",
		"model":         m.modelName,
		"timestamp":     int64(1234567890),
		"call_count":    0,
		"tools_count":   0,
		"should_error":  false,
		"responses_len": 1,
	}
}

func (m *MockChatModel) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error) {
	ch := make(chan any, 1)
	ch <- "Mock stream result"
	close(ch)
	return ch, nil
}

type MockTool struct {
	name        string
	description string
}

func (m *MockTool) Name() string        { return m.name }
func (m *MockTool) Description() string { return m.description }
func (m *MockTool) Definition() tools.ToolDefinition {
	return tools.ToolDefinition{
		Name:        m.name,
		Description: m.description,
		InputSchema: "{}",
	}
}

func (m *MockTool) Execute(ctx context.Context, input any) (any, error) {
	return "mock tool result", nil
}

func (m *MockTool) Batch(ctx context.Context, inputs []any) ([]any, error) {
	results := make([]any, len(inputs))
	for i := range inputs {
		results[i] = "mock tool batch result"
	}
	return results, nil
}
```

### Example (Stream Chat)

Example demonstrating streaming \(mock implementation\).

```go
package main

import (
	"context"
	"fmt"
	"log"
	"strings"

	"github.com/lookatitude/beluga-ai/pkg/agents/tools"
	"github.com/lookatitude/beluga-ai/pkg/core"
	"github.com/lookatitude/beluga-ai/pkg/llms/iface"
	"github.com/lookatitude/beluga-ai/pkg/schema"
	"github.com/stretchr/testify/mock"
)

func main() {
	// This is a mock example - in real usage, you'd use an actual provider
	mockModel := &MockChatModel{modelName: "streaming-example"}

	// Create mock streaming channel
	streamChan := make(chan iface.AIMessageChunk, 3)
	streamChan <- iface.AIMessageChunk{Content: "Hello"}
	streamChan <- iface.AIMessageChunk{Content: " world"}
	streamChan <- iface.AIMessageChunk{Content: "!"}
	close(streamChan)

	// Note: In a real test, you'd set up mock expectations here
	// For this example, we directly use the mock implementation

	// Use streaming
	messages := []schema.Message{schema.NewHumanMessage("Say hello")}
	resultChan, err := mockModel.StreamChat(context.Background(), messages)
	if err != nil {
		log.Fatal(err)
	}

	// Collect streaming results
	var fullContent string
	var fullContentSb110 strings.Builder
	for chunk := range resultChan {
		if chunk.Err != nil {
			log.Printf("Stream error: %v", chunk.Err)
			break
		}
		if _, err := fullContentSb110.WriteString(chunk.Content); err != nil {
			log.Printf("Failed to write: %v", err)
		}
		if _, err := fmt.Printf("Received: %s\n", chunk.Content); err != nil {
			log.Printf("Failed to print: %v", err)
		}
	}
	fullContent += fullContentSb110.String()

	if _, err := fmt.Printf("Full content: %s\n", fullContent); err != nil {
		log.Printf("Failed to print: %v", err)
	}
	// Note: In a real test, you'd assert expectations here
	// Output:
	// Received: Hello
	// Received: world
	// Received: !
	// Full content: Hello world!
}

type MockChatModel struct {
	mock.Mock
	modelName string
}

func (m *MockChatModel) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error) {
	return schema.NewAIMessage("Mock response"), nil
}

func (m *MockChatModel) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan iface.AIMessageChunk, error) {
	ch := make(chan iface.AIMessageChunk, 1)
	ch <- iface.AIMessageChunk{Content: "Mock stream"}
	close(ch)
	return ch, nil
}

func (m *MockChatModel) BindTools(toolsToBind []tools.Tool) iface.ChatModel {
	return m
}

func (m *MockChatModel) GetModelName() string {
	return m.modelName
}

func (m *MockChatModel) GetProviderName() string {
	return "mock"
}

func (m *MockChatModel) Invoke(ctx context.Context, input any, options ...core.Option) (any, error) {
	return "Mock invoke result", nil
}

func (m *MockChatModel) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error) {
	results := make([]any, len(inputs))
	for i := range results {
		results[i] = schema.NewAIMessage(fmt.Sprintf("Batch response %d", i+1))
	}
	return results, nil
}

func (m *MockChatModel) CheckHealth() map[string]any {
	return map[string]any{
		"state":         "healthy",
		"provider":      "mock",
		"model":         m.modelName,
		"timestamp":     int64(1234567890),
		"call_count":    0,
		"tools_count":   0,
		"should_error":  false,
		"responses_len": 1,
	}
}

func (m *MockChatModel) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error) {
	ch := make(chan any, 1)
	ch <- "Mock stream result"
	close(ch)
	return ch, nil
}
```

<a name="ChatModelAdapter"></a>
## type [ChatModelAdapter](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L285-L288>)

ChatModelAdapter wraps an LLM to provide the ChatModel interface.

```go
type ChatModelAdapter struct {
    // contains filtered or unexported fields
}
```

<a name="NewChatModelAdapter"></a>
### func [NewChatModelAdapter](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L291>)

```go
func NewChatModelAdapter(llm iface.LLM, options *ChatOptions) *ChatModelAdapter
```

NewChatModelAdapter creates a new ChatModelAdapter.

<a name="ChatModelAdapter.Batch"></a>
### func \(\*ChatModelAdapter\) [Batch](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L368>)

```go
func (c *ChatModelAdapter) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error)
```

Batch implements the Runnable interface.

<a name="ChatModelAdapter.CheckHealth"></a>
### func \(\*ChatModelAdapter\) [CheckHealth](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L345>)

```go
func (c *ChatModelAdapter) CheckHealth() map[string]any
```

CheckHealth implements the HealthChecker interface.

<a name="ChatModelAdapter.GenerateMessages"></a>
### func \(\*ChatModelAdapter\) [GenerateMessages](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L299>)

```go
func (c *ChatModelAdapter) GenerateMessages(ctx context.Context, messages []schema.Message, options ...core.Option) ([]schema.Message, error)
```

GenerateMessages implements the MessageGenerator interface.

<a name="ChatModelAdapter.GetModelInfo"></a>
### func \(\*ChatModelAdapter\) [GetModelInfo](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L334>)

```go
func (c *ChatModelAdapter) GetModelInfo() ModelInfo
```

GetModelInfo implements the ModelInfoProvider interface.

<a name="ChatModelAdapter.Invoke"></a>
### func \(\*ChatModelAdapter\) [Invoke](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L355>)

```go
func (c *ChatModelAdapter) Invoke(ctx context.Context, input any, options ...core.Option) (any, error)
```

Invoke implements the Runnable interface.

<a name="ChatModelAdapter.Stream"></a>
### func \(\*ChatModelAdapter\) [Stream](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L381>)

```go
func (c *ChatModelAdapter) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error)
```

Stream implements the Runnable interface.

<a name="ChatModelAdapter.StreamMessages"></a>
### func \(\*ChatModelAdapter\) [StreamMessages](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L319>)

```go
func (c *ChatModelAdapter) StreamMessages(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan schema.Message, error)
```

StreamMessages implements the StreamMessageHandler interface.

<a name="ChatModelFactory"></a>
## type [ChatModelFactory](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L100-L103>)

ChatModelFactory defines the interface for creating chat model instances. It enables dependency injection and different chat model creation strategies.

```go
type ChatModelFactory interface {
    // CreateChatModel creates a new chat model instance based on the provided configuration.
    CreateChatModel(ctx context.Context, config any) (ChatModel, error)
}
```

<a name="ChatOption"></a>
## type [ChatOption](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L67-L69>)

ChatOption represents a functional option for configuring chat models.

```go
type ChatOption interface {
    Apply(config *map[string]any)
}
```

<a name="ChatOptionFunc"></a>
### func [ChatOptionFunc](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L80>)

```go
func ChatOptionFunc(f func(config *map[string]any)) ChatOption
```

ChatOptionFunc creates a new ChatOption that executes the provided function.

<a name="WithChatFunctionCalling"></a>
### func [WithChatFunctionCalling](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L141>)

```go
func WithChatFunctionCalling(enabled bool) ChatOption
```

WithChatFunctionCalling enables or disables function calling for chat models.

<a name="WithChatMaxRetries"></a>
### func [WithChatMaxRetries](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L155>)

```go
func WithChatMaxRetries(maxRetries int) ChatOption
```

WithChatMaxRetries sets the maximum retries for chat model operations.

<a name="WithChatMaxTokens"></a>
### func [WithChatMaxTokens](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L113>)

```go
func WithChatMaxTokens(maxTokens int) ChatOption
```

WithChatMaxTokens sets the maximum tokens for chat model generation.

<a name="WithChatObservability"></a>
### func [WithChatObservability](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L162>)

```go
func WithChatObservability(metrics, tracing bool) ChatOption
```

WithChatObservability enables or disables observability features for chat models.

<a name="WithChatStopSequences"></a>
### func [WithChatStopSequences](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L127>)

```go
func WithChatStopSequences(sequences []string) ChatOption
```

WithChatStopSequences sets the stop sequences for chat model generation.

<a name="WithChatSystemPrompt"></a>
### func [WithChatSystemPrompt](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L134>)

```go
func WithChatSystemPrompt(prompt string) ChatOption
```

WithChatSystemPrompt sets the system prompt for chat model generation.

<a name="WithChatTemperature"></a>
### func [WithChatTemperature](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L106>)

```go
func WithChatTemperature(temp float32) ChatOption
```

WithChatTemperature sets the temperature for chat model generation.

<a name="WithChatTimeout"></a>
### func [WithChatTimeout](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L148>)

```go
func WithChatTimeout(timeout time.Duration) ChatOption
```

WithChatTimeout sets the timeout for chat model operations.

<a name="WithChatTopP"></a>
### func [WithChatTopP](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L120>)

```go
func WithChatTopP(topP float32) ChatOption
```

WithChatTopP sets the top\-p value for chat model generation.

<a name="ChatOptions"></a>
## type [ChatOptions](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L85-L96>)

ChatOptions holds the configuration options for chat models.

```go
type ChatOptions struct {
    SystemPrompt    string
    StopSequences   []string
    MaxTokens       int
    Timeout         time.Duration
    MaxRetries      int
    Temperature     float32
    TopP            float32
    FunctionCalling bool
    EnableMetrics   bool
    EnableTracing   bool
}
```

<a name="Config"></a>
## type [Config](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L16-L39>)

Config represents the configuration for LLM providers. It includes common settings that apply to all LLM providers.

```go
type Config struct {
    FrequencyPenalty        *float32       `mapstructure:"frequency_penalty" yaml:"frequency_penalty" validate:"omitempty,gte=-2,lte=2"`
    PresencePenalty         *float32       `mapstructure:"presence_penalty" yaml:"presence_penalty" validate:"omitempty,gte=-2,lte=2"`
    ProviderSpecific        map[string]any `mapstructure:"provider_specific" yaml:"provider_specific"`
    MaxTokens               *int           `mapstructure:"max_tokens" yaml:"max_tokens" validate:"omitempty,gte=1,lte=32768"`
    TopK                    *int           `mapstructure:"top_k" yaml:"top_k" validate:"omitempty,gte=1,lte=100"`
    Temperature             *float32       `mapstructure:"temperature" yaml:"temperature" validate:"omitempty,gte=0,lte=2"`
    TopP                    *float32       `mapstructure:"top_p" yaml:"top_p" validate:"omitempty,gte=0,lte=1"`
    BaseURL                 string         `mapstructure:"base_url" yaml:"base_url"`
    APIKey                  string         `mapstructure:"api_key" yaml:"api_key" validate:"required_unless=Provider mock"`
    ModelName               string         `mapstructure:"model_name" yaml:"model_name" validate:"required"`
    Provider                string         `mapstructure:"provider" yaml:"provider" validate:"required,oneof=openai anthropic bedrock gemini ollama mock"`
    StopSequences           []string       `mapstructure:"stop_sequences" yaml:"stop_sequences"`
    RetryDelay              time.Duration  `mapstructure:"retry_delay" yaml:"retry_delay" default:"1s" validate:"min=100ms,max=30s"`
    Timeout                 time.Duration  `mapstructure:"timeout" yaml:"timeout" default:"30s" validate:"min=1s,max=5m"`
    MaxRetries              int            `mapstructure:"max_retries" yaml:"max_retries" default:"3" validate:"gte=0,lte=10"`
    MaxConcurrentBatches    int            `mapstructure:"max_concurrent_batches" yaml:"max_concurrent_batches" default:"5" validate:"gte=1,lte=100"`
    RetryBackoff            float64        `mapstructure:"retry_backoff" yaml:"retry_backoff" default:"2.0" validate:"gte=1,lte=5"`
    EnableStreaming         bool           `mapstructure:"enable_streaming" yaml:"enable_streaming" default:"true"`
    EnableTracing           bool           `mapstructure:"enable_tracing" yaml:"enable_tracing" default:"true"`
    EnableMetrics           bool           `mapstructure:"enable_metrics" yaml:"enable_metrics" default:"true"`
    EnableStructuredLogging bool           `mapstructure:"enable_structured_logging" yaml:"enable_structured_logging" default:"true"`
    EnableToolCalling       bool           `mapstructure:"enable_tool_calling" yaml:"enable_tool_calling" default:"true"`
}
```

<a name="CreateTestConfig"></a>
### func [CreateTestConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L583>)

```go
func CreateTestConfig() *Config
```

CreateTestConfig creates a test configuration.

<a name="DefaultConfig"></a>
### func [DefaultConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L340>)

```go
func DefaultConfig() *Config
```

DefaultConfig returns a default configuration for LLM operations.

<a name="NewConfig"></a>
### func [NewConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L201>)

```go
func NewConfig(opts ...ConfigOption) *Config
```

NewConfig creates a new configuration with the given options.

### Example

Example demonstrating configuration usage.

```go
package main

import (
	"context"
	"fmt"
	"log"
	"time"

	"github.com/lookatitude/beluga-ai/pkg/llms"
)

func main() {
	// Create configuration with functional options
	config := llms.NewConfig(
		llms.WithProvider("anthropic"),
		llms.WithModelName("claude-3-sonnet-20240229"),
		llms.WithAPIKey("your-api-key"),
		llms.WithTemperatureConfig(0.7),
		llms.WithMaxTokensConfig(1024),
		llms.WithMaxConcurrentBatches(5),
		llms.WithRetryConfig(3, time.Second, 2.0),
	)

	// Validate configuration
	if err := llms.ValidateProviderConfig(context.Background(), config); err != nil {
		log.Printf("Configuration error: %v", err)
		return
	}

	if _, err := fmt.Printf("Config validated for provider: %s\n", config.Provider); err != nil {
		log.Printf("Failed to print: %v", err)
	}
}
```

#### Output

```
Config validated for provider: anthropic
```

<a name="NewDefaultConfig"></a>
### func [NewDefaultConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L157>)

```go
func NewDefaultConfig() *Config
```

NewDefaultConfig returns a default configuration.

<a name="Config.MergeOptions"></a>
### func \(\*Config\) [MergeOptions](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L194>)

```go
func (c *Config) MergeOptions(opts ...ConfigOption)
```

MergeOptions applies functional options to the configuration.

<a name="Config.Validate"></a>
### func \(\*Config\) [Validate](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L185>)

```go
func (c *Config) Validate() error
```

Validate validates the configuration.

<a name="ConfigOption"></a>
## type [ConfigOption](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L42>)

ConfigOption is a functional option for configuring LLM instances.

```go
type ConfigOption func(*Config)
```

<a name="WithAPIKey"></a>
### func [WithAPIKey](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L59>)

```go
func WithAPIKey(apiKey string) ConfigOption
```

WithAPIKey sets the API key.

<a name="WithBaseURL"></a>
### func [WithBaseURL](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L66>)

```go
func WithBaseURL(baseURL string) ConfigOption
```

WithBaseURL sets the base URL.

<a name="WithMaxConcurrentBatches"></a>
### func [WithMaxConcurrentBatches](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L115>)

```go
func WithMaxConcurrentBatches(n int) ConfigOption
```

WithMaxConcurrentBatches sets the maximum concurrent batches.

<a name="WithMaxTokensConfig"></a>
### func [WithMaxTokensConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L101>)

```go
func WithMaxTokensConfig(maxTokens int) ConfigOption
```

WithMaxTokensConfig sets the maximum tokens.

<a name="WithModelName"></a>
### func [WithModelName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L52>)

```go
func WithModelName(modelName string) ConfigOption
```

WithModelName sets the model name.

<a name="WithObservability"></a>
### func [WithObservability](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L141>)

```go
func WithObservability(tracing, metrics, logging bool) ConfigOption
```

WithObservability enables or disables observability features.

<a name="WithProvider"></a>
### func [WithProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L45>)

```go
func WithProvider(provider string) ConfigOption
```

WithProvider sets the LLM provider.

<a name="WithProviderSpecific"></a>
### func [WithProviderSpecific](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L131>)

```go
func WithProviderSpecific(key string, value any) ConfigOption
```

WithProviderSpecific sets provider\-specific configuration.

<a name="WithRetryConfig"></a>
### func [WithRetryConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L122>)

```go
func WithRetryConfig(maxRetries int, delay time.Duration, backoff float64) ConfigOption
```

WithRetryConfig sets retry configuration.

<a name="WithStopSequences"></a>
### func [WithStopSequences](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L108>)

```go
func WithStopSequences(sequences []string) ConfigOption
```

WithStopSequences sets the stop sequences.

<a name="WithTemperatureConfig"></a>
### func [WithTemperatureConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L80>)

```go
func WithTemperatureConfig(temp float32) ConfigOption
```

WithTemperatureConfig sets the temperature.

<a name="WithTimeout"></a>
### func [WithTimeout](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L73>)

```go
func WithTimeout(timeout time.Duration) ConfigOption
```

WithTimeout sets the timeout.

<a name="WithToolCalling"></a>
### func [WithToolCalling](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L150>)

```go
func WithToolCalling(enabled bool) ConfigOption
```

WithToolCalling enables or disables tool calling.

<a name="WithTopKConfig"></a>
### func [WithTopKConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L94>)

```go
func WithTopKConfig(topK int) ConfigOption
```

WithTopKConfig sets the top\-k value.

<a name="WithTopPConfig"></a>
### func [WithTopPConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L87>)

```go
func WithTopPConfig(topP float32) ConfigOption
```

WithTopPConfig sets the top\-p value.

<a name="ConfigValidationError"></a>
## type [ConfigValidationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L241-L243>)

ConfigValidationError represents multiple validation errors.

```go
type ConfigValidationError struct {
    Errors []ValidationError
}
```

<a name="ConfigValidationError.AddError"></a>
### func \(\*ConfigValidationError\) [AddError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L257>)

```go
func (e *ConfigValidationError) AddError(field string, value any, message string)
```

AddError adds a validation error.

<a name="ConfigValidationError.Error"></a>
### func \(\*ConfigValidationError\) [Error](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L246>)

```go
func (e *ConfigValidationError) Error() string
```

Error implements the error interface.

<a name="ConfigValidationError.HasErrors"></a>
### func \(\*ConfigValidationError\) [HasErrors](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L266>)

```go
func (e *ConfigValidationError) HasErrors() bool
```

HasErrors checks if there are any validation errors.

<a name="Factory"></a>
## type [Factory](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L40-L46>)

Factory provides a factory pattern for creating LLM instances. It manages the creation of different LLM providers based on configuration.

```go
type Factory struct {
    // contains filtered or unexported fields
}
```

<a name="InitializeDefaultFactory"></a>
### func [InitializeDefaultFactory](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L553>)

```go
func InitializeDefaultFactory() *Factory
```

InitializeDefaultFactory creates and returns a factory with all built\-in providers registered.

<a name="NewFactory"></a>
### func [NewFactory](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L49>)

```go
func NewFactory() *Factory
```

NewFactory creates a new LLM factory.

### Example

Example demonstrating basic ChatModel usage.

```go
package main

import (
	"context"
	"fmt"
	"log"

	"github.com/lookatitude/beluga-ai/pkg/agents/tools"
	"github.com/lookatitude/beluga-ai/pkg/core"
	"github.com/lookatitude/beluga-ai/pkg/llms"
	"github.com/lookatitude/beluga-ai/pkg/llms/iface"
	"github.com/lookatitude/beluga-ai/pkg/schema"
	"github.com/stretchr/testify/mock"
)

func main() {
	// Create a new factory
	factory := llms.NewFactory()

	// Register a mock provider for demonstration
	mockModel := &MockChatModel{modelName: "example-model"}
	factory.RegisterProvider("example", mockModel)

	// Retrieve the provider
	model, err := factory.GetProvider("example")
	if err != nil {
		log.Fatal(err)
	}

	if _, err := fmt.Printf("Retrieved model: %s\n", model.GetModelName()); err != nil {
		log.Printf("Failed to print: %v", err)
	}
}

type MockChatModel struct {
	mock.Mock
	modelName string
}

func (m *MockChatModel) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error) {
	return schema.NewAIMessage("Mock response"), nil
}

func (m *MockChatModel) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan iface.AIMessageChunk, error) {
	ch := make(chan iface.AIMessageChunk, 1)
	ch <- iface.AIMessageChunk{Content: "Mock stream"}
	close(ch)
	return ch, nil
}

func (m *MockChatModel) BindTools(toolsToBind []tools.Tool) iface.ChatModel {
	return m
}

func (m *MockChatModel) GetModelName() string {
	return m.modelName
}

func (m *MockChatModel) GetProviderName() string {
	return "mock"
}

func (m *MockChatModel) Invoke(ctx context.Context, input any, options ...core.Option) (any, error) {
	return "Mock invoke result", nil
}

func (m *MockChatModel) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error) {
	results := make([]any, len(inputs))
	for i := range results {
		results[i] = schema.NewAIMessage(fmt.Sprintf("Batch response %d", i+1))
	}
	return results, nil
}

func (m *MockChatModel) CheckHealth() map[string]any {
	return map[string]any{
		"state":         "healthy",
		"provider":      "mock",
		"model":         m.modelName,
		"timestamp":     int64(1234567890),
		"call_count":    0,
		"tools_count":   0,
		"should_error":  false,
		"responses_len": 1,
	}
}

func (m *MockChatModel) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error) {
	ch := make(chan any, 1)
	ch <- "Mock stream result"
	close(ch)
	return ch, nil
}
```

#### Output

```
Retrieved model: example-model
```

<a name="Factory.CreateLLM"></a>
### func \(\*Factory\) [CreateLLM](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L142>)

```go
func (f *Factory) CreateLLM(providerName string, config *Config) (iface.LLM, error)
```

CreateLLM creates an LLM instance using the registered factory.

<a name="Factory.CreateProvider"></a>
### func \(\*Factory\) [CreateProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L123>)

```go
func (f *Factory) CreateProvider(providerName string, config *Config) (iface.ChatModel, error)
```

CreateProvider creates a provider instance using the registered factory.

<a name="Factory.GetLLM"></a>
### func \(\*Factory\) [GetLLM](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L86>)

```go
func (f *Factory) GetLLM(name string) (iface.LLM, error)
```

GetLLM returns a registered LLM provider.

<a name="Factory.GetProvider"></a>
### func \(\*Factory\) [GetProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L73>)

```go
func (f *Factory) GetProvider(name string) (iface.ChatModel, error)
```

GetProvider returns a registered ChatModel provider.

<a name="Factory.ListAvailableProviders"></a>
### func \(\*Factory\) [ListAvailableProviders](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L161>)

```go
func (f *Factory) ListAvailableProviders() []string
```

ListAvailableProviders returns a list of all available provider names.

<a name="Factory.ListLLMs"></a>
### func \(\*Factory\) [ListLLMs](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L111>)

```go
func (f *Factory) ListLLMs() []string
```

ListLLMs returns a list of all registered LLM names.

<a name="Factory.ListProviders"></a>
### func \(\*Factory\) [ListProviders](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L99>)

```go
func (f *Factory) ListProviders() []string
```

ListProviders returns a list of all registered provider names.

<a name="Factory.RegisterLLM"></a>
### func \(\*Factory\) [RegisterLLM](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L66>)

```go
func (f *Factory) RegisterLLM(name string, llm iface.LLM)
```

RegisterLLM registers an LLM provider with the factory.

<a name="Factory.RegisterLLMFactory"></a>
### func \(\*Factory\) [RegisterLLMFactory](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L179>)

```go
func (f *Factory) RegisterLLMFactory(name string, factory func(*Config) (iface.LLM, error))
```

<a name="Factory.RegisterProvider"></a>
### func \(\*Factory\) [RegisterProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L59>)

```go
func (f *Factory) RegisterProvider(name string, provider iface.ChatModel)
```

RegisterProvider registers a ChatModel provider with the factory.

<a name="Factory.RegisterProviderFactory"></a>
### func \(\*Factory\) [RegisterProviderFactory](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L173>)

```go
func (f *Factory) RegisterProviderFactory(name string, factory func(*Config) (iface.ChatModel, error))
```

RegisterProviderFactory registers a provider factory function.

<a name="HealthChecker"></a>
## type [HealthChecker](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L40-L43>)

HealthChecker defines the interface for health checking chat model components.

```go
type HealthChecker interface {
    // CheckHealth returns the health status information.
    CheckHealth() map[string]any
}
```

<a name="IntegrationTestConfig"></a>
## type [IntegrationTestConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L28-L45>)

IntegrationTestConfig holds configuration for integration tests.

```go
type IntegrationTestConfig struct {
    // Provider configurations
    AnthropicAPIKey string
    OpenAIAPIKey    string
    BedrockRegion   string
    OllamaBaseURL   string

    // Test settings
    Timeout       time.Duration
    MaxRetries    int
    SkipExpensive bool // Skip tests that cost money or take long time
    Verbose       bool

    // Safety limits
    MaxTokensPerTest int
    MaxRequests      int
    RequestDelay     time.Duration
}
```

<a name="DefaultIntegrationTestConfig"></a>
### func [DefaultIntegrationTestConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L48>)

```go
func DefaultIntegrationTestConfig() *IntegrationTestConfig
```

DefaultIntegrationTestConfig returns a default configuration for integration tests.

<a name="LoadIntegrationTestConfig"></a>
### func [LoadIntegrationTestConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L61>)

```go
func LoadIntegrationTestConfig() *IntegrationTestConfig
```

LoadIntegrationTestConfig loads configuration from environment variables.

<a name="IntegrationTestHelper"></a>
## type [IntegrationTestHelper](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L95-L101>)

IntegrationTestHelper provides utilities for integration testing.

```go
type IntegrationTestHelper struct {
    // contains filtered or unexported fields
}
```

<a name="NewIntegrationTestHelper"></a>
### func [NewIntegrationTestHelper](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L104>)

```go
func NewIntegrationTestHelper() *IntegrationTestHelper
```

NewIntegrationTestHelper creates a new integration test helper.

<a name="IntegrationTestHelper.GetConfig"></a>
### func \(\*IntegrationTestHelper\) [GetConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L237>)

```go
func (h *IntegrationTestHelper) GetConfig() *Config
```

GetConfig returns the test configuration as \*Config for compatibility.

<a name="IntegrationTestHelper.GetFactory"></a>
### func \(\*IntegrationTestHelper\) [GetFactory](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L232>)

```go
func (h *IntegrationTestHelper) GetFactory() *Factory
```

GetFactory returns the factory.

<a name="IntegrationTestHelper.GetMetrics"></a>
### func \(\*IntegrationTestHelper\) [GetMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L250>)

```go
func (h *IntegrationTestHelper) GetMetrics() *MockMetricsRecorder
```

GetMetrics returns a mock metrics recorder.

<a name="IntegrationTestHelper.GetTracing"></a>
### func \(\*IntegrationTestHelper\) [GetTracing](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L255>)

```go
func (h *IntegrationTestHelper) GetTracing() *MockTracingHelper
```

GetTracing returns a mock tracing helper.

<a name="IntegrationTestHelper.RateLimit"></a>
### func \(\*IntegrationTestHelper\) [RateLimit](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L196>)

```go
func (h *IntegrationTestHelper) RateLimit()
```

RateLimit enforces rate limiting between requests.

<a name="IntegrationTestHelper.SetupAnthropicProvider"></a>
### func \(\*IntegrationTestHelper\) [SetupAnthropicProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L132>)

```go
func (h *IntegrationTestHelper) SetupAnthropicProvider(modelName string) (iface.ChatModel, error)
```

SetupAnthropicProvider sets up an Anthropic provider.

<a name="IntegrationTestHelper.SetupBedrockProvider"></a>
### func \(\*IntegrationTestHelper\) [SetupBedrockProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L168>)

```go
func (h *IntegrationTestHelper) SetupBedrockProvider(modelName string) (iface.ChatModel, error)
```

SetupBedrockProvider sets up an AWS Bedrock provider.

<a name="IntegrationTestHelper.SetupMockProvider"></a>
### func \(\*IntegrationTestHelper\) [SetupMockProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L214>)

```go
func (h *IntegrationTestHelper) SetupMockProvider(providerName, modelName string, opts ...any) iface.ChatModel
```

SetupMockProvider sets up a mock provider for integration testing.

<a name="IntegrationTestHelper.SetupOllamaProvider"></a>
### func \(\*IntegrationTestHelper\) [SetupOllamaProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L182>)

```go
func (h *IntegrationTestHelper) SetupOllamaProvider(modelName string) (iface.ChatModel, error)
```

SetupOllamaProvider sets up an Ollama provider.

<a name="IntegrationTestHelper.SetupOpenAIProvider"></a>
### func \(\*IntegrationTestHelper\) [SetupOpenAIProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L150>)

```go
func (h *IntegrationTestHelper) SetupOpenAIProvider(modelName string) (iface.ChatModel, error)
```

SetupOpenAIProvider sets up an OpenAI provider.

<a name="IntegrationTestHelper.SetupProvider"></a>
### func \(\*IntegrationTestHelper\) [SetupProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L117>)

```go
func (h *IntegrationTestHelper) SetupProvider(providerName string, config *Config) (iface.ChatModel, error)
```

SetupProvider sets up a provider for integration testing.

<a name="IntegrationTestHelper.TestCrossProviderComparison"></a>
### func \(\*IntegrationTestHelper\) [TestCrossProviderComparison](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L366>)

```go
func (h *IntegrationTestHelper) TestCrossProviderComparison(t *testing.T, providers map[string]iface.ChatModel, testPrompt string)
```

TestCrossProviderComparison compares responses from multiple providers.

<a name="IntegrationTestHelper.TestProviderErrorHandling"></a>
### func \(\*IntegrationTestHelper\) [TestProviderErrorHandling](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L420>)

```go
func (h *IntegrationTestHelper) TestProviderErrorHandling(t *testing.T, provider iface.ChatModel, providerName string)
```

TestProviderErrorHandling tests error handling scenarios.

<a name="IntegrationTestHelper.TestProviderIntegration"></a>
### func \(\*IntegrationTestHelper\) [TestProviderIntegration](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L260>)

```go
func (h *IntegrationTestHelper) TestProviderIntegration(t *testing.T, provider iface.ChatModel, providerName string)
```

TestProviderIntegration tests a provider with basic integration tests.

<a name="IntegrationTestSuite"></a>
## type [IntegrationTestSuite](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L462-L467>)

IntegrationTestSuite represents a complete integration test suite.

```go
type IntegrationTestSuite struct {
    SetupFunc   func(t *testing.T) *IntegrationTestHelper
    TestFunc    func(t *testing.T, helper *IntegrationTestHelper)
    Name        string
    Description string
}
```

<a name="AnthropicIntegrationTestSuite"></a>
### func [AnthropicIntegrationTestSuite](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L486>)

```go
func AnthropicIntegrationTestSuite() IntegrationTestSuite
```

AnthropicIntegrationTestSuite returns a test suite for Anthropic.

<a name="MultiProviderIntegrationTestSuite"></a>
### func [MultiProviderIntegrationTestSuite](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L528>)

```go
func MultiProviderIntegrationTestSuite() IntegrationTestSuite
```

MultiProviderIntegrationTestSuite returns a test suite comparing multiple providers.

<a name="OllamaIntegrationTestSuite"></a>
### func [OllamaIntegrationTestSuite](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L578>)

```go
func OllamaIntegrationTestSuite() IntegrationTestSuite
```

OllamaIntegrationTestSuite returns a test suite for Ollama.

<a name="OpenAIIntegrationTestSuite"></a>
### func [OpenAIIntegrationTestSuite](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/integration_test_setup.go#L507>)

```go
func OpenAIIntegrationTestSuite() IntegrationTestSuite
```

OpenAIIntegrationTestSuite returns a test suite for OpenAI.

<a name="LLMError"></a>
## type [LLMError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L52-L58>)

LLMError represents an error that occurred during LLM operations. It includes an operation name, underlying error, and error code for programmatic handling.

```go
type LLMError struct {
    Err     error
    Details map[string]any
    Op      string
    Code    string
    Message string
}
```

### Example

Example demonstrating error handling.

```go
package main

import (
	"errors"
	"fmt"
	"log"

	"github.com/lookatitude/beluga-ai/pkg/llms"
)

func main() {
	// Create an LLM error
	err := llms.NewLLMError("generate", llms.ErrCodeRateLimit, errors.New("rate limit exceeded"))

	// Check if it's an LLM error
	if llms.IsLLMError(err) {
		if _, printErr := fmt.Printf("LLM Error Code: %s\n", llms.GetLLMErrorCode(err)); printErr != nil {
			log.Printf("Failed to print: %v", printErr)
		}
		if _, printErr := fmt.Printf("Is Retryable: %t\n", llms.IsRetryableError(err)); printErr != nil {
			log.Printf("Failed to print: %v", printErr)
		}
	}
}
```

#### Output

```
LLM Error Code: rate_limit
Is Retryable: true
```

<a name="GetLLMError"></a>
### func [GetLLMError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L113>)

```go
func GetLLMError(err error) *LLMError
```

GetLLMError extracts an LLMError from an error if it exists.

<a name="MapHTTPError"></a>
### func [MapHTTPError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L188>)

```go
func MapHTTPError(op string, statusCode int, err error) *LLMError
```

MapHTTPError maps HTTP status codes to LLM error codes.

<a name="NewLLMError"></a>
### func [NewLLMError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L77>)

```go
func NewLLMError(op, code string, err error) *LLMError
```

NewLLMError creates a new LLMError.

<a name="NewLLMErrorWithDetails"></a>
### func [NewLLMErrorWithDetails](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L96>)

```go
func NewLLMErrorWithDetails(op, code, message string, err error, details map[string]any) *LLMError
```

NewLLMErrorWithDetails creates a new LLMError with additional details.

<a name="NewLLMErrorWithMessage"></a>
### func [NewLLMErrorWithMessage](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L86>)

```go
func NewLLMErrorWithMessage(op, code, message string, err error) *LLMError
```

NewLLMErrorWithMessage creates a new LLMError with a custom message.

<a name="LLMError.Error"></a>
### func \(\*LLMError\) [Error](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L61>)

```go
func (e *LLMError) Error() string
```

Error implements the error interface.

<a name="LLMError.Unwrap"></a>
### func \(\*LLMError\) [Unwrap](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L72>)

```go
func (e *LLMError) Unwrap() error
```

Unwrap returns the underlying error.

<a name="LoadTestScenario"></a>
## type [LoadTestScenario](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L663-L669>)

LoadTestScenario represents a load testing scenario.

```go
type LoadTestScenario struct {
    TestFunc    func(ctx context.Context) error
    Name        string
    Duration    time.Duration
    Concurrency int
    RequestRate int
}
```

<a name="MessageGenerator"></a>
## type [MessageGenerator](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L20-L24>)

MessageGenerator defines the interface for generating messages. This focuses solely on message generation capabilities.

```go
type MessageGenerator interface {
    // GenerateMessages takes a list of messages and generates a response.
    // This is the primary method for chat-based interactions.
    GenerateMessages(ctx context.Context, messages []schema.Message, options ...core.Option) ([]schema.Message, error)
}
```

<a name="Metrics"></a>
## type [Metrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L69-L84>)

Metrics contains all the metrics for LLM operations.

```go
type Metrics struct {
    // contains filtered or unexported fields
}
```

<a name="GetMetrics"></a>
### func [GetMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/llms.go#L34>)

```go
func GetMetrics() *Metrics
```

GetMetrics returns the global metrics instance.

<a name="NewMetrics"></a>
### func [NewMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L87>)

```go
func NewMetrics(meter metric.Meter) *Metrics
```

NewMetrics creates a new Metrics instance.

<a name="Metrics.DecrementActiveRequests"></a>
### func \(\*Metrics\) [DecrementActiveRequests](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L158>)

```go
func (m *Metrics) DecrementActiveRequests(ctx context.Context, provider, model string)
```

DecrementActiveRequests decrements the active requests counter.

<a name="Metrics.DecrementActiveStreams"></a>
### func \(\*Metrics\) [DecrementActiveStreams](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L170>)

```go
func (m *Metrics) DecrementActiveStreams(ctx context.Context, provider, model string)
```

DecrementActiveStreams decrements the active streams counter.

<a name="Metrics.IncrementActiveRequests"></a>
### func \(\*Metrics\) [IncrementActiveRequests](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L152>)

```go
func (m *Metrics) IncrementActiveRequests(ctx context.Context, provider, model string)
```

IncrementActiveRequests increments the active requests counter.

<a name="Metrics.IncrementActiveStreams"></a>
### func \(\*Metrics\) [IncrementActiveStreams](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L164>)

```go
func (m *Metrics) IncrementActiveStreams(ctx context.Context, provider, model string)
```

IncrementActiveStreams increments the active streams counter.

<a name="Metrics.RecordBatch"></a>
### func \(\*Metrics\) [RecordBatch](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L138>)

```go
func (m *Metrics) RecordBatch(ctx context.Context, provider, model string, batchSize int, duration time.Duration)
```

RecordBatch records batch processing metrics.

<a name="Metrics.RecordError"></a>
### func \(\*Metrics\) [RecordError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L117>)

```go
func (m *Metrics) RecordError(ctx context.Context, provider, model, errorCode string, duration time.Duration)
```

RecordError records an error metric.

<a name="Metrics.RecordRequest"></a>
### func \(\*Metrics\) [RecordRequest](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L109>)

```go
func (m *Metrics) RecordRequest(ctx context.Context, provider, model string, duration time.Duration)
```

RecordRequest records a request metric.

<a name="Metrics.RecordStream"></a>
### func \(\*Metrics\) [RecordStream](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L145>)

```go
func (m *Metrics) RecordStream(ctx context.Context, provider, model string, duration time.Duration)
```

RecordStream records streaming metrics.

<a name="Metrics.RecordTokenUsage"></a>
### func \(\*Metrics\) [RecordTokenUsage](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L125>)

```go
func (m *Metrics) RecordTokenUsage(ctx context.Context, provider, model string, inputTokens, outputTokens int)
```

RecordTokenUsage records token usage metrics.

<a name="Metrics.RecordToolCall"></a>
### func \(\*Metrics\) [RecordToolCall](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L132>)

```go
func (m *Metrics) RecordToolCall(ctx context.Context, provider, model, toolName string)
```

RecordToolCall records a tool call metric.

<a name="MetricsRecorder"></a>
## type [MetricsRecorder](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L12-L23>)

MetricsRecorder defines the interface for recording metrics.

```go
type MetricsRecorder interface {
    RecordRequest(ctx context.Context, provider, model string, duration time.Duration)
    RecordError(ctx context.Context, provider, model, errorCode string, duration time.Duration)
    RecordTokenUsage(ctx context.Context, provider, model string, inputTokens, outputTokens int)
    RecordToolCall(ctx context.Context, provider, model, toolName string)
    RecordBatch(ctx context.Context, provider, model string, batchSize int, duration time.Duration)
    RecordStream(ctx context.Context, provider, model string, duration time.Duration)
    IncrementActiveRequests(ctx context.Context, provider, model string)
    DecrementActiveRequests(ctx context.Context, provider, model string)
    IncrementActiveStreams(ctx context.Context, provider, model string)
    DecrementActiveStreams(ctx context.Context, provider, model string)
}
```

<a name="MockMetricsRecorder"></a>
## type [MockMetricsRecorder](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L446-L448>)

MockMetricsRecorder provides a mock implementation of MetricsRecorder.

```go
type MockMetricsRecorder struct {
    mock.Mock
}
```

<a name="NewMockMetricsRecorder"></a>
### func [NewMockMetricsRecorder](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L450>)

```go
func NewMockMetricsRecorder() *MockMetricsRecorder
```

<a name="MockMetricsRecorder.DecrementActiveRequests"></a>
### func \(\*MockMetricsRecorder\) [DecrementActiveRequests](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L503>)

```go
func (m *MockMetricsRecorder) DecrementActiveRequests(ctx context.Context, provider, model string)
```

<a name="MockMetricsRecorder.DecrementActiveStreams"></a>
### func \(\*MockMetricsRecorder\) [DecrementActiveStreams](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L517>)

```go
func (m *MockMetricsRecorder) DecrementActiveStreams(ctx context.Context, provider, model string)
```

<a name="MockMetricsRecorder.IncrementActiveRequests"></a>
### func \(\*MockMetricsRecorder\) [IncrementActiveRequests](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L496>)

```go
func (m *MockMetricsRecorder) IncrementActiveRequests(ctx context.Context, provider, model string)
```

<a name="MockMetricsRecorder.IncrementActiveStreams"></a>
### func \(\*MockMetricsRecorder\) [IncrementActiveStreams](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L510>)

```go
func (m *MockMetricsRecorder) IncrementActiveStreams(ctx context.Context, provider, model string)
```

<a name="MockMetricsRecorder.RecordBatch"></a>
### func \(\*MockMetricsRecorder\) [RecordBatch](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L482>)

```go
func (m *MockMetricsRecorder) RecordBatch(ctx context.Context, provider, model string, batchSize int, duration time.Duration)
```

<a name="MockMetricsRecorder.RecordError"></a>
### func \(\*MockMetricsRecorder\) [RecordError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L461>)

```go
func (m *MockMetricsRecorder) RecordError(ctx context.Context, provider, model, errorCode string, duration time.Duration)
```

<a name="MockMetricsRecorder.RecordRequest"></a>
### func \(\*MockMetricsRecorder\) [RecordRequest](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L454>)

```go
func (m *MockMetricsRecorder) RecordRequest(ctx context.Context, provider, model string, duration time.Duration)
```

<a name="MockMetricsRecorder.RecordStream"></a>
### func \(\*MockMetricsRecorder\) [RecordStream](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L489>)

```go
func (m *MockMetricsRecorder) RecordStream(ctx context.Context, provider, model string, duration time.Duration)
```

<a name="MockMetricsRecorder.RecordTokenUsage"></a>
### func \(\*MockMetricsRecorder\) [RecordTokenUsage](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L468>)

```go
func (m *MockMetricsRecorder) RecordTokenUsage(ctx context.Context, provider, model string, inputTokens, outputTokens int)
```

<a name="MockMetricsRecorder.RecordToolCall"></a>
### func \(\*MockMetricsRecorder\) [RecordToolCall](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L475>)

```go
func (m *MockMetricsRecorder) RecordToolCall(ctx context.Context, provider, model, toolName string)
```

<a name="MockOption"></a>
## type [MockOption](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L63>)

MockOption configures the behavior of AdvancedMockChatModel.

```go
type MockOption func(*AdvancedMockChatModel)
```

<a name="WithError"></a>
### func [WithError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L80>)

```go
func WithError(err error) MockOption
```

WithError configures the mock to return an error.

<a name="WithHealthState"></a>
### func [WithHealthState](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L102>)

```go
func WithHealthState(state string) MockOption
```

WithHealthState sets the health check state.

<a name="WithNetworkDelay"></a>
### func [WithNetworkDelay](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L95>)

```go
func WithNetworkDelay(enabled bool) MockOption
```

WithNetworkDelay enables network delay simulation.

<a name="WithProviderName"></a>
### func [WithProviderName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L66>)

```go
func WithProviderName(name string) MockOption
```

WithProviderName sets the provider name.

<a name="WithResponses"></a>
### func [WithResponses](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L73>)

```go
func WithResponses(responses ...string) MockOption
```

WithResponses sets the responses to return.

<a name="WithStreamingDelay"></a>
### func [WithStreamingDelay](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L88>)

```go
func WithStreamingDelay(delay time.Duration) MockOption
```

WithStreamingDelay sets the delay between streaming chunks.

<a name="WithToolResults"></a>
### func [WithToolResults](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L109>)

```go
func WithToolResults(results map[string]any) MockOption
```

WithToolResults pre\-configures tool execution results.

<a name="MockProviderConfig"></a>
## type [MockProviderConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/generate.go#L16-L22>)

MockProviderConfig represents configuration for generating mock providers.

```go
type MockProviderConfig struct {
    ProviderName string
    ModelName    string
    Delay        string
    Responses    []string
    Errors       []string
}
```

<a name="MockTool"></a>
## type [MockTool](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L726-L731>)

MockTool provides a mock tool implementation for testing.

```go
type MockTool struct {
    // contains filtered or unexported fields
}
```

<a name="NewMockTool"></a>
### func [NewMockTool](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L733>)

```go
func NewMockTool(name string) *MockTool
```

<a name="MockTool.Batch"></a>
### func \(\*MockTool\) [Batch](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L766>)

```go
func (m *MockTool) Batch(ctx context.Context, inputs []any) ([]any, error)
```

<a name="MockTool.Definition"></a>
### func \(\*MockTool\) [Definition](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L748>)

```go
func (m *MockTool) Definition() tools.ToolDefinition
```

<a name="MockTool.Description"></a>
### func \(\*MockTool\) [Description](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L744>)

```go
func (m *MockTool) Description() string
```

<a name="MockTool.Execute"></a>
### func \(\*MockTool\) [Execute](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L756>)

```go
func (m *MockTool) Execute(ctx context.Context, input any) (any, error)
```

<a name="MockTool.Name"></a>
### func \(\*MockTool\) [Name](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L740>)

```go
func (m *MockTool) Name() string
```

<a name="MockTool.SetResult"></a>
### func \(\*MockTool\) [SetResult](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L782>)

```go
func (m *MockTool) SetResult(result any)
```

<a name="MockTool.SetShouldError"></a>
### func \(\*MockTool\) [SetShouldError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L778>)

```go
func (m *MockTool) SetShouldError(shouldError bool)
```

<a name="MockTracingHelper"></a>
## type [MockTracingHelper](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L525-L527>)

MockTracingHelper provides a mock implementation of tracing functionality.

```go
type MockTracingHelper struct {
    mock.Mock
}
```

<a name="NewMockTracingHelper"></a>
### func [NewMockTracingHelper](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L529>)

```go
func NewMockTracingHelper() *MockTracingHelper
```

<a name="MockTracingHelper.AddSpanAttributes"></a>
### func \(\*MockTracingHelper\) [AddSpanAttributes](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L551>)

```go
func (m *MockTracingHelper) AddSpanAttributes(ctx context.Context, attrs map[string]any)
```

<a name="MockTracingHelper.EndSpan"></a>
### func \(\*MockTracingHelper\) [EndSpan](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L558>)

```go
func (m *MockTracingHelper) EndSpan(ctx context.Context)
```

<a name="MockTracingHelper.RecordError"></a>
### func \(\*MockTracingHelper\) [RecordError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L544>)

```go
func (m *MockTracingHelper) RecordError(ctx context.Context, err error)
```

<a name="MockTracingHelper.StartOperation"></a>
### func \(\*MockTracingHelper\) [StartOperation](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/test_utils.go#L533>)

```go
func (m *MockTracingHelper) StartOperation(ctx context.Context, operation, provider, model string) context.Context
```

<a name="ModelInfo"></a>
## type [ModelInfo](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L58-L64>)

ModelInfo contains metadata about a chat model.

```go
type ModelInfo struct {
    Name         string
    Provider     string
    Version      string
    Capabilities []string
    MaxTokens    int
}
```

<a name="ModelInfoProvider"></a>
## type [ModelInfoProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L34-L37>)

ModelInfoProvider defines the interface for providing model information.

```go
type ModelInfoProvider interface {
    // GetModelInfo returns information about the underlying model.
    GetModelInfo() ModelInfo
}
```

<a name="NoOpMetrics"></a>
## type [NoOpMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L26>)

NoOpMetrics provides a no\-operation implementation for when metrics are disabled.

```go
type NoOpMetrics struct{}
```

<a name="NewNoOpMetrics"></a>
### func [NewNoOpMetrics](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L29>)

```go
func NewNoOpMetrics() *NoOpMetrics
```

NewNoOpMetrics creates a new no\-operation metrics recorder.

<a name="NoOpMetrics.DecrementActiveRequests"></a>
### func \(\*NoOpMetrics\) [DecrementActiveRequests](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L60>)

```go
func (n *NoOpMetrics) DecrementActiveRequests(ctx context.Context, provider, model string)
```

DecrementActiveRequests is a no\-op implementation.

<a name="NoOpMetrics.DecrementActiveStreams"></a>
### func \(\*NoOpMetrics\) [DecrementActiveStreams](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L66>)

```go
func (n *NoOpMetrics) DecrementActiveStreams(ctx context.Context, provider, model string)
```

DecrementActiveStreams is a no\-op implementation.

<a name="NoOpMetrics.IncrementActiveRequests"></a>
### func \(\*NoOpMetrics\) [IncrementActiveRequests](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L57>)

```go
func (n *NoOpMetrics) IncrementActiveRequests(ctx context.Context, provider, model string)
```

IncrementActiveRequests is a no\-op implementation.

<a name="NoOpMetrics.IncrementActiveStreams"></a>
### func \(\*NoOpMetrics\) [IncrementActiveStreams](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L63>)

```go
func (n *NoOpMetrics) IncrementActiveStreams(ctx context.Context, provider, model string)
```

IncrementActiveStreams is a no\-op implementation.

<a name="NoOpMetrics.RecordBatch"></a>
### func \(\*NoOpMetrics\) [RecordBatch](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L49>)

```go
func (n *NoOpMetrics) RecordBatch(ctx context.Context, provider, model string, batchSize int, duration time.Duration)
```

RecordBatch is a no\-op implementation.

<a name="NoOpMetrics.RecordError"></a>
### func \(\*NoOpMetrics\) [RecordError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L38>)

```go
func (n *NoOpMetrics) RecordError(ctx context.Context, provider, model, errorCode string, duration time.Duration)
```

RecordError is a no\-op implementation.

<a name="NoOpMetrics.RecordRequest"></a>
### func \(\*NoOpMetrics\) [RecordRequest](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L34>)

```go
func (n *NoOpMetrics) RecordRequest(ctx context.Context, provider, model string, duration time.Duration)
```

RecordRequest is a no\-op implementation.

<a name="NoOpMetrics.RecordStream"></a>
### func \(\*NoOpMetrics\) [RecordStream](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L53>)

```go
func (n *NoOpMetrics) RecordStream(ctx context.Context, provider, model string, duration time.Duration)
```

RecordStream is a no\-op implementation.

<a name="NoOpMetrics.RecordTokenUsage"></a>
### func \(\*NoOpMetrics\) [RecordTokenUsage](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L42>)

```go
func (n *NoOpMetrics) RecordTokenUsage(ctx context.Context, provider, model string, inputTokens, outputTokens int)
```

RecordTokenUsage is a no\-op implementation.

<a name="NoOpMetrics.RecordToolCall"></a>
### func \(\*NoOpMetrics\) [RecordToolCall](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/metrics.go#L46>)

```go
func (n *NoOpMetrics) RecordToolCall(ctx context.Context, provider, model, toolName string)
```

RecordToolCall is a no\-op implementation.

<a name="OpenTelemetryTracer"></a>
## type [OpenTelemetryTracer](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L22-L24>)

OpenTelemetryTracer implements TracerProvider using OpenTelemetry.

```go
type OpenTelemetryTracer struct {
    // contains filtered or unexported fields
}
```

<a name="NewOpenTelemetryTracer"></a>
### func [NewOpenTelemetryTracer](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L27>)

```go
func NewOpenTelemetryTracer(name string) *OpenTelemetryTracer
```

NewOpenTelemetryTracer creates a new OpenTelemetry tracer.

<a name="OpenTelemetryTracer.AddSpanAttributes"></a>
### func \(\*OpenTelemetryTracer\) [AddSpanAttributes](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L56>)

```go
func (t *OpenTelemetryTracer) AddSpanAttributes(span trace.Span, attrs map[string]any)
```

AddSpanAttributes adds attributes to a span.

<a name="OpenTelemetryTracer.RecordError"></a>
### func \(\*OpenTelemetryTracer\) [RecordError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L48>)

```go
func (t *OpenTelemetryTracer) RecordError(span trace.Span, err error)
```

RecordError records an error on a span.

<a name="OpenTelemetryTracer.StartSpan"></a>
### func \(\*OpenTelemetryTracer\) [StartSpan](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L37>)

```go
func (t *OpenTelemetryTracer) StartSpan(ctx context.Context, operation, provider, model string) (context.Context, trace.Span)
```

StartSpan starts a new trace span for an LLM operation. The returned span must be ended by the caller using span.End\(\).

<a name="ProviderConfig"></a>
## type [ProviderConfig](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/config.go#L208-L211>)

ProviderConfig represents configuration for a specific provider.

```go
type ProviderConfig struct {
    Config
}
```

<a name="ProviderError"></a>
## type [ProviderError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L271-L277>)

ProviderError represents provider\-specific errors.

```go
type ProviderError struct {
    Err      error
    Provider string
    Op       string
    Code     string
    Message  string
}
```

<a name="NewProviderError"></a>
### func [NewProviderError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L290>)

```go
func NewProviderError(provider, op, code, message string, err error) *ProviderError
```

NewProviderError creates a new ProviderError.

<a name="ProviderError.Error"></a>
### func \(\*ProviderError\) [Error](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L280>)

```go
func (e *ProviderError) Error() string
```

Error implements the error interface.

<a name="ProviderError.Unwrap"></a>
### func \(\*ProviderError\) [Unwrap](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L285>)

```go
func (e *ProviderError) Unwrap() error
```

Unwrap returns the underlying error.

<a name="ProviderTemplate"></a>
## type [ProviderTemplate](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/generate.go#L25-L31>)

ProviderTemplate represents a template for generating new providers.

```go
type ProviderTemplate struct {
    Name       string
    Package    string
    Config     any
    Imports    []string
    Interfaces []string
}
```

<a name="StreamError"></a>
## type [StreamError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L301-L306>)

StreamError represents streaming\-specific errors.

```go
type StreamError struct {
    Err     error
    Op      string
    Code    string
    Message string
}
```

<a name="NewStreamError"></a>
### func [NewStreamError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L319>)

```go
func NewStreamError(op, code, message string, err error) *StreamError
```

NewStreamError creates a new StreamError.

<a name="StreamError.Error"></a>
### func \(\*StreamError\) [Error](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L309>)

```go
func (e *StreamError) Error() string
```

Error implements the error interface.

<a name="StreamError.Unwrap"></a>
### func \(\*StreamError\) [Unwrap](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L314>)

```go
func (e *StreamError) Unwrap() error
```

Unwrap returns the underlying error.

<a name="StreamMessageHandler"></a>
## type [StreamMessageHandler](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/chatmodels.go#L28-L31>)

StreamMessageHandler defines the interface for streaming message responses. This allows for real\-time streaming of chat responses.

```go
type StreamMessageHandler interface {
    // StreamMessages provides streaming responses for chat interactions.
    StreamMessages(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan schema.Message, error)
}
```

<a name="TracerProvider"></a>
## type [TracerProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L15-L19>)

TracerProvider defines the interface for tracing operations.

```go
type TracerProvider interface {
    StartSpan(ctx context.Context, operation, provider, model string) (context.Context, trace.Span)
    RecordError(span trace.Span, err error)
    AddSpanAttributes(span trace.Span, attrs map[string]any)
}
```

<a name="TracingHelper"></a>
## type [TracingHelper](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L85-L87>)

TracingHelper provides high\-level tracing utilities.

```go
type TracingHelper struct {
    // contains filtered or unexported fields
}
```

<a name="NewTracingHelper"></a>
### func [NewTracingHelper](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L90>)

```go
func NewTracingHelper() *TracingHelper
```

NewTracingHelper creates a new TracingHelper with OpenTelemetry.

<a name="TracingHelper.AddSpanAttributes"></a>
### func \(\*TracingHelper\) [AddSpanAttributes](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L112>)

```go
func (th *TracingHelper) AddSpanAttributes(ctx context.Context, attrs map[string]any)
```

AddSpanAttributes adds attributes to the current span.

<a name="TracingHelper.EndSpan"></a>
### func \(\*TracingHelper\) [EndSpan](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L119>)

```go
func (th *TracingHelper) EndSpan(ctx context.Context)
```

EndSpan ends the current span.

<a name="TracingHelper.RecordError"></a>
### func \(\*TracingHelper\) [RecordError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L105>)

```go
func (th *TracingHelper) RecordError(ctx context.Context, err error)
```

RecordError records an error on the current span.

<a name="TracingHelper.StartOperation"></a>
### func \(\*TracingHelper\) [StartOperation](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/tracing.go#L98>)

```go
func (th *TracingHelper) StartOperation(ctx context.Context, operation, provider, model string) context.Context
```

StartOperation starts a new trace span for an LLM operation. The span must be ended by calling EndSpan on the returned context.

<a name="ValidationError"></a>
## type [ValidationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L220-L224>)

ValidationError represents a configuration validation error.

```go
type ValidationError struct {
    Field   string
    Value   any
    Message string
}
```

<a name="NewValidationError"></a>
### func [NewValidationError](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L232>)

```go
func NewValidationError(field string, value any, message string) *ValidationError
```

NewValidationError creates a new ValidationError.

<a name="ValidationError.Error"></a>
### func \(\*ValidationError\) [Error](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/errors.go#L227>)

```go
func (e *ValidationError) Error() string
```

Error implements the error interface.

Generated by [gomarkdoc](<https://github.com/princjef/gomarkdoc>)

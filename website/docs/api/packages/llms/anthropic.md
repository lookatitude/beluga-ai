<!-- Code generated by gomarkdoc. DO NOT EDIT -->

# anthropic

```go
import "github.com/lookatitude/beluga-ai/llms/anthropic"
```

Package anthropic provides an implementation of the llms.ChatModel interface using the Anthropic API \(Claude models\).

## Index

- [type AnthropicChat](<#AnthropicChat>)
  - [func NewAnthropicChat\(options ...AnthropicOption\) \(\*AnthropicChat, error\)](<#NewAnthropicChat>)
  - [func \(ac \*AnthropicChat\) Batch\(ctx context.Context, inputs \[\]\[\]schema.Message, options ...core.Option\) \(\[\]\[\]schema.Message, error\)](<#AnthropicChat.Batch>)
  - [func \(ac \*AnthropicChat\) BindTools\(toolsToBind \[\]tools.Tool\) \(llms.ChatModel, error\)](<#AnthropicChat.BindTools>)
  - [func \(ac \*AnthropicChat\) Generate\(ctx context.Context, messages \[\]schema.Message, options ...core.Option\) \(schema.Message, error\)](<#AnthropicChat.Generate>)
  - [func \(ac \*AnthropicChat\) Invoke\(ctx context.Context, input schema.Message, options ...core.Option\) \(schema.Message, error\)](<#AnthropicChat.Invoke>)
  - [func \(ac \*AnthropicChat\) Stream\(ctx context.Context, input \[\]schema.Message, options ...core.Option\) \(\<\-chan schema.ChatResponseChunk, error\)](<#AnthropicChat.Stream>)
  - [func \(ac \*AnthropicChat\) StreamChat\(ctx context.Context, messages \[\]schema.Message, options ...core.Option\) \(\<\-chan schema.ChatResponseChunk, error\)](<#AnthropicChat.StreamChat>)
- [type AnthropicOption](<#AnthropicOption>)
  - [func WithAnthropicAPIKey\(apiKey string\) AnthropicOption](<#WithAnthropicAPIKey>)
  - [func WithAnthropicAPIVersion\(version string\) AnthropicOption](<#WithAnthropicAPIVersion>)
  - [func WithAnthropicBaseURL\(baseURL string\) AnthropicOption](<#WithAnthropicBaseURL>)
  - [func WithAnthropicDefaultRequest\(req anthropic.MessageNewParams\) AnthropicOption](<#WithAnthropicDefaultRequest>)
  - [func WithAnthropicMaxConcurrentBatches\(n int\) AnthropicOption](<#WithAnthropicMaxConcurrentBatches>)
  - [func WithAnthropicModel\(modelName string\) AnthropicOption](<#WithAnthropicModel>)


<a name="AnthropicChat"></a>
## type AnthropicChat

AnthropicChat represents a chat model client for the Anthropic API.

```go
type AnthropicChat struct {
    // contains filtered or unexported fields
}
```

<a name="NewAnthropicChat"></a>
### func NewAnthropicChat

```go
func NewAnthropicChat(options ...AnthropicOption) (*AnthropicChat, error)
```

NewAnthropicChat creates a new Anthropic chat client. It requires an API key \(read from ANTHROPIC\_API\_KEY env var by default\) and accepts functional options.

<a name="AnthropicChat.Batch"></a>
### func \(\*AnthropicChat\) Batch

```go
func (ac *AnthropicChat) Batch(ctx context.Context, inputs [][]schema.Message, options ...core.Option) ([][]schema.Message, error)
```

Batch implements the llms.ChatModel interface \(core.Runnable\).

<a name="AnthropicChat.BindTools"></a>
### func \(\*AnthropicChat\) BindTools

```go
func (ac *AnthropicChat) BindTools(toolsToBind []tools.Tool) (llms.ChatModel, error)
```

BindTools implements the llms.ChatModel interface.

<a name="AnthropicChat.Generate"></a>
### func \(\*AnthropicChat\) Generate

```go
func (ac *AnthropicChat) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error)
```

Generate implements the llms.ChatModel interface.

<a name="AnthropicChat.Invoke"></a>
### func \(\*AnthropicChat\) Invoke

```go
func (ac *AnthropicChat) Invoke(ctx context.Context, input schema.Message, options ...core.Option) (schema.Message, error)
```

Invoke implements the llms.ChatModel interface \(core.Runnable\).

<a name="AnthropicChat.Stream"></a>
### func \(\*AnthropicChat\) Stream

```go
func (ac *AnthropicChat) Stream(ctx context.Context, input []schema.Message, options ...core.Option) (<-chan schema.ChatResponseChunk, error)
```

Stream implements the llms.ChatModel interface \(core.Runnable\).

<a name="AnthropicChat.StreamChat"></a>
### func \(\*AnthropicChat\) StreamChat

```go
func (ac *AnthropicChat) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan schema.ChatResponseChunk, error)
```

StreamChat implements the llms.ChatModel interface with streaming.

<a name="AnthropicOption"></a>
## type AnthropicOption

AnthropicOption is a function type for setting options on the AnthropicChat client configuration.

```go
type AnthropicOption func(*anthropicChatConfig)
```

<a name="WithAnthropicAPIKey"></a>
### func WithAnthropicAPIKey

```go
func WithAnthropicAPIKey(apiKey string) AnthropicOption
```

WithAnthropicAPIKey sets the API key.

<a name="WithAnthropicAPIVersion"></a>
### func WithAnthropicAPIVersion

```go
func WithAnthropicAPIVersion(version string) AnthropicOption
```

WithAnthropicAPIVersion sets the API version header. Note: The current SDK might not use this directly for client construction in the same way. It uses anthropic.WithAPIVersion for specific request headers if needed, but not typically for client init.

<a name="WithAnthropicBaseURL"></a>
### func WithAnthropicBaseURL

```go
func WithAnthropicBaseURL(baseURL string) AnthropicOption
```

WithAnthropicBaseURL sets the base URL.

<a name="WithAnthropicDefaultRequest"></a>
### func WithAnthropicDefaultRequest

```go
func WithAnthropicDefaultRequest(req anthropic.MessageNewParams) AnthropicOption
```

WithAnthropicDefaultRequest sets the default request parameters. Note: This replaces the entire default request struct.

<a name="WithAnthropicMaxConcurrentBatches"></a>
### func WithAnthropicMaxConcurrentBatches

```go
func WithAnthropicMaxConcurrentBatches(n int) AnthropicOption
```

WithAnthropicMaxConcurrentBatches sets the concurrency limit for Batch.

<a name="WithAnthropicModel"></a>
### func WithAnthropicModel

```go
func WithAnthropicModel(modelName string) AnthropicOption
```

WithAnthropicModel sets the default model name.

Generated by [gomarkdoc](<https://github.com/princjef/gomarkdoc>)

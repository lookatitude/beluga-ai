---
title: openai
sidebar_position: 1
---

<!-- Code generated by gomarkdoc. DO NOT EDIT -->


# openai

```go
import "github.com/lookatitude/beluga-ai/pkg/llms/providers/openai"
```

Package openai provides an implementation of the llms.ChatModel interface using the OpenAI API \(GPT models\).

## Index

- [Constants](#constants>)
- [func NewOpenAIProviderFactory\(\) func\(\*llms.Config\) \(iface.ChatModel, error\)](#NewOpenAIProviderFactory>)
- [type OpenAIProvider](#OpenAIProvider>)
  - [func NewOpenAIProvider\(config \*llms.Config\) \(\*OpenAIProvider, error\)](#NewOpenAIProvider>)
  - [func \(o \*OpenAIProvider\) Batch\(ctx context.Context, inputs \[\]any, options ...core.Option\) \(\[\]any, error\)](#OpenAIProvider.Batch>)
  - [func \(o \*OpenAIProvider\) BindTools\(toolsToBind \[\]tools.Tool\) iface.ChatModel](#OpenAIProvider.BindTools>)
  - [func \(o \*OpenAIProvider\) CheckHealth\(\) map\[string\]any](#OpenAIProvider.CheckHealth>)
  - [func \(o \*OpenAIProvider\) Generate\(ctx context.Context, messages \[\]schema.Message, options ...core.Option\) \(schema.Message, error\)](#OpenAIProvider.Generate>)
  - [func \(o \*OpenAIProvider\) GetModelName\(\) string](#OpenAIProvider.GetModelName>)
  - [func \(o \*OpenAIProvider\) GetProviderName\(\) string](#OpenAIProvider.GetProviderName>)
  - [func \(o \*OpenAIProvider\) Invoke\(ctx context.Context, input any, options ...core.Option\) \(any, error\)](#OpenAIProvider.Invoke>)
  - [func \(o \*OpenAIProvider\) Stream\(ctx context.Context, input any, options ...core.Option\) \(\<\-chan any, error\)](#OpenAIProvider.Stream>)
  - [func \(o \*OpenAIProvider\) StreamChat\(ctx context.Context, messages \[\]schema.Message, options ...core.Option\) \(\<\-chan iface.AIMessageChunk, error\)](#OpenAIProvider.StreamChat>)

## Constants

Provider constants.

```go
const (
    ProviderName = "openai"
    DefaultModel = "gpt-3.5-turbo"

    // Error codes specific to OpenAI.
    ErrCodeInvalidAPIKey  = "openai_invalid_api_key"
    ErrCodeRateLimit      = "openai_rate_limit"
    ErrCodeModelNotFound  = "openai_model_not_found"
    ErrCodeInvalidRequest = "openai_invalid_request"
    ErrCodeQuotaExceeded  = "openai_quota_exceeded"
)
```


## func [NewOpenAIProviderFactory](https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L593)

```go
func NewOpenAIProviderFactory() func(*llms.Config) (iface.ChatModel, error)
```

Factory function for creating OpenAI providers.


## type [OpenAIProvider](https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L37-L45)

OpenAIProvider implements the ChatModel interface for OpenAI GPT models.

```go
type OpenAIProvider struct {
    // contains filtered or unexported fields
}
```


### func [NewOpenAIProvider](https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L48)

```go
func NewOpenAIProvider(config *llms.Config) (*OpenAIProvider, error)
```

NewOpenAIProvider creates a new OpenAI provider instance.


### func \(\*OpenAIProvider\) [Batch](https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L176)

```go
func (o *OpenAIProvider) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error)
```

Batch implements the Runnable interface.


### func \(\*OpenAIProvider\) [BindTools](https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L150)

```go
func (o *OpenAIProvider) BindTools(toolsToBind []tools.Tool) iface.ChatModel
```

BindTools implements the ChatModel interface.


### func \(\*OpenAIProvider\) [CheckHealth](https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L581)

```go
func (o *OpenAIProvider) CheckHealth() map[string]any
```

CheckHealth implements the HealthChecker interface.


### func \(\*OpenAIProvider\) [Generate](https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L90)

```go
func (o *OpenAIProvider) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error)
```

Generate implements the ChatModel interface.


### func \(\*OpenAIProvider\) [GetModelName](https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L158)

```go
func (o *OpenAIProvider) GetModelName() string
```

GetModelName implements the ChatModel interface.


### func \(\*OpenAIProvider\) [GetProviderName](https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L162)

```go
func (o *OpenAIProvider) GetProviderName() string
```


### func \(\*OpenAIProvider\) [Invoke](https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L167)

```go
func (o *OpenAIProvider) Invoke(ctx context.Context, input any, options ...core.Option) (any, error)
```

Invoke implements the Runnable interface.


### func \(\*OpenAIProvider\) [Stream](https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L216)

```go
func (o *OpenAIProvider) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error)
```

Stream implements the Runnable interface.


### func \(\*OpenAIProvider\) [StreamChat](https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/openai/provider.go#L132)

```go
func (o *OpenAIProvider) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan iface.AIMessageChunk, error)
```

StreamChat implements the ChatModel interface.

Generated by [gomarkdoc](https://github.com/princjef/gomarkdoc)

---
title: ollama
sidebar_position: 1
---

<!-- Code generated by gomarkdoc. DO NOT EDIT -->


# ollama

```go
import "github.com/lookatitude/beluga-ai/pkg/llms/providers/ollama"
```

Package ollama provides an implementation of the llms.ChatModel interface using the Ollama API for local LLM models.

## Index

- [Constants](<#constants>)
- [func NewOllamaProviderFactory\(\) func\(\*llms.Config\) \(iface.ChatModel, error\)](<#NewOllamaProviderFactory>)
- [type OllamaProvider](<#OllamaProvider>)
  - [func NewOllamaProvider\(config \*llms.Config\) \(\*OllamaProvider, error\)](<#NewOllamaProvider>)
  - [func \(o \*OllamaProvider\) Batch\(ctx context.Context, inputs \[\]any, options ...core.Option\) \(\[\]any, error\)](<#OllamaProvider.Batch>)
  - [func \(o \*OllamaProvider\) BindTools\(toolsToBind \[\]tools.Tool\) iface.ChatModel](<#OllamaProvider.BindTools>)
  - [func \(o \*OllamaProvider\) CheckHealth\(\) map\[string\]any](<#OllamaProvider.CheckHealth>)
  - [func \(o \*OllamaProvider\) Generate\(ctx context.Context, messages \[\]schema.Message, options ...core.Option\) \(schema.Message, error\)](<#OllamaProvider.Generate>)
  - [func \(o \*OllamaProvider\) GetModelName\(\) string](<#OllamaProvider.GetModelName>)
  - [func \(o \*OllamaProvider\) GetProviderName\(\) string](<#OllamaProvider.GetProviderName>)
  - [func \(o \*OllamaProvider\) Invoke\(ctx context.Context, input any, options ...core.Option\) \(any, error\)](<#OllamaProvider.Invoke>)
  - [func \(o \*OllamaProvider\) Stream\(ctx context.Context, input any, options ...core.Option\) \(\<\-chan any, error\)](<#OllamaProvider.Stream>)
  - [func \(o \*OllamaProvider\) StreamChat\(ctx context.Context, messages \[\]schema.Message, options ...core.Option\) \(\<\-chan iface.AIMessageChunk, error\)](<#OllamaProvider.StreamChat>)

## Constants

<a name="ProviderName"></a>Provider constants.

```go
const (
    ProviderName = "ollama"
    DefaultModel = "llama2"

    // Error codes specific to Ollama.
    ErrCodeConnectionFailed = "ollama_connection_failed"
    ErrCodeModelNotFound    = "ollama_model_not_found"
    ErrCodeInvalidRequest   = "ollama_invalid_request"
)
```

<a name="NewOllamaProviderFactory"></a>
## func [NewOllamaProviderFactory](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/ollama/provider.go#L622>)

```go
func NewOllamaProviderFactory() func(*llms.Config) (iface.ChatModel, error)
```

Factory function for creating Ollama providers.

<a name="OllamaProvider"></a>
## type [OllamaProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/ollama/provider.go#L37-L46>)

OllamaProvider implements the ChatModel interface for Ollama models.

```go
type OllamaProvider struct {
    // contains filtered or unexported fields
}
```

<a name="NewOllamaProvider"></a>
### func [NewOllamaProvider](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/ollama/provider.go#L49>)

```go
func NewOllamaProvider(config *llms.Config) (*OllamaProvider, error)
```

NewOllamaProvider creates a new Ollama provider instance.

<a name="OllamaProvider.Batch"></a>
### func \(\*OllamaProvider\) [Batch](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/ollama/provider.go#L201>)

```go
func (o *OllamaProvider) Batch(ctx context.Context, inputs []any, options ...core.Option) ([]any, error)
```

Batch implements the Runnable interface.

<a name="OllamaProvider.BindTools"></a>
### func \(\*OllamaProvider\) [BindTools](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/ollama/provider.go#L175>)

```go
func (o *OllamaProvider) BindTools(toolsToBind []tools.Tool) iface.ChatModel
```

BindTools implements the ChatModel interface.

<a name="OllamaProvider.CheckHealth"></a>
### func \(\*OllamaProvider\) [CheckHealth](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/ollama/provider.go#L610>)

```go
func (o *OllamaProvider) CheckHealth() map[string]any
```

CheckHealth implements the HealthChecker interface.

<a name="OllamaProvider.Generate"></a>
### func \(\*OllamaProvider\) [Generate](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/ollama/provider.go#L87>)

```go
func (o *OllamaProvider) Generate(ctx context.Context, messages []schema.Message, options ...core.Option) (schema.Message, error)
```

Generate implements the ChatModel interface.

<a name="OllamaProvider.GetModelName"></a>
### func \(\*OllamaProvider\) [GetModelName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/ollama/provider.go#L183>)

```go
func (o *OllamaProvider) GetModelName() string
```

GetModelName implements the ChatModel interface.

<a name="OllamaProvider.GetProviderName"></a>
### func \(\*OllamaProvider\) [GetProviderName](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/ollama/provider.go#L187>)

```go
func (o *OllamaProvider) GetProviderName() string
```

<a name="OllamaProvider.Invoke"></a>
### func \(\*OllamaProvider\) [Invoke](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/ollama/provider.go#L192>)

```go
func (o *OllamaProvider) Invoke(ctx context.Context, input any, options ...core.Option) (any, error)
```

Invoke implements the Runnable interface.

<a name="OllamaProvider.Stream"></a>
### func \(\*OllamaProvider\) [Stream](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/ollama/provider.go#L241>)

```go
func (o *OllamaProvider) Stream(ctx context.Context, input any, options ...core.Option) (<-chan any, error)
```

Stream implements the Runnable interface.

<a name="OllamaProvider.StreamChat"></a>
### func \(\*OllamaProvider\) [StreamChat](<https://github.com/lookatitude/beluga-ai/blob/main/pkg/llms/providers/ollama/provider.go#L129>)

```go
func (o *OllamaProvider) StreamChat(ctx context.Context, messages []schema.Message, options ...core.Option) (<-chan iface.AIMessageChunk, error)
```

StreamChat implements the ChatModel interface.

Generated by [gomarkdoc](<https://github.com/princjef/gomarkdoc>)

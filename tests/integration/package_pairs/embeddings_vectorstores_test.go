// Package package_pairs provides integration tests between Embeddings and Vectorstores packages.
// This test suite verifies that embeddings and vector stores work together correctly
// for document storage, retrieval, and similarity search operations.
package package_pairs

import (
	"context"
	"fmt"
	"testing"
	"time"

	"github.com/lookatitude/beluga-ai/pkg/embeddings"
	"github.com/lookatitude/beluga-ai/pkg/schema"
	"github.com/lookatitude/beluga-ai/pkg/vectorstores"
	"github.com/lookatitude/beluga-ai/tests/integration/utils"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	embeddingsiface "github.com/lookatitude/beluga-ai/pkg/embeddings/iface"
	vectorstoresiface "github.com/lookatitude/beluga-ai/pkg/vectorstores/iface"
)

// TestIntegrationEmbeddingsVectorstores tests the integration between Embeddings and Vectorstores
func TestIntegrationEmbeddingsVectorstores(t *testing.T) {
	helper := utils.NewIntegrationTestHelper()
	defer helper.Cleanup(context.Background())

	tests := []struct {
		name               string
		documentsCount     int
		embeddingDimension int
		searchQueries      []string
		expectedResults    int
	}{
		{
			name:               "basic_document_embedding_storage",
			documentsCount:     10,
			embeddingDimension: 128,
			searchQueries:      []string{"machine learning", "artificial intelligence"},
			expectedResults:    5,
		},
		{
			name:               "large_document_collection",
			documentsCount:     100,
			embeddingDimension: 256,
			searchQueries:      []string{"deep learning", "neural networks", "computer vision"},
			expectedResults:    3,
		},
		{
			name:               "high_dimensional_embeddings",
			documentsCount:     25,
			embeddingDimension: 512,
			searchQueries:      []string{"natural language processing"},
			expectedResults:    2,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctx := context.Background()

			// Create embedder and vector store
			embedder := helper.CreateMockEmbedder("integration-embedder", tt.embeddingDimension)
			vectorStore := helper.CreateMockVectorStore("integration-vectorstore")

			// Create test documents
			documents := utils.CreateTestDocuments(tt.documentsCount, "AI")

			// Test document embedding and storage
			start := time.Now()
			documentIDs, err := vectorStore.AddDocuments(ctx, documents,
				vectorstoresiface.WithEmbedder(embedder))
			embeddingDuration := time.Since(start)

			require.NoError(t, err)
			assert.Len(t, documentIDs, tt.documentsCount)

			t.Logf("Embedded and stored %d documents in %v", tt.documentsCount, embeddingDuration)

			// Verify embedder was called for each document
			if mockEmbedder, ok := embedder.(*embeddings.AdvancedMockEmbedder); ok {
				// The vector store should have called EmbedDocuments
				assert.Greater(t, mockEmbedder.GetCallCount(), 0,
					"Embedder should have been called during document storage")
			}

			// Test similarity search with embeddings
			for i, query := range tt.searchQueries {
				searchStart := time.Now()

				// Test search by query (requires embedder)
				searchDocs, scores, err := vectorStore.SimilaritySearchByQuery(
					ctx, query, tt.expectedResults, embedder)
				searchDuration := time.Since(searchStart)

				require.NoError(t, err, "Search query %d failed", i+1)
				assert.LessOrEqual(t, len(searchDocs), tt.expectedResults,
					"Search query %d should return max %d results", i+1, tt.expectedResults)
				assert.Equal(t, len(searchDocs), len(scores),
					"Search query %d should have matching documents and scores", i+1)

				t.Logf("Search query %d: '%s' returned %d documents in %v",
					i+1, query, len(searchDocs), searchDuration)

				// Verify search results quality
				if len(searchDocs) > 0 {
					// Scores should be in descending order
					for j := 1; j < len(scores); j++ {
						assert.GreaterOrEqual(t, scores[j-1], scores[j],
							"Scores should be in descending order for query %d", i+1)
					}

					// All documents should have content
					for j, doc := range searchDocs {
						assert.NotEmpty(t, doc.GetContent(),
							"Query %d result %d should have content", i+1, j+1)
					}
				}
			}

			// Test direct embedding consistency
			testQuery := "test consistency query"

			// Get embedding directly from embedder
			queryEmbedding, err := embedder.EmbedQuery(ctx, testQuery)
			require.NoError(t, err)

			// Search using the direct embedding
			directSearchDocs, _, err := vectorStore.SimilaritySearch(
				ctx, queryEmbedding, tt.expectedResults)
			require.NoError(t, err)

			// Search using query (which internally uses embedder)
			querySearchDocs, _, err := vectorStore.SimilaritySearchByQuery(
				ctx, testQuery, tt.expectedResults, embedder)
			require.NoError(t, err)

			// Results should be consistent (for deterministic embedders)
			assert.Equal(t, len(directSearchDocs), len(querySearchDocs),
				"Direct and query search should return same number of results")
		})
	}
}

// TestEmbeddingsVectorstoresErrorHandling tests error scenarios
func TestEmbeddingsVectorstoresErrorHandling(t *testing.T) {
	helper := utils.NewIntegrationTestHelper()
	defer helper.Cleanup(context.Background())

	tests := []struct {
		name        string
		setupError  func() (embeddingsiface.Embedder, vectorstoresiface.VectorStore)
		operation   func(ctx context.Context, embedder embeddingsiface.Embedder, store vectorstoresiface.VectorStore) error
		expectedErr bool
	}{
		{
			name: "embedder_error_during_storage",
			setupError: func() (embeddingsiface.Embedder, vectorstoresiface.VectorStore) {
				errorEmbedder := embeddings.NewAdvancedMockEmbedder("error-provider", "error-model", 128,
					embeddings.WithMockError(true, fmt.Errorf("embedding service down")))
				normalStore := helper.CreateMockVectorStore("normal-store")
				return errorEmbedder, normalStore
			},
			operation: func(ctx context.Context, embedder embeddingsiface.Embedder, store vectorstoresiface.VectorStore) error {
				docs := utils.CreateTestDocuments(3, "test")
				_, err := store.AddDocuments(ctx, docs, vectorstoresiface.WithEmbedder(embedder))
				return err
			},
			expectedErr: true,
		},
		{
			name: "vectorstore_error_during_storage",
			setupError: func() (embeddingsiface.Embedder, vectorstoresiface.VectorStore) {
				normalEmbedder := helper.CreateMockEmbedder("normal-embedder", 128)
				errorStore := vectorstores.NewAdvancedMockVectorStore("error-store",
					vectorstores.WithMockError(true, fmt.Errorf("storage capacity exceeded")))
				return normalEmbedder, errorStore
			},
			operation: func(ctx context.Context, embedder embeddingsiface.Embedder, store vectorstoresiface.VectorStore) error {
				docs := utils.CreateTestDocuments(3, "test")
				_, err := store.AddDocuments(ctx, docs, vectorstoresiface.WithEmbedder(embedder))
				return err
			},
			expectedErr: true,
		},
		{
			name: "embedder_error_during_search",
			setupError: func() (embeddingsiface.Embedder, vectorstoresiface.VectorStore) {
				// Start with working embedder for storage
				workingEmbedder := helper.CreateMockEmbedder("working-embedder", 128)
				store := helper.CreateMockVectorStore("normal-store")

				// Add some documents first
				docs := utils.CreateTestDocuments(5, "test")
				store.AddDocuments(context.Background(), docs, vectorstoresiface.WithEmbedder(workingEmbedder))

				// Then create error embedder for search
				errorEmbedder := embeddings.NewAdvancedMockEmbedder("error-provider", "error-model", 128,
					embeddings.WithMockError(true, fmt.Errorf("embedding service unavailable")))

				return errorEmbedder, store
			},
			operation: func(ctx context.Context, embedder embeddingsiface.Embedder, store vectorstoresiface.VectorStore) error {
				_, _, err := store.SimilaritySearchByQuery(ctx, "test query", 3, embedder)
				return err
			},
			expectedErr: true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			embedder, store := tt.setupError()

			ctx := context.Background()
			err := tt.operation(ctx, embedder, store)

			if tt.expectedErr {
				assert.Error(t, err)
				t.Logf("Expected error occurred: %v", err)
			} else {
				assert.NoError(t, err)
			}
		})
	}
}

// TestEmbeddingsVectorstoresPerformance tests performance scenarios
func TestEmbeddingsVectorstoresPerformance(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping performance tests in short mode")
	}

	helper := utils.NewIntegrationTestHelper()
	defer helper.Cleanup(context.Background())

	tests := []struct {
		name               string
		documentsCount     int
		embeddingDimension int
		searchCount        int
		maxEmbeddingTime   time.Duration
		maxSearchTime      time.Duration
	}{
		{
			name:               "small_scale_performance",
			documentsCount:     50,
			embeddingDimension: 128,
			searchCount:        10,
			maxEmbeddingTime:   2 * time.Second,
			maxSearchTime:      1 * time.Second,
		},
		{
			name:               "medium_scale_performance",
			documentsCount:     200,
			embeddingDimension: 256,
			searchCount:        25,
			maxEmbeddingTime:   5 * time.Second,
			maxSearchTime:      3 * time.Second,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctx := context.Background()

			// Create components
			embedder := helper.CreateMockEmbedder("perf-embedder", tt.embeddingDimension)
			vectorStore := helper.CreateMockVectorStore("perf-vectorstore")

			// Test embedding and storage performance
			documents := utils.CreateTestDocuments(tt.documentsCount, "performance")

			embeddingStart := time.Now()
			_, err := vectorStore.AddDocuments(ctx, documents, vectorstoresiface.WithEmbedder(embedder))
			embeddingDuration := time.Since(embeddingStart)

			require.NoError(t, err)
			assert.LessOrEqual(t, embeddingDuration, tt.maxEmbeddingTime,
				"Embedding %d documents should complete within %v, took %v",
				tt.documentsCount, tt.maxEmbeddingTime, embeddingDuration)

			// Test search performance
			queries := utils.CreateTestQueries(tt.searchCount)

			searchStart := time.Now()
			for i, query := range queries {
				_, _, err := vectorStore.SimilaritySearchByQuery(ctx, query, 5, embedder)
				require.NoError(t, err, "Search query %d failed", i+1)
			}
			searchDuration := time.Since(searchStart)

			assert.LessOrEqual(t, searchDuration, tt.maxSearchTime,
				"Searching %d queries should complete within %v, took %v",
				tt.searchCount, tt.maxSearchTime, searchDuration)

			t.Logf("Performance test: %d docs embedded in %v, %d searches in %v",
				tt.documentsCount, embeddingDuration, tt.searchCount, searchDuration)
		})
	}
}

// TestEmbeddingsVectorstoresConcurrency tests concurrent operations
func TestEmbeddingsVectorstoresConcurrency(t *testing.T) {
	helper := utils.NewIntegrationTestHelper()
	defer helper.Cleanup(context.Background())

	embedder := helper.CreateMockEmbedder("concurrent-embedder", 256)
	vectorStore := helper.CreateMockVectorStore("concurrent-vectorstore")

	const numGoroutines = 5
	const operationsPerGoroutine = 4

	t.Run("concurrent_embedding_and_storage", func(t *testing.T) {
		helper.CrossPackageLoadTest(t, func() error {
			ctx := context.Background()

			// Create a document
			doc := schema.NewDocument(
				fmt.Sprintf("Concurrent test document with unique content %d", time.Now().UnixNano()),
				map[string]string{"test": "concurrent"},
			)

			// Store document (involves embedding)
			_, err := vectorStore.AddDocuments(ctx, []schema.Document{doc},
				vectorstoresiface.WithEmbedder(embedder))
			if err != nil {
				return fmt.Errorf("failed to store document: %w", err)
			}

			// Search for similar documents (involves embedding the query)
			_, _, err = vectorStore.SimilaritySearchByQuery(ctx, "test query", 3, embedder)
			if err != nil {
				return fmt.Errorf("failed to search documents: %w", err)
			}

			return nil
		}, numGoroutines*operationsPerGoroutine, numGoroutines)
	})
}

// TestEmbeddingsVectorstoresRealWorldScenarios tests realistic usage patterns
func TestEmbeddingsVectorstoresRealWorldScenarios(t *testing.T) {
	helper := utils.NewIntegrationTestHelper()
	defer helper.Cleanup(context.Background())

	scenarios := []struct {
		name     string
		scenario func(t *testing.T)
	}{
		{
			name: "knowledge_base_construction",
			scenario: func(t *testing.T) {
				ctx := context.Background()

				embedder := helper.CreateMockEmbedder("kb-embedder", 384)
				vectorStore := helper.CreateMockVectorStore("kb-vectorstore")

				// Simulate building a knowledge base from different sources
				documentBatches := [][]schema.Document{
					utils.CreateTestDocuments(10, "AI basics"),
					utils.CreateTestDocuments(8, "machine learning"),
					utils.CreateTestDocuments(12, "deep learning"),
					utils.CreateTestDocuments(6, "natural language processing"),
				}

				totalDocs := 0
				for i, batch := range documentBatches {
					batchStart := time.Now()

					ids, err := vectorStore.AddDocuments(ctx, batch,
						vectorstoresiface.WithEmbedder(embedder))
					batchDuration := time.Since(batchStart)

					require.NoError(t, err, "Batch %d failed", i+1)
					assert.Len(t, ids, len(batch), "Batch %d should return correct number of IDs", i+1)

					totalDocs += len(batch)
					t.Logf("Batch %d: embedded and stored %d documents in %v",
						i+1, len(batch), batchDuration)
				}

				// Test comprehensive search across all documents
				searchQueries := []string{
					"What are the fundamentals of artificial intelligence?",
					"How do machine learning algorithms work?",
					"What is deep learning and how does it differ from traditional ML?",
					"How does natural language processing enable human-computer interaction?",
				}

				for i, query := range searchQueries {
					docs, scores, err := vectorStore.SimilaritySearchByQuery(ctx, query, 5, embedder)
					require.NoError(t, err, "Search query %d failed", i+1)

					assert.LessOrEqual(t, len(docs), 5, "Query %d should respect k limit", i+1)
					assert.Equal(t, len(docs), len(scores), "Query %d should have matching docs and scores", i+1)

					if len(docs) > 0 {
						t.Logf("Query %d found %d relevant documents with top score %.3f",
							i+1, len(docs), scores[0])
					}
				}

				t.Logf("Knowledge base construction complete: %d total documents indexed and searchable", totalDocs)
			},
		},
		{
			name: "semantic_similarity_testing",
			scenario: func(t *testing.T) {
				ctx := context.Background()

				embedder := helper.CreateMockEmbedder("semantic-embedder", 256)
				vectorStore := helper.CreateMockVectorStore("semantic-vectorstore")

				// Create documents with known semantic relationships
				documents := []schema.Document{
					schema.NewDocument("Machine learning is a subset of artificial intelligence",
						map[string]string{"topic": "ML", "level": "basic"}),
					schema.NewDocument("AI enables machines to simulate human intelligence",
						map[string]string{"topic": "AI", "level": "basic"}),
					schema.NewDocument("Deep learning uses neural networks with multiple layers",
						map[string]string{"topic": "DL", "level": "intermediate"}),
					schema.NewDocument("Cooking recipes often require precise measurements",
						map[string]string{"topic": "cooking", "level": "basic"}), // Unrelated document
				}

				// Store documents
				_, err := vectorStore.AddDocuments(ctx, documents,
					vectorstoresiface.WithEmbedder(embedder))
				require.NoError(t, err)

				// Test semantic queries
				semanticQueries := []struct {
					query              string
					expectRelatedTopic string
					expectedMinResults int
				}{
					{
						query:              "What is artificial intelligence?",
						expectRelatedTopic: "AI",
						expectedMinResults: 1,
					},
					{
						query:              "How do neural networks learn?",
						expectRelatedTopic: "DL",
						expectedMinResults: 1,
					},
				}

				for i, sq := range semanticQueries {
					docs, _, err := vectorStore.SimilaritySearchByQuery(ctx, sq.query, 3, embedder)
					require.NoError(t, err, "Semantic query %d failed", i+1)

					assert.GreaterOrEqual(t, len(docs), sq.expectedMinResults,
						"Semantic query %d should find at least %d related documents",
						i+1, sq.expectedMinResults)
				}
			},
		},
		{
			name: "incremental_updates",
			scenario: func(t *testing.T) {
				ctx := context.Background()

				embedder := helper.CreateMockEmbedder("incremental-embedder", 200)
				vectorStore := helper.CreateMockVectorStore("incremental-vectorstore")

				// Initial document set
				initialDocs := utils.CreateTestDocuments(5, "initial")
				ids1, err := vectorStore.AddDocuments(ctx, initialDocs,
					vectorstoresiface.WithEmbedder(embedder))
				require.NoError(t, err)

				// Verify initial search works
				initialResults, _, err := vectorStore.SimilaritySearchByQuery(
					ctx, "initial content", 3, embedder)
				require.NoError(t, err)
				initialCount := len(initialResults)

				// Add more documents
				additionalDocs := utils.CreateTestDocuments(7, "additional")
				ids2, err := vectorStore.AddDocuments(ctx, additionalDocs,
					vectorstoresiface.WithEmbedder(embedder))
				require.NoError(t, err)

				// Verify expanded search works
				expandedResults, _, err := vectorStore.SimilaritySearchByQuery(
					ctx, "content", 10, embedder)
				require.NoError(t, err)

				// Should potentially find more documents now
				assert.GreaterOrEqual(t, len(expandedResults), initialCount,
					"Expanded collection should have at least as many results")

				// Test deletion
				if len(ids1) > 0 {
					err = vectorStore.DeleteDocuments(ctx, ids1[:2]) // Delete 2 documents
					assert.NoError(t, err, "Document deletion should work")
				}

				// Verify deletion worked
				finalResults, _, err := vectorStore.SimilaritySearchByQuery(
					ctx, "content", 15, embedder)
				require.NoError(t, err)

				t.Logf("Incremental updates: initial=%d, expanded=%d, final=%d results",
					initialCount, len(expandedResults), len(finalResults))

				// Store final IDs for cleanup
				_ = ids2 // Mark as used
			},
		},
	}

	for _, scenario := range scenarios {
		t.Run(scenario.name, func(t *testing.T) {
			scenario.scenario(t)
		})
	}
}

// TestEmbeddingsVectorstoresCompatibility tests compatibility across different provider combinations
func TestEmbeddingsVectorstoresCompatibility(t *testing.T) {
	helper := utils.NewIntegrationTestHelper()
	defer helper.Cleanup(context.Background())

	// Test different embedding dimension and vector store combinations
	combinations := []struct {
		embeddingDim    int
		vectorStoreType string
		expectedWorking bool
	}{
		{128, "inmemory", true},
		{256, "inmemory", true},
		{512, "inmemory", true},
		{1536, "inmemory", true}, // OpenAI ada-002 dimension
		{768, "inmemory", true},  // Common transformer dimension
	}

	for _, combo := range combinations {
		t.Run(fmt.Sprintf("dim_%d_%s", combo.embeddingDim, combo.vectorStoreType), func(t *testing.T) {
			ctx := context.Background()

			embedder := helper.CreateMockEmbedder("compat-embedder", combo.embeddingDim)
			vectorStore := helper.CreateMockVectorStore("compat-vectorstore")

			// Test basic compatibility
			documents := utils.CreateTestDocuments(5, "compatibility")

			_, err := vectorStore.AddDocuments(ctx, documents,
				vectorstoresiface.WithEmbedder(embedder))

			if combo.expectedWorking {
				assert.NoError(t, err, "Dimension %d should be compatible", combo.embeddingDim)

				// Test search compatibility
				_, _, err = vectorStore.SimilaritySearchByQuery(ctx, "compatibility test", 3, embedder)
				assert.NoError(t, err, "Search should work with dimension %d", combo.embeddingDim)
			} else {
				assert.Error(t, err, "Dimension %d should not be compatible", combo.embeddingDim)
			}
		})
	}
}

// BenchmarkIntegrationEmbeddingsVectorstores benchmarks embedding-vectorstore integration
func BenchmarkIntegrationEmbeddingsVectorstores(b *testing.B) {
	helper := utils.NewIntegrationTestHelper()
	defer helper.Cleanup(context.Background())

	embedder := helper.CreateMockEmbedder("benchmark-embedder", 256)
	vectorStore := helper.CreateMockVectorStore("benchmark-vectorstore")
	ctx := context.Background()

	// Pre-populate for search benchmarks
	documents := utils.CreateTestDocuments(100, "benchmark")
	vectorStore.AddDocuments(ctx, documents, vectorstoresiface.WithEmbedder(embedder))

	b.Run("DocumentEmbeddingAndStorage", func(b *testing.B) {
		testDoc := utils.CreateTestDocuments(1, "benchmark")[0]
		b.ResetTimer()
		for i := 0; i < b.N; i++ {
			_, err := vectorStore.AddDocuments(ctx, []schema.Document{testDoc},
				vectorstoresiface.WithEmbedder(embedder))
			if err != nil {
				b.Errorf("Document embedding and storage error: %v", err)
			}
		}
	})

	b.Run("QueryEmbeddingAndSearch", func(b *testing.B) {
		b.ResetTimer()
		for i := 0; i < b.N; i++ {
			query := fmt.Sprintf("benchmark query %d", i)
			_, _, err := vectorStore.SimilaritySearchByQuery(ctx, query, 5, embedder)
			if err != nil {
				b.Errorf("Query embedding and search error: %v", err)
			}
		}
	})

	b.Run("DirectEmbeddingOperations", func(b *testing.B) {
		b.ResetTimer()
		for i := 0; i < b.N; i++ {
			// Test direct embedding operations
			query := fmt.Sprintf("direct embedding test %d", i)
			queryEmbedding, err := embedder.EmbedQuery(ctx, query)
			if err != nil {
				b.Errorf("Query embedding error: %v", err)
				continue
			}

			// Test vector search
			_, _, err = vectorStore.SimilaritySearch(ctx, queryEmbedding, 5)
			if err != nil {
				b.Errorf("Vector search error: %v", err)
			}
		}
	})

	b.Run("BatchEmbeddingOperations", func(b *testing.B) {
		texts := make([]string, 10)
		for i := range texts {
			texts[i] = fmt.Sprintf("Batch embedding text %d for benchmarking", i)
		}

		b.ResetTimer()
		for i := 0; i < b.N; i++ {
			_, err := embedder.EmbedDocuments(ctx, texts)
			if err != nil {
				b.Errorf("Batch embedding error: %v", err)
			}
		}
	})
}
